{"version":3,"file":"index-bVKPJrRP.js","sources":["../../node_modules/@ai-sdk/openai/node_modules/@ai-sdk/provider-utils/dist/index.mjs","../../node_modules/@ai-sdk/openai/dist/index.mjs"],"sourcesContent":["// src/combine-headers.ts\nfunction combineHeaders(...headers) {\n  return headers.reduce(\n    (combinedHeaders, currentHeaders) => ({\n      ...combinedHeaders,\n      ...currentHeaders != null ? currentHeaders : {}\n    }),\n    {}\n  );\n}\n\n// src/convert-async-iterator-to-readable-stream.ts\nfunction convertAsyncIteratorToReadableStream(iterator) {\n  return new ReadableStream({\n    /**\n     * Called when the consumer wants to pull more data from the stream.\n     *\n     * @param {ReadableStreamDefaultController<T>} controller - The controller to enqueue data into the stream.\n     * @returns {Promise<void>}\n     */\n    async pull(controller) {\n      try {\n        const { value, done } = await iterator.next();\n        if (done) {\n          controller.close();\n        } else {\n          controller.enqueue(value);\n        }\n      } catch (error) {\n        controller.error(error);\n      }\n    },\n    /**\n     * Called when the consumer cancels the stream.\n     */\n    cancel() {\n    }\n  });\n}\n\n// src/delay.ts\nasync function delay(delayInMs) {\n  return delayInMs == null ? Promise.resolve() : new Promise((resolve2) => setTimeout(resolve2, delayInMs));\n}\n\n// src/event-source-parser-stream.ts\nfunction createEventSourceParserStream() {\n  let buffer = \"\";\n  let event = void 0;\n  let data = [];\n  let lastEventId = void 0;\n  let retry = void 0;\n  function parseLine(line, controller) {\n    if (line === \"\") {\n      dispatchEvent(controller);\n      return;\n    }\n    if (line.startsWith(\":\")) {\n      return;\n    }\n    const colonIndex = line.indexOf(\":\");\n    if (colonIndex === -1) {\n      handleField(line, \"\");\n      return;\n    }\n    const field = line.slice(0, colonIndex);\n    const valueStart = colonIndex + 1;\n    const value = valueStart < line.length && line[valueStart] === \" \" ? line.slice(valueStart + 1) : line.slice(valueStart);\n    handleField(field, value);\n  }\n  function dispatchEvent(controller) {\n    if (data.length > 0) {\n      controller.enqueue({\n        event,\n        data: data.join(\"\\n\"),\n        id: lastEventId,\n        retry\n      });\n      data = [];\n      event = void 0;\n      retry = void 0;\n    }\n  }\n  function handleField(field, value) {\n    switch (field) {\n      case \"event\":\n        event = value;\n        break;\n      case \"data\":\n        data.push(value);\n        break;\n      case \"id\":\n        lastEventId = value;\n        break;\n      case \"retry\":\n        const parsedRetry = parseInt(value, 10);\n        if (!isNaN(parsedRetry)) {\n          retry = parsedRetry;\n        }\n        break;\n    }\n  }\n  return new TransformStream({\n    transform(chunk, controller) {\n      const { lines, incompleteLine } = splitLines(buffer, chunk);\n      buffer = incompleteLine;\n      for (let i = 0; i < lines.length; i++) {\n        parseLine(lines[i], controller);\n      }\n    },\n    flush(controller) {\n      parseLine(buffer, controller);\n      dispatchEvent(controller);\n    }\n  });\n}\nfunction splitLines(buffer, chunk) {\n  const lines = [];\n  let currentLine = buffer;\n  for (let i = 0; i < chunk.length; ) {\n    const char = chunk[i++];\n    if (char === \"\\n\") {\n      lines.push(currentLine);\n      currentLine = \"\";\n    } else if (char === \"\\r\") {\n      lines.push(currentLine);\n      currentLine = \"\";\n      if (chunk[i] === \"\\n\") {\n        i++;\n      }\n    } else {\n      currentLine += char;\n    }\n  }\n  return { lines, incompleteLine: currentLine };\n}\n\n// src/extract-response-headers.ts\nfunction extractResponseHeaders(response) {\n  const headers = {};\n  response.headers.forEach((value, key) => {\n    headers[key] = value;\n  });\n  return headers;\n}\n\n// src/generate-id.ts\nimport { InvalidArgumentError } from \"@ai-sdk/provider\";\nimport { customAlphabet } from \"nanoid/non-secure\";\nvar createIdGenerator = ({\n  prefix,\n  size: defaultSize = 16,\n  alphabet = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\",\n  separator = \"-\"\n} = {}) => {\n  const generator = customAlphabet(alphabet, defaultSize);\n  if (prefix == null) {\n    return generator;\n  }\n  if (alphabet.includes(separator)) {\n    throw new InvalidArgumentError({\n      argument: \"separator\",\n      message: `The separator \"${separator}\" must not be part of the alphabet \"${alphabet}\".`\n    });\n  }\n  return (size) => `${prefix}${separator}${generator(size)}`;\n};\nvar generateId = createIdGenerator();\n\n// src/get-error-message.ts\nfunction getErrorMessage(error) {\n  if (error == null) {\n    return \"unknown error\";\n  }\n  if (typeof error === \"string\") {\n    return error;\n  }\n  if (error instanceof Error) {\n    return error.message;\n  }\n  return JSON.stringify(error);\n}\n\n// src/get-from-api.ts\nimport { APICallError } from \"@ai-sdk/provider\";\n\n// src/remove-undefined-entries.ts\nfunction removeUndefinedEntries(record) {\n  return Object.fromEntries(\n    Object.entries(record).filter(([_key, value]) => value != null)\n  );\n}\n\n// src/is-abort-error.ts\nfunction isAbortError(error) {\n  return error instanceof Error && (error.name === \"AbortError\" || error.name === \"TimeoutError\");\n}\n\n// src/get-from-api.ts\nvar getOriginalFetch = () => globalThis.fetch;\nvar getFromApi = async ({\n  url,\n  headers = {},\n  successfulResponseHandler,\n  failedResponseHandler,\n  abortSignal,\n  fetch = getOriginalFetch()\n}) => {\n  try {\n    const response = await fetch(url, {\n      method: \"GET\",\n      headers: removeUndefinedEntries(headers),\n      signal: abortSignal\n    });\n    const responseHeaders = extractResponseHeaders(response);\n    if (!response.ok) {\n      let errorInformation;\n      try {\n        errorInformation = await failedResponseHandler({\n          response,\n          url,\n          requestBodyValues: {}\n        });\n      } catch (error) {\n        if (isAbortError(error) || APICallError.isInstance(error)) {\n          throw error;\n        }\n        throw new APICallError({\n          message: \"Failed to process error response\",\n          cause: error,\n          statusCode: response.status,\n          url,\n          responseHeaders,\n          requestBodyValues: {}\n        });\n      }\n      throw errorInformation.value;\n    }\n    try {\n      return await successfulResponseHandler({\n        response,\n        url,\n        requestBodyValues: {}\n      });\n    } catch (error) {\n      if (error instanceof Error) {\n        if (isAbortError(error) || APICallError.isInstance(error)) {\n          throw error;\n        }\n      }\n      throw new APICallError({\n        message: \"Failed to process successful response\",\n        cause: error,\n        statusCode: response.status,\n        url,\n        responseHeaders,\n        requestBodyValues: {}\n      });\n    }\n  } catch (error) {\n    if (isAbortError(error)) {\n      throw error;\n    }\n    if (error instanceof TypeError && error.message === \"fetch failed\") {\n      const cause = error.cause;\n      if (cause != null) {\n        throw new APICallError({\n          message: `Cannot connect to API: ${cause.message}`,\n          cause,\n          url,\n          isRetryable: true,\n          requestBodyValues: {}\n        });\n      }\n    }\n    throw error;\n  }\n};\n\n// src/load-api-key.ts\nimport { LoadAPIKeyError } from \"@ai-sdk/provider\";\nfunction loadApiKey({\n  apiKey,\n  environmentVariableName,\n  apiKeyParameterName = \"apiKey\",\n  description\n}) {\n  if (typeof apiKey === \"string\") {\n    return apiKey;\n  }\n  if (apiKey != null) {\n    throw new LoadAPIKeyError({\n      message: `${description} API key must be a string.`\n    });\n  }\n  if (typeof process === \"undefined\") {\n    throw new LoadAPIKeyError({\n      message: `${description} API key is missing. Pass it using the '${apiKeyParameterName}' parameter. Environment variables is not supported in this environment.`\n    });\n  }\n  apiKey = process.env[environmentVariableName];\n  if (apiKey == null) {\n    throw new LoadAPIKeyError({\n      message: `${description} API key is missing. Pass it using the '${apiKeyParameterName}' parameter or the ${environmentVariableName} environment variable.`\n    });\n  }\n  if (typeof apiKey !== \"string\") {\n    throw new LoadAPIKeyError({\n      message: `${description} API key must be a string. The value of the ${environmentVariableName} environment variable is not a string.`\n    });\n  }\n  return apiKey;\n}\n\n// src/load-optional-setting.ts\nfunction loadOptionalSetting({\n  settingValue,\n  environmentVariableName\n}) {\n  if (typeof settingValue === \"string\") {\n    return settingValue;\n  }\n  if (settingValue != null || typeof process === \"undefined\") {\n    return void 0;\n  }\n  settingValue = process.env[environmentVariableName];\n  if (settingValue == null || typeof settingValue !== \"string\") {\n    return void 0;\n  }\n  return settingValue;\n}\n\n// src/load-setting.ts\nimport { LoadSettingError } from \"@ai-sdk/provider\";\nfunction loadSetting({\n  settingValue,\n  environmentVariableName,\n  settingName,\n  description\n}) {\n  if (typeof settingValue === \"string\") {\n    return settingValue;\n  }\n  if (settingValue != null) {\n    throw new LoadSettingError({\n      message: `${description} setting must be a string.`\n    });\n  }\n  if (typeof process === \"undefined\") {\n    throw new LoadSettingError({\n      message: `${description} setting is missing. Pass it using the '${settingName}' parameter. Environment variables is not supported in this environment.`\n    });\n  }\n  settingValue = process.env[environmentVariableName];\n  if (settingValue == null) {\n    throw new LoadSettingError({\n      message: `${description} setting is missing. Pass it using the '${settingName}' parameter or the ${environmentVariableName} environment variable.`\n    });\n  }\n  if (typeof settingValue !== \"string\") {\n    throw new LoadSettingError({\n      message: `${description} setting must be a string. The value of the ${environmentVariableName} environment variable is not a string.`\n    });\n  }\n  return settingValue;\n}\n\n// src/parse-json.ts\nimport {\n  JSONParseError,\n  TypeValidationError as TypeValidationError2\n} from \"@ai-sdk/provider\";\nimport SecureJSON from \"secure-json-parse\";\n\n// src/validate-types.ts\nimport { TypeValidationError } from \"@ai-sdk/provider\";\n\n// src/validator.ts\nvar validatorSymbol = Symbol.for(\"vercel.ai.validator\");\nfunction validator(validate) {\n  return { [validatorSymbol]: true, validate };\n}\nfunction isValidator(value) {\n  return typeof value === \"object\" && value !== null && validatorSymbol in value && value[validatorSymbol] === true && \"validate\" in value;\n}\nfunction asValidator(value) {\n  return isValidator(value) ? value : zodValidator(value);\n}\nfunction zodValidator(zodSchema) {\n  return validator((value) => {\n    const result = zodSchema.safeParse(value);\n    return result.success ? { success: true, value: result.data } : { success: false, error: result.error };\n  });\n}\n\n// src/validate-types.ts\nfunction validateTypes({\n  value,\n  schema: inputSchema\n}) {\n  const result = safeValidateTypes({ value, schema: inputSchema });\n  if (!result.success) {\n    throw TypeValidationError.wrap({ value, cause: result.error });\n  }\n  return result.value;\n}\nfunction safeValidateTypes({\n  value,\n  schema\n}) {\n  const validator2 = asValidator(schema);\n  try {\n    if (validator2.validate == null) {\n      return { success: true, value };\n    }\n    const result = validator2.validate(value);\n    if (result.success) {\n      return result;\n    }\n    return {\n      success: false,\n      error: TypeValidationError.wrap({ value, cause: result.error })\n    };\n  } catch (error) {\n    return {\n      success: false,\n      error: TypeValidationError.wrap({ value, cause: error })\n    };\n  }\n}\n\n// src/parse-json.ts\nfunction parseJSON({\n  text,\n  schema\n}) {\n  try {\n    const value = SecureJSON.parse(text);\n    if (schema == null) {\n      return value;\n    }\n    return validateTypes({ value, schema });\n  } catch (error) {\n    if (JSONParseError.isInstance(error) || TypeValidationError2.isInstance(error)) {\n      throw error;\n    }\n    throw new JSONParseError({ text, cause: error });\n  }\n}\nfunction safeParseJSON({\n  text,\n  schema\n}) {\n  try {\n    const value = SecureJSON.parse(text);\n    if (schema == null) {\n      return { success: true, value, rawValue: value };\n    }\n    const validationResult = safeValidateTypes({ value, schema });\n    return validationResult.success ? { ...validationResult, rawValue: value } : validationResult;\n  } catch (error) {\n    return {\n      success: false,\n      error: JSONParseError.isInstance(error) ? error : new JSONParseError({ text, cause: error })\n    };\n  }\n}\nfunction isParsableJson(input) {\n  try {\n    SecureJSON.parse(input);\n    return true;\n  } catch (e) {\n    return false;\n  }\n}\n\n// src/parse-provider-options.ts\nimport { InvalidArgumentError as InvalidArgumentError2 } from \"@ai-sdk/provider\";\nfunction parseProviderOptions({\n  provider,\n  providerOptions,\n  schema\n}) {\n  if ((providerOptions == null ? void 0 : providerOptions[provider]) == null) {\n    return void 0;\n  }\n  const parsedProviderOptions = safeValidateTypes({\n    value: providerOptions[provider],\n    schema\n  });\n  if (!parsedProviderOptions.success) {\n    throw new InvalidArgumentError2({\n      argument: \"providerOptions\",\n      message: `invalid ${provider} provider options`,\n      cause: parsedProviderOptions.error\n    });\n  }\n  return parsedProviderOptions.value;\n}\n\n// src/post-to-api.ts\nimport { APICallError as APICallError2 } from \"@ai-sdk/provider\";\nvar getOriginalFetch2 = () => globalThis.fetch;\nvar postJsonToApi = async ({\n  url,\n  headers,\n  body,\n  failedResponseHandler,\n  successfulResponseHandler,\n  abortSignal,\n  fetch\n}) => postToApi({\n  url,\n  headers: {\n    \"Content-Type\": \"application/json\",\n    ...headers\n  },\n  body: {\n    content: JSON.stringify(body),\n    values: body\n  },\n  failedResponseHandler,\n  successfulResponseHandler,\n  abortSignal,\n  fetch\n});\nvar postFormDataToApi = async ({\n  url,\n  headers,\n  formData,\n  failedResponseHandler,\n  successfulResponseHandler,\n  abortSignal,\n  fetch\n}) => postToApi({\n  url,\n  headers,\n  body: {\n    content: formData,\n    values: Object.fromEntries(formData.entries())\n  },\n  failedResponseHandler,\n  successfulResponseHandler,\n  abortSignal,\n  fetch\n});\nvar postToApi = async ({\n  url,\n  headers = {},\n  body,\n  successfulResponseHandler,\n  failedResponseHandler,\n  abortSignal,\n  fetch = getOriginalFetch2()\n}) => {\n  try {\n    const response = await fetch(url, {\n      method: \"POST\",\n      headers: removeUndefinedEntries(headers),\n      body: body.content,\n      signal: abortSignal\n    });\n    const responseHeaders = extractResponseHeaders(response);\n    if (!response.ok) {\n      let errorInformation;\n      try {\n        errorInformation = await failedResponseHandler({\n          response,\n          url,\n          requestBodyValues: body.values\n        });\n      } catch (error) {\n        if (isAbortError(error) || APICallError2.isInstance(error)) {\n          throw error;\n        }\n        throw new APICallError2({\n          message: \"Failed to process error response\",\n          cause: error,\n          statusCode: response.status,\n          url,\n          responseHeaders,\n          requestBodyValues: body.values\n        });\n      }\n      throw errorInformation.value;\n    }\n    try {\n      return await successfulResponseHandler({\n        response,\n        url,\n        requestBodyValues: body.values\n      });\n    } catch (error) {\n      if (error instanceof Error) {\n        if (isAbortError(error) || APICallError2.isInstance(error)) {\n          throw error;\n        }\n      }\n      throw new APICallError2({\n        message: \"Failed to process successful response\",\n        cause: error,\n        statusCode: response.status,\n        url,\n        responseHeaders,\n        requestBodyValues: body.values\n      });\n    }\n  } catch (error) {\n    if (isAbortError(error)) {\n      throw error;\n    }\n    if (error instanceof TypeError && error.message === \"fetch failed\") {\n      const cause = error.cause;\n      if (cause != null) {\n        throw new APICallError2({\n          message: `Cannot connect to API: ${cause.message}`,\n          cause,\n          url,\n          requestBodyValues: body.values,\n          isRetryable: true\n          // retry when network error\n        });\n      }\n    }\n    throw error;\n  }\n};\n\n// src/resolve.ts\nasync function resolve(value) {\n  if (typeof value === \"function\") {\n    value = value();\n  }\n  return Promise.resolve(value);\n}\n\n// src/response-handler.ts\nimport { APICallError as APICallError3, EmptyResponseBodyError } from \"@ai-sdk/provider\";\nvar createJsonErrorResponseHandler = ({\n  errorSchema,\n  errorToMessage,\n  isRetryable\n}) => async ({ response, url, requestBodyValues }) => {\n  const responseBody = await response.text();\n  const responseHeaders = extractResponseHeaders(response);\n  if (responseBody.trim() === \"\") {\n    return {\n      responseHeaders,\n      value: new APICallError3({\n        message: response.statusText,\n        url,\n        requestBodyValues,\n        statusCode: response.status,\n        responseHeaders,\n        responseBody,\n        isRetryable: isRetryable == null ? void 0 : isRetryable(response)\n      })\n    };\n  }\n  try {\n    const parsedError = parseJSON({\n      text: responseBody,\n      schema: errorSchema\n    });\n    return {\n      responseHeaders,\n      value: new APICallError3({\n        message: errorToMessage(parsedError),\n        url,\n        requestBodyValues,\n        statusCode: response.status,\n        responseHeaders,\n        responseBody,\n        data: parsedError,\n        isRetryable: isRetryable == null ? void 0 : isRetryable(response, parsedError)\n      })\n    };\n  } catch (parseError) {\n    return {\n      responseHeaders,\n      value: new APICallError3({\n        message: response.statusText,\n        url,\n        requestBodyValues,\n        statusCode: response.status,\n        responseHeaders,\n        responseBody,\n        isRetryable: isRetryable == null ? void 0 : isRetryable(response)\n      })\n    };\n  }\n};\nvar createEventSourceResponseHandler = (chunkSchema) => async ({ response }) => {\n  const responseHeaders = extractResponseHeaders(response);\n  if (response.body == null) {\n    throw new EmptyResponseBodyError({});\n  }\n  return {\n    responseHeaders,\n    value: response.body.pipeThrough(new TextDecoderStream()).pipeThrough(createEventSourceParserStream()).pipeThrough(\n      new TransformStream({\n        transform({ data }, controller) {\n          if (data === \"[DONE]\") {\n            return;\n          }\n          controller.enqueue(\n            safeParseJSON({\n              text: data,\n              schema: chunkSchema\n            })\n          );\n        }\n      })\n    )\n  };\n};\nvar createJsonStreamResponseHandler = (chunkSchema) => async ({ response }) => {\n  const responseHeaders = extractResponseHeaders(response);\n  if (response.body == null) {\n    throw new EmptyResponseBodyError({});\n  }\n  let buffer = \"\";\n  return {\n    responseHeaders,\n    value: response.body.pipeThrough(new TextDecoderStream()).pipeThrough(\n      new TransformStream({\n        transform(chunkText, controller) {\n          if (chunkText.endsWith(\"\\n\")) {\n            controller.enqueue(\n              safeParseJSON({\n                text: buffer + chunkText,\n                schema: chunkSchema\n              })\n            );\n            buffer = \"\";\n          } else {\n            buffer += chunkText;\n          }\n        }\n      })\n    )\n  };\n};\nvar createJsonResponseHandler = (responseSchema) => async ({ response, url, requestBodyValues }) => {\n  const responseBody = await response.text();\n  const parsedResult = safeParseJSON({\n    text: responseBody,\n    schema: responseSchema\n  });\n  const responseHeaders = extractResponseHeaders(response);\n  if (!parsedResult.success) {\n    throw new APICallError3({\n      message: \"Invalid JSON response\",\n      cause: parsedResult.error,\n      statusCode: response.status,\n      responseHeaders,\n      responseBody,\n      url,\n      requestBodyValues\n    });\n  }\n  return {\n    responseHeaders,\n    value: parsedResult.value,\n    rawValue: parsedResult.rawValue\n  };\n};\nvar createBinaryResponseHandler = () => async ({ response, url, requestBodyValues }) => {\n  const responseHeaders = extractResponseHeaders(response);\n  if (!response.body) {\n    throw new APICallError3({\n      message: \"Response body is empty\",\n      url,\n      requestBodyValues,\n      statusCode: response.status,\n      responseHeaders,\n      responseBody: void 0\n    });\n  }\n  try {\n    const buffer = await response.arrayBuffer();\n    return {\n      responseHeaders,\n      value: new Uint8Array(buffer)\n    };\n  } catch (error) {\n    throw new APICallError3({\n      message: \"Failed to read response as array buffer\",\n      url,\n      requestBodyValues,\n      statusCode: response.status,\n      responseHeaders,\n      responseBody: void 0,\n      cause: error\n    });\n  }\n};\nvar createStatusCodeErrorResponseHandler = () => async ({ response, url, requestBodyValues }) => {\n  const responseHeaders = extractResponseHeaders(response);\n  const responseBody = await response.text();\n  return {\n    responseHeaders,\n    value: new APICallError3({\n      message: response.statusText,\n      url,\n      requestBodyValues,\n      statusCode: response.status,\n      responseHeaders,\n      responseBody\n    })\n  };\n};\n\n// src/uint8-utils.ts\nvar { btoa, atob } = globalThis;\nfunction convertBase64ToUint8Array(base64String) {\n  const base64Url = base64String.replace(/-/g, \"+\").replace(/_/g, \"/\");\n  const latin1string = atob(base64Url);\n  return Uint8Array.from(latin1string, (byte) => byte.codePointAt(0));\n}\nfunction convertUint8ArrayToBase64(array) {\n  let latin1string = \"\";\n  for (let i = 0; i < array.length; i++) {\n    latin1string += String.fromCodePoint(array[i]);\n  }\n  return btoa(latin1string);\n}\n\n// src/without-trailing-slash.ts\nfunction withoutTrailingSlash(url) {\n  return url == null ? void 0 : url.replace(/\\/$/, \"\");\n}\nexport {\n  asValidator,\n  combineHeaders,\n  convertAsyncIteratorToReadableStream,\n  convertBase64ToUint8Array,\n  convertUint8ArrayToBase64,\n  createBinaryResponseHandler,\n  createEventSourceParserStream,\n  createEventSourceResponseHandler,\n  createIdGenerator,\n  createJsonErrorResponseHandler,\n  createJsonResponseHandler,\n  createJsonStreamResponseHandler,\n  createStatusCodeErrorResponseHandler,\n  delay,\n  extractResponseHeaders,\n  generateId,\n  getErrorMessage,\n  getFromApi,\n  isAbortError,\n  isParsableJson,\n  isValidator,\n  loadApiKey,\n  loadOptionalSetting,\n  loadSetting,\n  parseJSON,\n  parseProviderOptions,\n  postFormDataToApi,\n  postJsonToApi,\n  postToApi,\n  removeUndefinedEntries,\n  resolve,\n  safeParseJSON,\n  safeValidateTypes,\n  validateTypes,\n  validator,\n  validatorSymbol,\n  withoutTrailingSlash,\n  zodValidator\n};\n//# sourceMappingURL=index.mjs.map","// src/openai-provider.ts\nimport {\n  loadApiKey,\n  withoutTrailingSlash\n} from \"@ai-sdk/provider-utils\";\n\n// src/openai-chat-language-model.ts\nimport {\n  InvalidResponseDataError,\n  UnsupportedFunctionalityError as UnsupportedFunctionalityError3\n} from \"@ai-sdk/provider\";\nimport {\n  combineHeaders,\n  createEventSourceResponseHandler,\n  createJsonResponseHandler,\n  generateId,\n  isParsableJson,\n  postJsonToApi\n} from \"@ai-sdk/provider-utils\";\nimport { z as z2 } from \"zod\";\n\n// src/convert-to-openai-chat-messages.ts\nimport {\n  UnsupportedFunctionalityError\n} from \"@ai-sdk/provider\";\nimport { convertUint8ArrayToBase64 } from \"@ai-sdk/provider-utils\";\nfunction convertToOpenAIChatMessages({\n  prompt,\n  useLegacyFunctionCalling = false,\n  systemMessageMode = \"system\"\n}) {\n  const messages = [];\n  const warnings = [];\n  for (const { role, content } of prompt) {\n    switch (role) {\n      case \"system\": {\n        switch (systemMessageMode) {\n          case \"system\": {\n            messages.push({ role: \"system\", content });\n            break;\n          }\n          case \"developer\": {\n            messages.push({ role: \"developer\", content });\n            break;\n          }\n          case \"remove\": {\n            warnings.push({\n              type: \"other\",\n              message: \"system messages are removed for this model\"\n            });\n            break;\n          }\n          default: {\n            const _exhaustiveCheck = systemMessageMode;\n            throw new Error(\n              `Unsupported system message mode: ${_exhaustiveCheck}`\n            );\n          }\n        }\n        break;\n      }\n      case \"user\": {\n        if (content.length === 1 && content[0].type === \"text\") {\n          messages.push({ role: \"user\", content: content[0].text });\n          break;\n        }\n        messages.push({\n          role: \"user\",\n          content: content.map((part, index) => {\n            var _a, _b, _c, _d;\n            switch (part.type) {\n              case \"text\": {\n                return { type: \"text\", text: part.text };\n              }\n              case \"image\": {\n                return {\n                  type: \"image_url\",\n                  image_url: {\n                    url: part.image instanceof URL ? part.image.toString() : `data:${(_a = part.mimeType) != null ? _a : \"image/jpeg\"};base64,${convertUint8ArrayToBase64(part.image)}`,\n                    // OpenAI specific extension: image detail\n                    detail: (_c = (_b = part.providerMetadata) == null ? void 0 : _b.openai) == null ? void 0 : _c.imageDetail\n                  }\n                };\n              }\n              case \"file\": {\n                if (part.data instanceof URL) {\n                  throw new UnsupportedFunctionalityError({\n                    functionality: \"'File content parts with URL data' functionality not supported.\"\n                  });\n                }\n                switch (part.mimeType) {\n                  case \"audio/wav\": {\n                    return {\n                      type: \"input_audio\",\n                      input_audio: { data: part.data, format: \"wav\" }\n                    };\n                  }\n                  case \"audio/mp3\":\n                  case \"audio/mpeg\": {\n                    return {\n                      type: \"input_audio\",\n                      input_audio: { data: part.data, format: \"mp3\" }\n                    };\n                  }\n                  case \"application/pdf\": {\n                    return {\n                      type: \"file\",\n                      file: {\n                        filename: (_d = part.filename) != null ? _d : `part-${index}.pdf`,\n                        file_data: `data:application/pdf;base64,${part.data}`\n                      }\n                    };\n                  }\n                  default: {\n                    throw new UnsupportedFunctionalityError({\n                      functionality: `File content part type ${part.mimeType} in user messages`\n                    });\n                  }\n                }\n              }\n            }\n          })\n        });\n        break;\n      }\n      case \"assistant\": {\n        let text = \"\";\n        const toolCalls = [];\n        for (const part of content) {\n          switch (part.type) {\n            case \"text\": {\n              text += part.text;\n              break;\n            }\n            case \"tool-call\": {\n              toolCalls.push({\n                id: part.toolCallId,\n                type: \"function\",\n                function: {\n                  name: part.toolName,\n                  arguments: JSON.stringify(part.args)\n                }\n              });\n              break;\n            }\n          }\n        }\n        if (useLegacyFunctionCalling) {\n          if (toolCalls.length > 1) {\n            throw new UnsupportedFunctionalityError({\n              functionality: \"useLegacyFunctionCalling with multiple tool calls in one message\"\n            });\n          }\n          messages.push({\n            role: \"assistant\",\n            content: text,\n            function_call: toolCalls.length > 0 ? toolCalls[0].function : void 0\n          });\n        } else {\n          messages.push({\n            role: \"assistant\",\n            content: text,\n            tool_calls: toolCalls.length > 0 ? toolCalls : void 0\n          });\n        }\n        break;\n      }\n      case \"tool\": {\n        for (const toolResponse of content) {\n          if (useLegacyFunctionCalling) {\n            messages.push({\n              role: \"function\",\n              name: toolResponse.toolName,\n              content: JSON.stringify(toolResponse.result)\n            });\n          } else {\n            messages.push({\n              role: \"tool\",\n              tool_call_id: toolResponse.toolCallId,\n              content: JSON.stringify(toolResponse.result)\n            });\n          }\n        }\n        break;\n      }\n      default: {\n        const _exhaustiveCheck = role;\n        throw new Error(`Unsupported role: ${_exhaustiveCheck}`);\n      }\n    }\n  }\n  return { messages, warnings };\n}\n\n// src/map-openai-chat-logprobs.ts\nfunction mapOpenAIChatLogProbsOutput(logprobs) {\n  var _a, _b;\n  return (_b = (_a = logprobs == null ? void 0 : logprobs.content) == null ? void 0 : _a.map(({ token, logprob, top_logprobs }) => ({\n    token,\n    logprob,\n    topLogprobs: top_logprobs ? top_logprobs.map(({ token: token2, logprob: logprob2 }) => ({\n      token: token2,\n      logprob: logprob2\n    })) : []\n  }))) != null ? _b : void 0;\n}\n\n// src/map-openai-finish-reason.ts\nfunction mapOpenAIFinishReason(finishReason) {\n  switch (finishReason) {\n    case \"stop\":\n      return \"stop\";\n    case \"length\":\n      return \"length\";\n    case \"content_filter\":\n      return \"content-filter\";\n    case \"function_call\":\n    case \"tool_calls\":\n      return \"tool-calls\";\n    default:\n      return \"unknown\";\n  }\n}\n\n// src/openai-error.ts\nimport { z } from \"zod\";\nimport { createJsonErrorResponseHandler } from \"@ai-sdk/provider-utils\";\nvar openaiErrorDataSchema = z.object({\n  error: z.object({\n    message: z.string(),\n    // The additional information below is handled loosely to support\n    // OpenAI-compatible providers that have slightly different error\n    // responses:\n    type: z.string().nullish(),\n    param: z.any().nullish(),\n    code: z.union([z.string(), z.number()]).nullish()\n  })\n});\nvar openaiFailedResponseHandler = createJsonErrorResponseHandler({\n  errorSchema: openaiErrorDataSchema,\n  errorToMessage: (data) => data.error.message\n});\n\n// src/get-response-metadata.ts\nfunction getResponseMetadata({\n  id,\n  model,\n  created\n}) {\n  return {\n    id: id != null ? id : void 0,\n    modelId: model != null ? model : void 0,\n    timestamp: created != null ? new Date(created * 1e3) : void 0\n  };\n}\n\n// src/openai-prepare-tools.ts\nimport {\n  UnsupportedFunctionalityError as UnsupportedFunctionalityError2\n} from \"@ai-sdk/provider\";\nfunction prepareTools({\n  mode,\n  useLegacyFunctionCalling = false,\n  structuredOutputs\n}) {\n  var _a;\n  const tools = ((_a = mode.tools) == null ? void 0 : _a.length) ? mode.tools : void 0;\n  const toolWarnings = [];\n  if (tools == null) {\n    return { tools: void 0, tool_choice: void 0, toolWarnings };\n  }\n  const toolChoice = mode.toolChoice;\n  if (useLegacyFunctionCalling) {\n    const openaiFunctions = [];\n    for (const tool of tools) {\n      if (tool.type === \"provider-defined\") {\n        toolWarnings.push({ type: \"unsupported-tool\", tool });\n      } else {\n        openaiFunctions.push({\n          name: tool.name,\n          description: tool.description,\n          parameters: tool.parameters\n        });\n      }\n    }\n    if (toolChoice == null) {\n      return {\n        functions: openaiFunctions,\n        function_call: void 0,\n        toolWarnings\n      };\n    }\n    const type2 = toolChoice.type;\n    switch (type2) {\n      case \"auto\":\n      case \"none\":\n      case void 0:\n        return {\n          functions: openaiFunctions,\n          function_call: void 0,\n          toolWarnings\n        };\n      case \"required\":\n        throw new UnsupportedFunctionalityError2({\n          functionality: \"useLegacyFunctionCalling and toolChoice: required\"\n        });\n      default:\n        return {\n          functions: openaiFunctions,\n          function_call: { name: toolChoice.toolName },\n          toolWarnings\n        };\n    }\n  }\n  const openaiTools2 = [];\n  for (const tool of tools) {\n    if (tool.type === \"provider-defined\") {\n      toolWarnings.push({ type: \"unsupported-tool\", tool });\n    } else {\n      openaiTools2.push({\n        type: \"function\",\n        function: {\n          name: tool.name,\n          description: tool.description,\n          parameters: tool.parameters,\n          strict: structuredOutputs ? true : void 0\n        }\n      });\n    }\n  }\n  if (toolChoice == null) {\n    return { tools: openaiTools2, tool_choice: void 0, toolWarnings };\n  }\n  const type = toolChoice.type;\n  switch (type) {\n    case \"auto\":\n    case \"none\":\n    case \"required\":\n      return { tools: openaiTools2, tool_choice: type, toolWarnings };\n    case \"tool\":\n      return {\n        tools: openaiTools2,\n        tool_choice: {\n          type: \"function\",\n          function: {\n            name: toolChoice.toolName\n          }\n        },\n        toolWarnings\n      };\n    default: {\n      const _exhaustiveCheck = type;\n      throw new UnsupportedFunctionalityError2({\n        functionality: `Unsupported tool choice type: ${_exhaustiveCheck}`\n      });\n    }\n  }\n}\n\n// src/openai-chat-language-model.ts\nvar OpenAIChatLanguageModel = class {\n  constructor(modelId, settings, config) {\n    this.specificationVersion = \"v1\";\n    this.modelId = modelId;\n    this.settings = settings;\n    this.config = config;\n  }\n  get supportsStructuredOutputs() {\n    var _a;\n    return (_a = this.settings.structuredOutputs) != null ? _a : isReasoningModel(this.modelId);\n  }\n  get defaultObjectGenerationMode() {\n    if (isAudioModel(this.modelId)) {\n      return \"tool\";\n    }\n    return this.supportsStructuredOutputs ? \"json\" : \"tool\";\n  }\n  get provider() {\n    return this.config.provider;\n  }\n  get supportsImageUrls() {\n    return !this.settings.downloadImages;\n  }\n  getArgs({\n    mode,\n    prompt,\n    maxTokens,\n    temperature,\n    topP,\n    topK,\n    frequencyPenalty,\n    presencePenalty,\n    stopSequences,\n    responseFormat,\n    seed,\n    providerMetadata\n  }) {\n    var _a, _b, _c, _d, _e, _f, _g, _h;\n    const type = mode.type;\n    const warnings = [];\n    if (topK != null) {\n      warnings.push({\n        type: \"unsupported-setting\",\n        setting: \"topK\"\n      });\n    }\n    if ((responseFormat == null ? void 0 : responseFormat.type) === \"json\" && responseFormat.schema != null && !this.supportsStructuredOutputs) {\n      warnings.push({\n        type: \"unsupported-setting\",\n        setting: \"responseFormat\",\n        details: \"JSON response format schema is only supported with structuredOutputs\"\n      });\n    }\n    const useLegacyFunctionCalling = this.settings.useLegacyFunctionCalling;\n    if (useLegacyFunctionCalling && this.settings.parallelToolCalls === true) {\n      throw new UnsupportedFunctionalityError3({\n        functionality: \"useLegacyFunctionCalling with parallelToolCalls\"\n      });\n    }\n    if (useLegacyFunctionCalling && this.supportsStructuredOutputs) {\n      throw new UnsupportedFunctionalityError3({\n        functionality: \"structuredOutputs with useLegacyFunctionCalling\"\n      });\n    }\n    const { messages, warnings: messageWarnings } = convertToOpenAIChatMessages(\n      {\n        prompt,\n        useLegacyFunctionCalling,\n        systemMessageMode: getSystemMessageMode(this.modelId)\n      }\n    );\n    warnings.push(...messageWarnings);\n    const baseArgs = {\n      // model id:\n      model: this.modelId,\n      // model specific settings:\n      logit_bias: this.settings.logitBias,\n      logprobs: this.settings.logprobs === true || typeof this.settings.logprobs === \"number\" ? true : void 0,\n      top_logprobs: typeof this.settings.logprobs === \"number\" ? this.settings.logprobs : typeof this.settings.logprobs === \"boolean\" ? this.settings.logprobs ? 0 : void 0 : void 0,\n      user: this.settings.user,\n      parallel_tool_calls: this.settings.parallelToolCalls,\n      // standardized settings:\n      max_tokens: maxTokens,\n      temperature,\n      top_p: topP,\n      frequency_penalty: frequencyPenalty,\n      presence_penalty: presencePenalty,\n      response_format: (responseFormat == null ? void 0 : responseFormat.type) === \"json\" ? this.supportsStructuredOutputs && responseFormat.schema != null ? {\n        type: \"json_schema\",\n        json_schema: {\n          schema: responseFormat.schema,\n          strict: true,\n          name: (_a = responseFormat.name) != null ? _a : \"response\",\n          description: responseFormat.description\n        }\n      } : { type: \"json_object\" } : void 0,\n      stop: stopSequences,\n      seed,\n      // openai specific settings:\n      // TODO remove in next major version; we auto-map maxTokens now\n      max_completion_tokens: (_b = providerMetadata == null ? void 0 : providerMetadata.openai) == null ? void 0 : _b.maxCompletionTokens,\n      store: (_c = providerMetadata == null ? void 0 : providerMetadata.openai) == null ? void 0 : _c.store,\n      metadata: (_d = providerMetadata == null ? void 0 : providerMetadata.openai) == null ? void 0 : _d.metadata,\n      prediction: (_e = providerMetadata == null ? void 0 : providerMetadata.openai) == null ? void 0 : _e.prediction,\n      reasoning_effort: (_g = (_f = providerMetadata == null ? void 0 : providerMetadata.openai) == null ? void 0 : _f.reasoningEffort) != null ? _g : this.settings.reasoningEffort,\n      // messages:\n      messages\n    };\n    if (isReasoningModel(this.modelId)) {\n      if (baseArgs.temperature != null) {\n        baseArgs.temperature = void 0;\n        warnings.push({\n          type: \"unsupported-setting\",\n          setting: \"temperature\",\n          details: \"temperature is not supported for reasoning models\"\n        });\n      }\n      if (baseArgs.top_p != null) {\n        baseArgs.top_p = void 0;\n        warnings.push({\n          type: \"unsupported-setting\",\n          setting: \"topP\",\n          details: \"topP is not supported for reasoning models\"\n        });\n      }\n      if (baseArgs.frequency_penalty != null) {\n        baseArgs.frequency_penalty = void 0;\n        warnings.push({\n          type: \"unsupported-setting\",\n          setting: \"frequencyPenalty\",\n          details: \"frequencyPenalty is not supported for reasoning models\"\n        });\n      }\n      if (baseArgs.presence_penalty != null) {\n        baseArgs.presence_penalty = void 0;\n        warnings.push({\n          type: \"unsupported-setting\",\n          setting: \"presencePenalty\",\n          details: \"presencePenalty is not supported for reasoning models\"\n        });\n      }\n      if (baseArgs.logit_bias != null) {\n        baseArgs.logit_bias = void 0;\n        warnings.push({\n          type: \"other\",\n          message: \"logitBias is not supported for reasoning models\"\n        });\n      }\n      if (baseArgs.logprobs != null) {\n        baseArgs.logprobs = void 0;\n        warnings.push({\n          type: \"other\",\n          message: \"logprobs is not supported for reasoning models\"\n        });\n      }\n      if (baseArgs.top_logprobs != null) {\n        baseArgs.top_logprobs = void 0;\n        warnings.push({\n          type: \"other\",\n          message: \"topLogprobs is not supported for reasoning models\"\n        });\n      }\n      if (baseArgs.max_tokens != null) {\n        if (baseArgs.max_completion_tokens == null) {\n          baseArgs.max_completion_tokens = baseArgs.max_tokens;\n        }\n        baseArgs.max_tokens = void 0;\n      }\n    } else if (this.modelId.startsWith(\"gpt-4o-search-preview\") || this.modelId.startsWith(\"gpt-4o-mini-search-preview\")) {\n      if (baseArgs.temperature != null) {\n        baseArgs.temperature = void 0;\n        warnings.push({\n          type: \"unsupported-setting\",\n          setting: \"temperature\",\n          details: \"temperature is not supported for the search preview models and has been removed.\"\n        });\n      }\n    }\n    switch (type) {\n      case \"regular\": {\n        const { tools, tool_choice, functions, function_call, toolWarnings } = prepareTools({\n          mode,\n          useLegacyFunctionCalling,\n          structuredOutputs: this.supportsStructuredOutputs\n        });\n        return {\n          args: {\n            ...baseArgs,\n            tools,\n            tool_choice,\n            functions,\n            function_call\n          },\n          warnings: [...warnings, ...toolWarnings]\n        };\n      }\n      case \"object-json\": {\n        return {\n          args: {\n            ...baseArgs,\n            response_format: this.supportsStructuredOutputs && mode.schema != null ? {\n              type: \"json_schema\",\n              json_schema: {\n                schema: mode.schema,\n                strict: true,\n                name: (_h = mode.name) != null ? _h : \"response\",\n                description: mode.description\n              }\n            } : { type: \"json_object\" }\n          },\n          warnings\n        };\n      }\n      case \"object-tool\": {\n        return {\n          args: useLegacyFunctionCalling ? {\n            ...baseArgs,\n            function_call: {\n              name: mode.tool.name\n            },\n            functions: [\n              {\n                name: mode.tool.name,\n                description: mode.tool.description,\n                parameters: mode.tool.parameters\n              }\n            ]\n          } : {\n            ...baseArgs,\n            tool_choice: {\n              type: \"function\",\n              function: { name: mode.tool.name }\n            },\n            tools: [\n              {\n                type: \"function\",\n                function: {\n                  name: mode.tool.name,\n                  description: mode.tool.description,\n                  parameters: mode.tool.parameters,\n                  strict: this.supportsStructuredOutputs ? true : void 0\n                }\n              }\n            ]\n          },\n          warnings\n        };\n      }\n      default: {\n        const _exhaustiveCheck = type;\n        throw new Error(`Unsupported type: ${_exhaustiveCheck}`);\n      }\n    }\n  }\n  async doGenerate(options) {\n    var _a, _b, _c, _d, _e, _f, _g, _h;\n    const { args: body, warnings } = this.getArgs(options);\n    const {\n      responseHeaders,\n      value: response,\n      rawValue: rawResponse\n    } = await postJsonToApi({\n      url: this.config.url({\n        path: \"/chat/completions\",\n        modelId: this.modelId\n      }),\n      headers: combineHeaders(this.config.headers(), options.headers),\n      body,\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createJsonResponseHandler(\n        openaiChatResponseSchema\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch\n    });\n    const { messages: rawPrompt, ...rawSettings } = body;\n    const choice = response.choices[0];\n    const completionTokenDetails = (_a = response.usage) == null ? void 0 : _a.completion_tokens_details;\n    const promptTokenDetails = (_b = response.usage) == null ? void 0 : _b.prompt_tokens_details;\n    const providerMetadata = { openai: {} };\n    if ((completionTokenDetails == null ? void 0 : completionTokenDetails.reasoning_tokens) != null) {\n      providerMetadata.openai.reasoningTokens = completionTokenDetails == null ? void 0 : completionTokenDetails.reasoning_tokens;\n    }\n    if ((completionTokenDetails == null ? void 0 : completionTokenDetails.accepted_prediction_tokens) != null) {\n      providerMetadata.openai.acceptedPredictionTokens = completionTokenDetails == null ? void 0 : completionTokenDetails.accepted_prediction_tokens;\n    }\n    if ((completionTokenDetails == null ? void 0 : completionTokenDetails.rejected_prediction_tokens) != null) {\n      providerMetadata.openai.rejectedPredictionTokens = completionTokenDetails == null ? void 0 : completionTokenDetails.rejected_prediction_tokens;\n    }\n    if ((promptTokenDetails == null ? void 0 : promptTokenDetails.cached_tokens) != null) {\n      providerMetadata.openai.cachedPromptTokens = promptTokenDetails == null ? void 0 : promptTokenDetails.cached_tokens;\n    }\n    return {\n      text: (_c = choice.message.content) != null ? _c : void 0,\n      toolCalls: this.settings.useLegacyFunctionCalling && choice.message.function_call ? [\n        {\n          toolCallType: \"function\",\n          toolCallId: generateId(),\n          toolName: choice.message.function_call.name,\n          args: choice.message.function_call.arguments\n        }\n      ] : (_d = choice.message.tool_calls) == null ? void 0 : _d.map((toolCall) => {\n        var _a2;\n        return {\n          toolCallType: \"function\",\n          toolCallId: (_a2 = toolCall.id) != null ? _a2 : generateId(),\n          toolName: toolCall.function.name,\n          args: toolCall.function.arguments\n        };\n      }),\n      finishReason: mapOpenAIFinishReason(choice.finish_reason),\n      usage: {\n        promptTokens: (_f = (_e = response.usage) == null ? void 0 : _e.prompt_tokens) != null ? _f : NaN,\n        completionTokens: (_h = (_g = response.usage) == null ? void 0 : _g.completion_tokens) != null ? _h : NaN\n      },\n      rawCall: { rawPrompt, rawSettings },\n      rawResponse: { headers: responseHeaders, body: rawResponse },\n      request: { body: JSON.stringify(body) },\n      response: getResponseMetadata(response),\n      warnings,\n      logprobs: mapOpenAIChatLogProbsOutput(choice.logprobs),\n      providerMetadata\n    };\n  }\n  async doStream(options) {\n    if (this.settings.simulateStreaming) {\n      const result = await this.doGenerate(options);\n      const simulatedStream = new ReadableStream({\n        start(controller) {\n          controller.enqueue({ type: \"response-metadata\", ...result.response });\n          if (result.text) {\n            controller.enqueue({\n              type: \"text-delta\",\n              textDelta: result.text\n            });\n          }\n          if (result.toolCalls) {\n            for (const toolCall of result.toolCalls) {\n              controller.enqueue({\n                type: \"tool-call-delta\",\n                toolCallType: \"function\",\n                toolCallId: toolCall.toolCallId,\n                toolName: toolCall.toolName,\n                argsTextDelta: toolCall.args\n              });\n              controller.enqueue({\n                type: \"tool-call\",\n                ...toolCall\n              });\n            }\n          }\n          controller.enqueue({\n            type: \"finish\",\n            finishReason: result.finishReason,\n            usage: result.usage,\n            logprobs: result.logprobs,\n            providerMetadata: result.providerMetadata\n          });\n          controller.close();\n        }\n      });\n      return {\n        stream: simulatedStream,\n        rawCall: result.rawCall,\n        rawResponse: result.rawResponse,\n        warnings: result.warnings\n      };\n    }\n    const { args, warnings } = this.getArgs(options);\n    const body = {\n      ...args,\n      stream: true,\n      // only include stream_options when in strict compatibility mode:\n      stream_options: this.config.compatibility === \"strict\" ? { include_usage: true } : void 0\n    };\n    const { responseHeaders, value: response } = await postJsonToApi({\n      url: this.config.url({\n        path: \"/chat/completions\",\n        modelId: this.modelId\n      }),\n      headers: combineHeaders(this.config.headers(), options.headers),\n      body,\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createEventSourceResponseHandler(\n        openaiChatChunkSchema\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch\n    });\n    const { messages: rawPrompt, ...rawSettings } = args;\n    const toolCalls = [];\n    let finishReason = \"unknown\";\n    let usage = {\n      promptTokens: void 0,\n      completionTokens: void 0\n    };\n    let logprobs;\n    let isFirstChunk = true;\n    const { useLegacyFunctionCalling } = this.settings;\n    const providerMetadata = { openai: {} };\n    return {\n      stream: response.pipeThrough(\n        new TransformStream({\n          transform(chunk, controller) {\n            var _a, _b, _c, _d, _e, _f, _g, _h, _i, _j, _k, _l;\n            if (!chunk.success) {\n              finishReason = \"error\";\n              controller.enqueue({ type: \"error\", error: chunk.error });\n              return;\n            }\n            const value = chunk.value;\n            if (\"error\" in value) {\n              finishReason = \"error\";\n              controller.enqueue({ type: \"error\", error: value.error });\n              return;\n            }\n            if (isFirstChunk) {\n              isFirstChunk = false;\n              controller.enqueue({\n                type: \"response-metadata\",\n                ...getResponseMetadata(value)\n              });\n            }\n            if (value.usage != null) {\n              const {\n                prompt_tokens,\n                completion_tokens,\n                prompt_tokens_details,\n                completion_tokens_details\n              } = value.usage;\n              usage = {\n                promptTokens: prompt_tokens != null ? prompt_tokens : void 0,\n                completionTokens: completion_tokens != null ? completion_tokens : void 0\n              };\n              if ((completion_tokens_details == null ? void 0 : completion_tokens_details.reasoning_tokens) != null) {\n                providerMetadata.openai.reasoningTokens = completion_tokens_details == null ? void 0 : completion_tokens_details.reasoning_tokens;\n              }\n              if ((completion_tokens_details == null ? void 0 : completion_tokens_details.accepted_prediction_tokens) != null) {\n                providerMetadata.openai.acceptedPredictionTokens = completion_tokens_details == null ? void 0 : completion_tokens_details.accepted_prediction_tokens;\n              }\n              if ((completion_tokens_details == null ? void 0 : completion_tokens_details.rejected_prediction_tokens) != null) {\n                providerMetadata.openai.rejectedPredictionTokens = completion_tokens_details == null ? void 0 : completion_tokens_details.rejected_prediction_tokens;\n              }\n              if ((prompt_tokens_details == null ? void 0 : prompt_tokens_details.cached_tokens) != null) {\n                providerMetadata.openai.cachedPromptTokens = prompt_tokens_details == null ? void 0 : prompt_tokens_details.cached_tokens;\n              }\n            }\n            const choice = value.choices[0];\n            if ((choice == null ? void 0 : choice.finish_reason) != null) {\n              finishReason = mapOpenAIFinishReason(choice.finish_reason);\n            }\n            if ((choice == null ? void 0 : choice.delta) == null) {\n              return;\n            }\n            const delta = choice.delta;\n            if (delta.content != null) {\n              controller.enqueue({\n                type: \"text-delta\",\n                textDelta: delta.content\n              });\n            }\n            const mappedLogprobs = mapOpenAIChatLogProbsOutput(\n              choice == null ? void 0 : choice.logprobs\n            );\n            if (mappedLogprobs == null ? void 0 : mappedLogprobs.length) {\n              if (logprobs === void 0) logprobs = [];\n              logprobs.push(...mappedLogprobs);\n            }\n            const mappedToolCalls = useLegacyFunctionCalling && delta.function_call != null ? [\n              {\n                type: \"function\",\n                id: generateId(),\n                function: delta.function_call,\n                index: 0\n              }\n            ] : delta.tool_calls;\n            if (mappedToolCalls != null) {\n              for (const toolCallDelta of mappedToolCalls) {\n                const index = toolCallDelta.index;\n                if (toolCalls[index] == null) {\n                  if (toolCallDelta.type !== \"function\") {\n                    throw new InvalidResponseDataError({\n                      data: toolCallDelta,\n                      message: `Expected 'function' type.`\n                    });\n                  }\n                  if (toolCallDelta.id == null) {\n                    throw new InvalidResponseDataError({\n                      data: toolCallDelta,\n                      message: `Expected 'id' to be a string.`\n                    });\n                  }\n                  if (((_a = toolCallDelta.function) == null ? void 0 : _a.name) == null) {\n                    throw new InvalidResponseDataError({\n                      data: toolCallDelta,\n                      message: `Expected 'function.name' to be a string.`\n                    });\n                  }\n                  toolCalls[index] = {\n                    id: toolCallDelta.id,\n                    type: \"function\",\n                    function: {\n                      name: toolCallDelta.function.name,\n                      arguments: (_b = toolCallDelta.function.arguments) != null ? _b : \"\"\n                    },\n                    hasFinished: false\n                  };\n                  const toolCall2 = toolCalls[index];\n                  if (((_c = toolCall2.function) == null ? void 0 : _c.name) != null && ((_d = toolCall2.function) == null ? void 0 : _d.arguments) != null) {\n                    if (toolCall2.function.arguments.length > 0) {\n                      controller.enqueue({\n                        type: \"tool-call-delta\",\n                        toolCallType: \"function\",\n                        toolCallId: toolCall2.id,\n                        toolName: toolCall2.function.name,\n                        argsTextDelta: toolCall2.function.arguments\n                      });\n                    }\n                    if (isParsableJson(toolCall2.function.arguments)) {\n                      controller.enqueue({\n                        type: \"tool-call\",\n                        toolCallType: \"function\",\n                        toolCallId: (_e = toolCall2.id) != null ? _e : generateId(),\n                        toolName: toolCall2.function.name,\n                        args: toolCall2.function.arguments\n                      });\n                      toolCall2.hasFinished = true;\n                    }\n                  }\n                  continue;\n                }\n                const toolCall = toolCalls[index];\n                if (toolCall.hasFinished) {\n                  continue;\n                }\n                if (((_f = toolCallDelta.function) == null ? void 0 : _f.arguments) != null) {\n                  toolCall.function.arguments += (_h = (_g = toolCallDelta.function) == null ? void 0 : _g.arguments) != null ? _h : \"\";\n                }\n                controller.enqueue({\n                  type: \"tool-call-delta\",\n                  toolCallType: \"function\",\n                  toolCallId: toolCall.id,\n                  toolName: toolCall.function.name,\n                  argsTextDelta: (_i = toolCallDelta.function.arguments) != null ? _i : \"\"\n                });\n                if (((_j = toolCall.function) == null ? void 0 : _j.name) != null && ((_k = toolCall.function) == null ? void 0 : _k.arguments) != null && isParsableJson(toolCall.function.arguments)) {\n                  controller.enqueue({\n                    type: \"tool-call\",\n                    toolCallType: \"function\",\n                    toolCallId: (_l = toolCall.id) != null ? _l : generateId(),\n                    toolName: toolCall.function.name,\n                    args: toolCall.function.arguments\n                  });\n                  toolCall.hasFinished = true;\n                }\n              }\n            }\n          },\n          flush(controller) {\n            var _a, _b;\n            controller.enqueue({\n              type: \"finish\",\n              finishReason,\n              logprobs,\n              usage: {\n                promptTokens: (_a = usage.promptTokens) != null ? _a : NaN,\n                completionTokens: (_b = usage.completionTokens) != null ? _b : NaN\n              },\n              ...providerMetadata != null ? { providerMetadata } : {}\n            });\n          }\n        })\n      ),\n      rawCall: { rawPrompt, rawSettings },\n      rawResponse: { headers: responseHeaders },\n      request: { body: JSON.stringify(body) },\n      warnings\n    };\n  }\n};\nvar openaiTokenUsageSchema = z2.object({\n  prompt_tokens: z2.number().nullish(),\n  completion_tokens: z2.number().nullish(),\n  prompt_tokens_details: z2.object({\n    cached_tokens: z2.number().nullish()\n  }).nullish(),\n  completion_tokens_details: z2.object({\n    reasoning_tokens: z2.number().nullish(),\n    accepted_prediction_tokens: z2.number().nullish(),\n    rejected_prediction_tokens: z2.number().nullish()\n  }).nullish()\n}).nullish();\nvar openaiChatResponseSchema = z2.object({\n  id: z2.string().nullish(),\n  created: z2.number().nullish(),\n  model: z2.string().nullish(),\n  choices: z2.array(\n    z2.object({\n      message: z2.object({\n        role: z2.literal(\"assistant\").nullish(),\n        content: z2.string().nullish(),\n        function_call: z2.object({\n          arguments: z2.string(),\n          name: z2.string()\n        }).nullish(),\n        tool_calls: z2.array(\n          z2.object({\n            id: z2.string().nullish(),\n            type: z2.literal(\"function\"),\n            function: z2.object({\n              name: z2.string(),\n              arguments: z2.string()\n            })\n          })\n        ).nullish()\n      }),\n      index: z2.number(),\n      logprobs: z2.object({\n        content: z2.array(\n          z2.object({\n            token: z2.string(),\n            logprob: z2.number(),\n            top_logprobs: z2.array(\n              z2.object({\n                token: z2.string(),\n                logprob: z2.number()\n              })\n            )\n          })\n        ).nullable()\n      }).nullish(),\n      finish_reason: z2.string().nullish()\n    })\n  ),\n  usage: openaiTokenUsageSchema\n});\nvar openaiChatChunkSchema = z2.union([\n  z2.object({\n    id: z2.string().nullish(),\n    created: z2.number().nullish(),\n    model: z2.string().nullish(),\n    choices: z2.array(\n      z2.object({\n        delta: z2.object({\n          role: z2.enum([\"assistant\"]).nullish(),\n          content: z2.string().nullish(),\n          function_call: z2.object({\n            name: z2.string().optional(),\n            arguments: z2.string().optional()\n          }).nullish(),\n          tool_calls: z2.array(\n            z2.object({\n              index: z2.number(),\n              id: z2.string().nullish(),\n              type: z2.literal(\"function\").nullish(),\n              function: z2.object({\n                name: z2.string().nullish(),\n                arguments: z2.string().nullish()\n              })\n            })\n          ).nullish()\n        }).nullish(),\n        logprobs: z2.object({\n          content: z2.array(\n            z2.object({\n              token: z2.string(),\n              logprob: z2.number(),\n              top_logprobs: z2.array(\n                z2.object({\n                  token: z2.string(),\n                  logprob: z2.number()\n                })\n              )\n            })\n          ).nullable()\n        }).nullish(),\n        finish_reason: z2.string().nullish(),\n        index: z2.number()\n      })\n    ),\n    usage: openaiTokenUsageSchema\n  }),\n  openaiErrorDataSchema\n]);\nfunction isReasoningModel(modelId) {\n  return modelId.startsWith(\"o\") || modelId.startsWith(\"gpt-5\");\n}\nfunction isAudioModel(modelId) {\n  return modelId.startsWith(\"gpt-4o-audio-preview\");\n}\nfunction getSystemMessageMode(modelId) {\n  var _a, _b;\n  if (!isReasoningModel(modelId)) {\n    return \"system\";\n  }\n  return (_b = (_a = reasoningModels[modelId]) == null ? void 0 : _a.systemMessageMode) != null ? _b : \"developer\";\n}\nvar reasoningModels = {\n  \"o1-mini\": {\n    systemMessageMode: \"remove\"\n  },\n  \"o1-mini-2024-09-12\": {\n    systemMessageMode: \"remove\"\n  },\n  \"o1-preview\": {\n    systemMessageMode: \"remove\"\n  },\n  \"o1-preview-2024-09-12\": {\n    systemMessageMode: \"remove\"\n  },\n  o3: {\n    systemMessageMode: \"developer\"\n  },\n  \"o3-2025-04-16\": {\n    systemMessageMode: \"developer\"\n  },\n  \"o3-mini\": {\n    systemMessageMode: \"developer\"\n  },\n  \"o3-mini-2025-01-31\": {\n    systemMessageMode: \"developer\"\n  },\n  \"o4-mini\": {\n    systemMessageMode: \"developer\"\n  },\n  \"o4-mini-2025-04-16\": {\n    systemMessageMode: \"developer\"\n  }\n};\n\n// src/openai-completion-language-model.ts\nimport {\n  UnsupportedFunctionalityError as UnsupportedFunctionalityError5\n} from \"@ai-sdk/provider\";\nimport {\n  combineHeaders as combineHeaders2,\n  createEventSourceResponseHandler as createEventSourceResponseHandler2,\n  createJsonResponseHandler as createJsonResponseHandler2,\n  postJsonToApi as postJsonToApi2\n} from \"@ai-sdk/provider-utils\";\nimport { z as z3 } from \"zod\";\n\n// src/convert-to-openai-completion-prompt.ts\nimport {\n  InvalidPromptError,\n  UnsupportedFunctionalityError as UnsupportedFunctionalityError4\n} from \"@ai-sdk/provider\";\nfunction convertToOpenAICompletionPrompt({\n  prompt,\n  inputFormat,\n  user = \"user\",\n  assistant = \"assistant\"\n}) {\n  if (inputFormat === \"prompt\" && prompt.length === 1 && prompt[0].role === \"user\" && prompt[0].content.length === 1 && prompt[0].content[0].type === \"text\") {\n    return { prompt: prompt[0].content[0].text };\n  }\n  let text = \"\";\n  if (prompt[0].role === \"system\") {\n    text += `${prompt[0].content}\n\n`;\n    prompt = prompt.slice(1);\n  }\n  for (const { role, content } of prompt) {\n    switch (role) {\n      case \"system\": {\n        throw new InvalidPromptError({\n          message: \"Unexpected system message in prompt: ${content}\",\n          prompt\n        });\n      }\n      case \"user\": {\n        const userMessage = content.map((part) => {\n          switch (part.type) {\n            case \"text\": {\n              return part.text;\n            }\n            case \"image\": {\n              throw new UnsupportedFunctionalityError4({\n                functionality: \"images\"\n              });\n            }\n          }\n        }).join(\"\");\n        text += `${user}:\n${userMessage}\n\n`;\n        break;\n      }\n      case \"assistant\": {\n        const assistantMessage = content.map((part) => {\n          switch (part.type) {\n            case \"text\": {\n              return part.text;\n            }\n            case \"tool-call\": {\n              throw new UnsupportedFunctionalityError4({\n                functionality: \"tool-call messages\"\n              });\n            }\n          }\n        }).join(\"\");\n        text += `${assistant}:\n${assistantMessage}\n\n`;\n        break;\n      }\n      case \"tool\": {\n        throw new UnsupportedFunctionalityError4({\n          functionality: \"tool messages\"\n        });\n      }\n      default: {\n        const _exhaustiveCheck = role;\n        throw new Error(`Unsupported role: ${_exhaustiveCheck}`);\n      }\n    }\n  }\n  text += `${assistant}:\n`;\n  return {\n    prompt: text,\n    stopSequences: [`\n${user}:`]\n  };\n}\n\n// src/map-openai-completion-logprobs.ts\nfunction mapOpenAICompletionLogProbs(logprobs) {\n  return logprobs == null ? void 0 : logprobs.tokens.map((token, index) => ({\n    token,\n    logprob: logprobs.token_logprobs[index],\n    topLogprobs: logprobs.top_logprobs ? Object.entries(logprobs.top_logprobs[index]).map(\n      ([token2, logprob]) => ({\n        token: token2,\n        logprob\n      })\n    ) : []\n  }));\n}\n\n// src/openai-completion-language-model.ts\nvar OpenAICompletionLanguageModel = class {\n  constructor(modelId, settings, config) {\n    this.specificationVersion = \"v1\";\n    this.defaultObjectGenerationMode = void 0;\n    this.modelId = modelId;\n    this.settings = settings;\n    this.config = config;\n  }\n  get provider() {\n    return this.config.provider;\n  }\n  getArgs({\n    mode,\n    inputFormat,\n    prompt,\n    maxTokens,\n    temperature,\n    topP,\n    topK,\n    frequencyPenalty,\n    presencePenalty,\n    stopSequences: userStopSequences,\n    responseFormat,\n    seed\n  }) {\n    var _a;\n    const type = mode.type;\n    const warnings = [];\n    if (topK != null) {\n      warnings.push({\n        type: \"unsupported-setting\",\n        setting: \"topK\"\n      });\n    }\n    if (responseFormat != null && responseFormat.type !== \"text\") {\n      warnings.push({\n        type: \"unsupported-setting\",\n        setting: \"responseFormat\",\n        details: \"JSON response format is not supported.\"\n      });\n    }\n    const { prompt: completionPrompt, stopSequences } = convertToOpenAICompletionPrompt({ prompt, inputFormat });\n    const stop = [...stopSequences != null ? stopSequences : [], ...userStopSequences != null ? userStopSequences : []];\n    const baseArgs = {\n      // model id:\n      model: this.modelId,\n      // model specific settings:\n      echo: this.settings.echo,\n      logit_bias: this.settings.logitBias,\n      logprobs: typeof this.settings.logprobs === \"number\" ? this.settings.logprobs : typeof this.settings.logprobs === \"boolean\" ? this.settings.logprobs ? 0 : void 0 : void 0,\n      suffix: this.settings.suffix,\n      user: this.settings.user,\n      // standardized settings:\n      max_tokens: maxTokens,\n      temperature,\n      top_p: topP,\n      frequency_penalty: frequencyPenalty,\n      presence_penalty: presencePenalty,\n      seed,\n      // prompt:\n      prompt: completionPrompt,\n      // stop sequences:\n      stop: stop.length > 0 ? stop : void 0\n    };\n    switch (type) {\n      case \"regular\": {\n        if ((_a = mode.tools) == null ? void 0 : _a.length) {\n          throw new UnsupportedFunctionalityError5({\n            functionality: \"tools\"\n          });\n        }\n        if (mode.toolChoice) {\n          throw new UnsupportedFunctionalityError5({\n            functionality: \"toolChoice\"\n          });\n        }\n        return { args: baseArgs, warnings };\n      }\n      case \"object-json\": {\n        throw new UnsupportedFunctionalityError5({\n          functionality: \"object-json mode\"\n        });\n      }\n      case \"object-tool\": {\n        throw new UnsupportedFunctionalityError5({\n          functionality: \"object-tool mode\"\n        });\n      }\n      default: {\n        const _exhaustiveCheck = type;\n        throw new Error(`Unsupported type: ${_exhaustiveCheck}`);\n      }\n    }\n  }\n  async doGenerate(options) {\n    const { args, warnings } = this.getArgs(options);\n    const {\n      responseHeaders,\n      value: response,\n      rawValue: rawResponse\n    } = await postJsonToApi2({\n      url: this.config.url({\n        path: \"/completions\",\n        modelId: this.modelId\n      }),\n      headers: combineHeaders2(this.config.headers(), options.headers),\n      body: args,\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createJsonResponseHandler2(\n        openaiCompletionResponseSchema\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch\n    });\n    const { prompt: rawPrompt, ...rawSettings } = args;\n    const choice = response.choices[0];\n    return {\n      text: choice.text,\n      usage: {\n        promptTokens: response.usage.prompt_tokens,\n        completionTokens: response.usage.completion_tokens\n      },\n      finishReason: mapOpenAIFinishReason(choice.finish_reason),\n      logprobs: mapOpenAICompletionLogProbs(choice.logprobs),\n      rawCall: { rawPrompt, rawSettings },\n      rawResponse: { headers: responseHeaders, body: rawResponse },\n      response: getResponseMetadata(response),\n      warnings,\n      request: { body: JSON.stringify(args) }\n    };\n  }\n  async doStream(options) {\n    const { args, warnings } = this.getArgs(options);\n    const body = {\n      ...args,\n      stream: true,\n      // only include stream_options when in strict compatibility mode:\n      stream_options: this.config.compatibility === \"strict\" ? { include_usage: true } : void 0\n    };\n    const { responseHeaders, value: response } = await postJsonToApi2({\n      url: this.config.url({\n        path: \"/completions\",\n        modelId: this.modelId\n      }),\n      headers: combineHeaders2(this.config.headers(), options.headers),\n      body,\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createEventSourceResponseHandler2(\n        openaiCompletionChunkSchema\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch\n    });\n    const { prompt: rawPrompt, ...rawSettings } = args;\n    let finishReason = \"unknown\";\n    let usage = {\n      promptTokens: Number.NaN,\n      completionTokens: Number.NaN\n    };\n    let logprobs;\n    let isFirstChunk = true;\n    return {\n      stream: response.pipeThrough(\n        new TransformStream({\n          transform(chunk, controller) {\n            if (!chunk.success) {\n              finishReason = \"error\";\n              controller.enqueue({ type: \"error\", error: chunk.error });\n              return;\n            }\n            const value = chunk.value;\n            if (\"error\" in value) {\n              finishReason = \"error\";\n              controller.enqueue({ type: \"error\", error: value.error });\n              return;\n            }\n            if (isFirstChunk) {\n              isFirstChunk = false;\n              controller.enqueue({\n                type: \"response-metadata\",\n                ...getResponseMetadata(value)\n              });\n            }\n            if (value.usage != null) {\n              usage = {\n                promptTokens: value.usage.prompt_tokens,\n                completionTokens: value.usage.completion_tokens\n              };\n            }\n            const choice = value.choices[0];\n            if ((choice == null ? void 0 : choice.finish_reason) != null) {\n              finishReason = mapOpenAIFinishReason(choice.finish_reason);\n            }\n            if ((choice == null ? void 0 : choice.text) != null) {\n              controller.enqueue({\n                type: \"text-delta\",\n                textDelta: choice.text\n              });\n            }\n            const mappedLogprobs = mapOpenAICompletionLogProbs(\n              choice == null ? void 0 : choice.logprobs\n            );\n            if (mappedLogprobs == null ? void 0 : mappedLogprobs.length) {\n              if (logprobs === void 0) logprobs = [];\n              logprobs.push(...mappedLogprobs);\n            }\n          },\n          flush(controller) {\n            controller.enqueue({\n              type: \"finish\",\n              finishReason,\n              logprobs,\n              usage\n            });\n          }\n        })\n      ),\n      rawCall: { rawPrompt, rawSettings },\n      rawResponse: { headers: responseHeaders },\n      warnings,\n      request: { body: JSON.stringify(body) }\n    };\n  }\n};\nvar openaiCompletionResponseSchema = z3.object({\n  id: z3.string().nullish(),\n  created: z3.number().nullish(),\n  model: z3.string().nullish(),\n  choices: z3.array(\n    z3.object({\n      text: z3.string(),\n      finish_reason: z3.string(),\n      logprobs: z3.object({\n        tokens: z3.array(z3.string()),\n        token_logprobs: z3.array(z3.number()),\n        top_logprobs: z3.array(z3.record(z3.string(), z3.number())).nullable()\n      }).nullish()\n    })\n  ),\n  usage: z3.object({\n    prompt_tokens: z3.number(),\n    completion_tokens: z3.number()\n  })\n});\nvar openaiCompletionChunkSchema = z3.union([\n  z3.object({\n    id: z3.string().nullish(),\n    created: z3.number().nullish(),\n    model: z3.string().nullish(),\n    choices: z3.array(\n      z3.object({\n        text: z3.string(),\n        finish_reason: z3.string().nullish(),\n        index: z3.number(),\n        logprobs: z3.object({\n          tokens: z3.array(z3.string()),\n          token_logprobs: z3.array(z3.number()),\n          top_logprobs: z3.array(z3.record(z3.string(), z3.number())).nullable()\n        }).nullish()\n      })\n    ),\n    usage: z3.object({\n      prompt_tokens: z3.number(),\n      completion_tokens: z3.number()\n    }).nullish()\n  }),\n  openaiErrorDataSchema\n]);\n\n// src/openai-embedding-model.ts\nimport {\n  TooManyEmbeddingValuesForCallError\n} from \"@ai-sdk/provider\";\nimport {\n  combineHeaders as combineHeaders3,\n  createJsonResponseHandler as createJsonResponseHandler3,\n  postJsonToApi as postJsonToApi3\n} from \"@ai-sdk/provider-utils\";\nimport { z as z4 } from \"zod\";\nvar OpenAIEmbeddingModel = class {\n  constructor(modelId, settings, config) {\n    this.specificationVersion = \"v1\";\n    this.modelId = modelId;\n    this.settings = settings;\n    this.config = config;\n  }\n  get provider() {\n    return this.config.provider;\n  }\n  get maxEmbeddingsPerCall() {\n    var _a;\n    return (_a = this.settings.maxEmbeddingsPerCall) != null ? _a : 2048;\n  }\n  get supportsParallelCalls() {\n    var _a;\n    return (_a = this.settings.supportsParallelCalls) != null ? _a : true;\n  }\n  async doEmbed({\n    values,\n    headers,\n    abortSignal\n  }) {\n    if (values.length > this.maxEmbeddingsPerCall) {\n      throw new TooManyEmbeddingValuesForCallError({\n        provider: this.provider,\n        modelId: this.modelId,\n        maxEmbeddingsPerCall: this.maxEmbeddingsPerCall,\n        values\n      });\n    }\n    const { responseHeaders, value: response } = await postJsonToApi3({\n      url: this.config.url({\n        path: \"/embeddings\",\n        modelId: this.modelId\n      }),\n      headers: combineHeaders3(this.config.headers(), headers),\n      body: {\n        model: this.modelId,\n        input: values,\n        encoding_format: \"float\",\n        dimensions: this.settings.dimensions,\n        user: this.settings.user\n      },\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createJsonResponseHandler3(\n        openaiTextEmbeddingResponseSchema\n      ),\n      abortSignal,\n      fetch: this.config.fetch\n    });\n    return {\n      embeddings: response.data.map((item) => item.embedding),\n      usage: response.usage ? { tokens: response.usage.prompt_tokens } : void 0,\n      rawResponse: { headers: responseHeaders }\n    };\n  }\n};\nvar openaiTextEmbeddingResponseSchema = z4.object({\n  data: z4.array(z4.object({ embedding: z4.array(z4.number()) })),\n  usage: z4.object({ prompt_tokens: z4.number() }).nullish()\n});\n\n// src/openai-image-model.ts\nimport {\n  combineHeaders as combineHeaders4,\n  createJsonResponseHandler as createJsonResponseHandler4,\n  postJsonToApi as postJsonToApi4\n} from \"@ai-sdk/provider-utils\";\nimport { z as z5 } from \"zod\";\n\n// src/openai-image-settings.ts\nvar modelMaxImagesPerCall = {\n  \"dall-e-3\": 1,\n  \"dall-e-2\": 10,\n  \"gpt-image-1\": 10\n};\nvar hasDefaultResponseFormat = /* @__PURE__ */ new Set([\"gpt-image-1\"]);\n\n// src/openai-image-model.ts\nvar OpenAIImageModel = class {\n  constructor(modelId, settings, config) {\n    this.modelId = modelId;\n    this.settings = settings;\n    this.config = config;\n    this.specificationVersion = \"v1\";\n  }\n  get maxImagesPerCall() {\n    var _a, _b;\n    return (_b = (_a = this.settings.maxImagesPerCall) != null ? _a : modelMaxImagesPerCall[this.modelId]) != null ? _b : 1;\n  }\n  get provider() {\n    return this.config.provider;\n  }\n  async doGenerate({\n    prompt,\n    n,\n    size,\n    aspectRatio,\n    seed,\n    providerOptions,\n    headers,\n    abortSignal\n  }) {\n    var _a, _b, _c, _d;\n    const warnings = [];\n    if (aspectRatio != null) {\n      warnings.push({\n        type: \"unsupported-setting\",\n        setting: \"aspectRatio\",\n        details: \"This model does not support aspect ratio. Use `size` instead.\"\n      });\n    }\n    if (seed != null) {\n      warnings.push({ type: \"unsupported-setting\", setting: \"seed\" });\n    }\n    const currentDate = (_c = (_b = (_a = this.config._internal) == null ? void 0 : _a.currentDate) == null ? void 0 : _b.call(_a)) != null ? _c : /* @__PURE__ */ new Date();\n    const { value: response, responseHeaders } = await postJsonToApi4({\n      url: this.config.url({\n        path: \"/images/generations\",\n        modelId: this.modelId\n      }),\n      headers: combineHeaders4(this.config.headers(), headers),\n      body: {\n        model: this.modelId,\n        prompt,\n        n,\n        size,\n        ...(_d = providerOptions.openai) != null ? _d : {},\n        ...!hasDefaultResponseFormat.has(this.modelId) ? { response_format: \"b64_json\" } : {}\n      },\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createJsonResponseHandler4(\n        openaiImageResponseSchema\n      ),\n      abortSignal,\n      fetch: this.config.fetch\n    });\n    return {\n      images: response.data.map((item) => item.b64_json),\n      warnings,\n      response: {\n        timestamp: currentDate,\n        modelId: this.modelId,\n        headers: responseHeaders\n      }\n    };\n  }\n};\nvar openaiImageResponseSchema = z5.object({\n  data: z5.array(z5.object({ b64_json: z5.string() }))\n});\n\n// src/openai-transcription-model.ts\nimport {\n  combineHeaders as combineHeaders5,\n  convertBase64ToUint8Array,\n  createJsonResponseHandler as createJsonResponseHandler5,\n  parseProviderOptions,\n  postFormDataToApi\n} from \"@ai-sdk/provider-utils\";\nimport { z as z6 } from \"zod\";\nvar openAIProviderOptionsSchema = z6.object({\n  include: z6.array(z6.string()).nullish(),\n  language: z6.string().nullish(),\n  prompt: z6.string().nullish(),\n  temperature: z6.number().min(0).max(1).nullish().default(0),\n  timestampGranularities: z6.array(z6.enum([\"word\", \"segment\"])).nullish().default([\"segment\"])\n});\nvar languageMap = {\n  afrikaans: \"af\",\n  arabic: \"ar\",\n  armenian: \"hy\",\n  azerbaijani: \"az\",\n  belarusian: \"be\",\n  bosnian: \"bs\",\n  bulgarian: \"bg\",\n  catalan: \"ca\",\n  chinese: \"zh\",\n  croatian: \"hr\",\n  czech: \"cs\",\n  danish: \"da\",\n  dutch: \"nl\",\n  english: \"en\",\n  estonian: \"et\",\n  finnish: \"fi\",\n  french: \"fr\",\n  galician: \"gl\",\n  german: \"de\",\n  greek: \"el\",\n  hebrew: \"he\",\n  hindi: \"hi\",\n  hungarian: \"hu\",\n  icelandic: \"is\",\n  indonesian: \"id\",\n  italian: \"it\",\n  japanese: \"ja\",\n  kannada: \"kn\",\n  kazakh: \"kk\",\n  korean: \"ko\",\n  latvian: \"lv\",\n  lithuanian: \"lt\",\n  macedonian: \"mk\",\n  malay: \"ms\",\n  marathi: \"mr\",\n  maori: \"mi\",\n  nepali: \"ne\",\n  norwegian: \"no\",\n  persian: \"fa\",\n  polish: \"pl\",\n  portuguese: \"pt\",\n  romanian: \"ro\",\n  russian: \"ru\",\n  serbian: \"sr\",\n  slovak: \"sk\",\n  slovenian: \"sl\",\n  spanish: \"es\",\n  swahili: \"sw\",\n  swedish: \"sv\",\n  tagalog: \"tl\",\n  tamil: \"ta\",\n  thai: \"th\",\n  turkish: \"tr\",\n  ukrainian: \"uk\",\n  urdu: \"ur\",\n  vietnamese: \"vi\",\n  welsh: \"cy\"\n};\nvar OpenAITranscriptionModel = class {\n  constructor(modelId, config) {\n    this.modelId = modelId;\n    this.config = config;\n    this.specificationVersion = \"v1\";\n  }\n  get provider() {\n    return this.config.provider;\n  }\n  getArgs({\n    audio,\n    mediaType,\n    providerOptions\n  }) {\n    var _a, _b, _c, _d, _e;\n    const warnings = [];\n    const openAIOptions = parseProviderOptions({\n      provider: \"openai\",\n      providerOptions,\n      schema: openAIProviderOptionsSchema\n    });\n    const formData = new FormData();\n    const blob = audio instanceof Uint8Array ? new Blob([audio]) : new Blob([convertBase64ToUint8Array(audio)]);\n    formData.append(\"model\", this.modelId);\n    formData.append(\"file\", new File([blob], \"audio\", { type: mediaType }));\n    if (openAIOptions) {\n      const transcriptionModelOptions = {\n        include: (_a = openAIOptions.include) != null ? _a : void 0,\n        language: (_b = openAIOptions.language) != null ? _b : void 0,\n        prompt: (_c = openAIOptions.prompt) != null ? _c : void 0,\n        temperature: (_d = openAIOptions.temperature) != null ? _d : void 0,\n        timestamp_granularities: (_e = openAIOptions.timestampGranularities) != null ? _e : void 0\n      };\n      for (const key in transcriptionModelOptions) {\n        const value = transcriptionModelOptions[key];\n        if (value !== void 0) {\n          formData.append(key, String(value));\n        }\n      }\n    }\n    return {\n      formData,\n      warnings\n    };\n  }\n  async doGenerate(options) {\n    var _a, _b, _c, _d, _e, _f;\n    const currentDate = (_c = (_b = (_a = this.config._internal) == null ? void 0 : _a.currentDate) == null ? void 0 : _b.call(_a)) != null ? _c : /* @__PURE__ */ new Date();\n    const { formData, warnings } = this.getArgs(options);\n    const {\n      value: response,\n      responseHeaders,\n      rawValue: rawResponse\n    } = await postFormDataToApi({\n      url: this.config.url({\n        path: \"/audio/transcriptions\",\n        modelId: this.modelId\n      }),\n      headers: combineHeaders5(this.config.headers(), options.headers),\n      formData,\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createJsonResponseHandler5(\n        openaiTranscriptionResponseSchema\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch\n    });\n    const language = response.language != null && response.language in languageMap ? languageMap[response.language] : void 0;\n    return {\n      text: response.text,\n      segments: (_e = (_d = response.words) == null ? void 0 : _d.map((word) => ({\n        text: word.word,\n        startSecond: word.start,\n        endSecond: word.end\n      }))) != null ? _e : [],\n      language,\n      durationInSeconds: (_f = response.duration) != null ? _f : void 0,\n      warnings,\n      response: {\n        timestamp: currentDate,\n        modelId: this.modelId,\n        headers: responseHeaders,\n        body: rawResponse\n      }\n    };\n  }\n};\nvar openaiTranscriptionResponseSchema = z6.object({\n  text: z6.string(),\n  language: z6.string().nullish(),\n  duration: z6.number().nullish(),\n  words: z6.array(\n    z6.object({\n      word: z6.string(),\n      start: z6.number(),\n      end: z6.number()\n    })\n  ).nullish()\n});\n\n// src/responses/openai-responses-language-model.ts\nimport {\n  APICallError\n} from \"@ai-sdk/provider\";\nimport {\n  combineHeaders as combineHeaders6,\n  createEventSourceResponseHandler as createEventSourceResponseHandler3,\n  createJsonResponseHandler as createJsonResponseHandler6,\n  generateId as generateId2,\n  parseProviderOptions as parseProviderOptions2,\n  postJsonToApi as postJsonToApi5\n} from \"@ai-sdk/provider-utils\";\nimport { z as z7 } from \"zod\";\n\n// src/responses/convert-to-openai-responses-messages.ts\nimport {\n  UnsupportedFunctionalityError as UnsupportedFunctionalityError6\n} from \"@ai-sdk/provider\";\nimport { convertUint8ArrayToBase64 as convertUint8ArrayToBase642 } from \"@ai-sdk/provider-utils\";\nfunction convertToOpenAIResponsesMessages({\n  prompt,\n  systemMessageMode\n}) {\n  const messages = [];\n  const warnings = [];\n  for (const { role, content } of prompt) {\n    switch (role) {\n      case \"system\": {\n        switch (systemMessageMode) {\n          case \"system\": {\n            messages.push({ role: \"system\", content });\n            break;\n          }\n          case \"developer\": {\n            messages.push({ role: \"developer\", content });\n            break;\n          }\n          case \"remove\": {\n            warnings.push({\n              type: \"other\",\n              message: \"system messages are removed for this model\"\n            });\n            break;\n          }\n          default: {\n            const _exhaustiveCheck = systemMessageMode;\n            throw new Error(\n              `Unsupported system message mode: ${_exhaustiveCheck}`\n            );\n          }\n        }\n        break;\n      }\n      case \"user\": {\n        messages.push({\n          role: \"user\",\n          content: content.map((part, index) => {\n            var _a, _b, _c, _d;\n            switch (part.type) {\n              case \"text\": {\n                return { type: \"input_text\", text: part.text };\n              }\n              case \"image\": {\n                return {\n                  type: \"input_image\",\n                  image_url: part.image instanceof URL ? part.image.toString() : `data:${(_a = part.mimeType) != null ? _a : \"image/jpeg\"};base64,${convertUint8ArrayToBase642(part.image)}`,\n                  // OpenAI specific extension: image detail\n                  detail: (_c = (_b = part.providerMetadata) == null ? void 0 : _b.openai) == null ? void 0 : _c.imageDetail\n                };\n              }\n              case \"file\": {\n                if (part.data instanceof URL) {\n                  throw new UnsupportedFunctionalityError6({\n                    functionality: \"File URLs in user messages\"\n                  });\n                }\n                switch (part.mimeType) {\n                  case \"application/pdf\": {\n                    return {\n                      type: \"input_file\",\n                      filename: (_d = part.filename) != null ? _d : `part-${index}.pdf`,\n                      file_data: `data:application/pdf;base64,${part.data}`\n                    };\n                  }\n                  default: {\n                    throw new UnsupportedFunctionalityError6({\n                      functionality: \"Only PDF files are supported in user messages\"\n                    });\n                  }\n                }\n              }\n            }\n          })\n        });\n        break;\n      }\n      case \"assistant\": {\n        for (const part of content) {\n          switch (part.type) {\n            case \"text\": {\n              messages.push({\n                role: \"assistant\",\n                content: [{ type: \"output_text\", text: part.text }]\n              });\n              break;\n            }\n            case \"tool-call\": {\n              messages.push({\n                type: \"function_call\",\n                call_id: part.toolCallId,\n                name: part.toolName,\n                arguments: JSON.stringify(part.args)\n              });\n              break;\n            }\n          }\n        }\n        break;\n      }\n      case \"tool\": {\n        for (const part of content) {\n          messages.push({\n            type: \"function_call_output\",\n            call_id: part.toolCallId,\n            output: JSON.stringify(part.result)\n          });\n        }\n        break;\n      }\n      default: {\n        const _exhaustiveCheck = role;\n        throw new Error(`Unsupported role: ${_exhaustiveCheck}`);\n      }\n    }\n  }\n  return { messages, warnings };\n}\n\n// src/responses/map-openai-responses-finish-reason.ts\nfunction mapOpenAIResponseFinishReason({\n  finishReason,\n  hasToolCalls\n}) {\n  switch (finishReason) {\n    case void 0:\n    case null:\n      return hasToolCalls ? \"tool-calls\" : \"stop\";\n    case \"max_output_tokens\":\n      return \"length\";\n    case \"content_filter\":\n      return \"content-filter\";\n    default:\n      return hasToolCalls ? \"tool-calls\" : \"unknown\";\n  }\n}\n\n// src/responses/openai-responses-prepare-tools.ts\nimport {\n  UnsupportedFunctionalityError as UnsupportedFunctionalityError7\n} from \"@ai-sdk/provider\";\nfunction prepareResponsesTools({\n  mode,\n  strict\n}) {\n  var _a;\n  const tools = ((_a = mode.tools) == null ? void 0 : _a.length) ? mode.tools : void 0;\n  const toolWarnings = [];\n  if (tools == null) {\n    return { tools: void 0, tool_choice: void 0, toolWarnings };\n  }\n  const toolChoice = mode.toolChoice;\n  const openaiTools2 = [];\n  for (const tool of tools) {\n    switch (tool.type) {\n      case \"function\":\n        openaiTools2.push({\n          type: \"function\",\n          name: tool.name,\n          description: tool.description,\n          parameters: tool.parameters,\n          strict: strict ? true : void 0\n        });\n        break;\n      case \"provider-defined\":\n        switch (tool.id) {\n          case \"openai.web_search_preview\":\n            openaiTools2.push({\n              type: \"web_search_preview\",\n              search_context_size: tool.args.searchContextSize,\n              user_location: tool.args.userLocation\n            });\n            break;\n          default:\n            toolWarnings.push({ type: \"unsupported-tool\", tool });\n            break;\n        }\n        break;\n      default:\n        toolWarnings.push({ type: \"unsupported-tool\", tool });\n        break;\n    }\n  }\n  if (toolChoice == null) {\n    return { tools: openaiTools2, tool_choice: void 0, toolWarnings };\n  }\n  const type = toolChoice.type;\n  switch (type) {\n    case \"auto\":\n    case \"none\":\n    case \"required\":\n      return { tools: openaiTools2, tool_choice: type, toolWarnings };\n    case \"tool\": {\n      if (toolChoice.toolName === \"web_search_preview\") {\n        return {\n          tools: openaiTools2,\n          tool_choice: {\n            type: \"web_search_preview\"\n          },\n          toolWarnings\n        };\n      }\n      return {\n        tools: openaiTools2,\n        tool_choice: {\n          type: \"function\",\n          name: toolChoice.toolName\n        },\n        toolWarnings\n      };\n    }\n    default: {\n      const _exhaustiveCheck = type;\n      throw new UnsupportedFunctionalityError7({\n        functionality: `Unsupported tool choice type: ${_exhaustiveCheck}`\n      });\n    }\n  }\n}\n\n// src/responses/openai-responses-language-model.ts\nvar OpenAIResponsesLanguageModel = class {\n  constructor(modelId, config) {\n    this.specificationVersion = \"v1\";\n    this.defaultObjectGenerationMode = \"json\";\n    this.supportsStructuredOutputs = true;\n    this.modelId = modelId;\n    this.config = config;\n  }\n  get provider() {\n    return this.config.provider;\n  }\n  getArgs({\n    mode,\n    maxTokens,\n    temperature,\n    stopSequences,\n    topP,\n    topK,\n    presencePenalty,\n    frequencyPenalty,\n    seed,\n    prompt,\n    providerMetadata,\n    responseFormat\n  }) {\n    var _a, _b, _c;\n    const warnings = [];\n    const modelConfig = getResponsesModelConfig(this.modelId);\n    const type = mode.type;\n    if (topK != null) {\n      warnings.push({\n        type: \"unsupported-setting\",\n        setting: \"topK\"\n      });\n    }\n    if (seed != null) {\n      warnings.push({\n        type: \"unsupported-setting\",\n        setting: \"seed\"\n      });\n    }\n    if (presencePenalty != null) {\n      warnings.push({\n        type: \"unsupported-setting\",\n        setting: \"presencePenalty\"\n      });\n    }\n    if (frequencyPenalty != null) {\n      warnings.push({\n        type: \"unsupported-setting\",\n        setting: \"frequencyPenalty\"\n      });\n    }\n    if (stopSequences != null) {\n      warnings.push({\n        type: \"unsupported-setting\",\n        setting: \"stopSequences\"\n      });\n    }\n    const { messages, warnings: messageWarnings } = convertToOpenAIResponsesMessages({\n      prompt,\n      systemMessageMode: modelConfig.systemMessageMode\n    });\n    warnings.push(...messageWarnings);\n    const openaiOptions = parseProviderOptions2({\n      provider: \"openai\",\n      providerOptions: providerMetadata,\n      schema: openaiResponsesProviderOptionsSchema\n    });\n    const isStrict = (_a = openaiOptions == null ? void 0 : openaiOptions.strictSchemas) != null ? _a : true;\n    const baseArgs = {\n      model: this.modelId,\n      input: messages,\n      temperature,\n      top_p: topP,\n      max_output_tokens: maxTokens,\n      ...(responseFormat == null ? void 0 : responseFormat.type) === \"json\" && {\n        text: {\n          format: responseFormat.schema != null ? {\n            type: \"json_schema\",\n            strict: isStrict,\n            name: (_b = responseFormat.name) != null ? _b : \"response\",\n            description: responseFormat.description,\n            schema: responseFormat.schema\n          } : { type: \"json_object\" }\n        }\n      },\n      // provider options:\n      metadata: openaiOptions == null ? void 0 : openaiOptions.metadata,\n      parallel_tool_calls: openaiOptions == null ? void 0 : openaiOptions.parallelToolCalls,\n      previous_response_id: openaiOptions == null ? void 0 : openaiOptions.previousResponseId,\n      store: openaiOptions == null ? void 0 : openaiOptions.store,\n      user: openaiOptions == null ? void 0 : openaiOptions.user,\n      instructions: openaiOptions == null ? void 0 : openaiOptions.instructions,\n      // model-specific settings:\n      ...modelConfig.isReasoningModel && ((openaiOptions == null ? void 0 : openaiOptions.reasoningEffort) != null || (openaiOptions == null ? void 0 : openaiOptions.reasoningSummary) != null) && {\n        reasoning: {\n          ...(openaiOptions == null ? void 0 : openaiOptions.reasoningEffort) != null && {\n            effort: openaiOptions.reasoningEffort\n          },\n          ...(openaiOptions == null ? void 0 : openaiOptions.reasoningSummary) != null && {\n            summary: openaiOptions.reasoningSummary\n          }\n        }\n      },\n      ...modelConfig.requiredAutoTruncation && {\n        truncation: \"auto\"\n      }\n    };\n    if (modelConfig.isReasoningModel) {\n      if (baseArgs.temperature != null) {\n        baseArgs.temperature = void 0;\n        warnings.push({\n          type: \"unsupported-setting\",\n          setting: \"temperature\",\n          details: \"temperature is not supported for reasoning models\"\n        });\n      }\n      if (baseArgs.top_p != null) {\n        baseArgs.top_p = void 0;\n        warnings.push({\n          type: \"unsupported-setting\",\n          setting: \"topP\",\n          details: \"topP is not supported for reasoning models\"\n        });\n      }\n    }\n    switch (type) {\n      case \"regular\": {\n        const { tools, tool_choice, toolWarnings } = prepareResponsesTools({\n          mode,\n          strict: isStrict\n          // TODO support provider options on tools\n        });\n        return {\n          args: {\n            ...baseArgs,\n            tools,\n            tool_choice\n          },\n          warnings: [...warnings, ...toolWarnings]\n        };\n      }\n      case \"object-json\": {\n        return {\n          args: {\n            ...baseArgs,\n            text: {\n              format: mode.schema != null ? {\n                type: \"json_schema\",\n                strict: isStrict,\n                name: (_c = mode.name) != null ? _c : \"response\",\n                description: mode.description,\n                schema: mode.schema\n              } : { type: \"json_object\" }\n            }\n          },\n          warnings\n        };\n      }\n      case \"object-tool\": {\n        return {\n          args: {\n            ...baseArgs,\n            tool_choice: { type: \"function\", name: mode.tool.name },\n            tools: [\n              {\n                type: \"function\",\n                name: mode.tool.name,\n                description: mode.tool.description,\n                parameters: mode.tool.parameters,\n                strict: isStrict\n              }\n            ]\n          },\n          warnings\n        };\n      }\n      default: {\n        const _exhaustiveCheck = type;\n        throw new Error(`Unsupported type: ${_exhaustiveCheck}`);\n      }\n    }\n  }\n  async doGenerate(options) {\n    var _a, _b, _c, _d, _e, _f, _g;\n    const { args: body, warnings } = this.getArgs(options);\n    const url = this.config.url({\n      path: \"/responses\",\n      modelId: this.modelId\n    });\n    const {\n      responseHeaders,\n      value: response,\n      rawValue: rawResponse\n    } = await postJsonToApi5({\n      url,\n      headers: combineHeaders6(this.config.headers(), options.headers),\n      body,\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createJsonResponseHandler6(\n        z7.object({\n          id: z7.string(),\n          created_at: z7.number(),\n          error: z7.object({\n            message: z7.string(),\n            code: z7.string()\n          }).nullish(),\n          model: z7.string(),\n          output: z7.array(\n            z7.discriminatedUnion(\"type\", [\n              z7.object({\n                type: z7.literal(\"message\"),\n                role: z7.literal(\"assistant\"),\n                content: z7.array(\n                  z7.object({\n                    type: z7.literal(\"output_text\"),\n                    text: z7.string(),\n                    annotations: z7.array(\n                      z7.object({\n                        type: z7.literal(\"url_citation\"),\n                        start_index: z7.number(),\n                        end_index: z7.number(),\n                        url: z7.string(),\n                        title: z7.string()\n                      })\n                    )\n                  })\n                )\n              }),\n              z7.object({\n                type: z7.literal(\"function_call\"),\n                call_id: z7.string(),\n                name: z7.string(),\n                arguments: z7.string()\n              }),\n              z7.object({\n                type: z7.literal(\"web_search_call\")\n              }),\n              z7.object({\n                type: z7.literal(\"computer_call\")\n              }),\n              z7.object({\n                type: z7.literal(\"reasoning\"),\n                summary: z7.array(\n                  z7.object({\n                    type: z7.literal(\"summary_text\"),\n                    text: z7.string()\n                  })\n                )\n              })\n            ])\n          ),\n          incomplete_details: z7.object({ reason: z7.string() }).nullable(),\n          usage: usageSchema\n        })\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch\n    });\n    if (response.error) {\n      throw new APICallError({\n        message: response.error.message,\n        url,\n        requestBodyValues: body,\n        statusCode: 400,\n        responseHeaders,\n        responseBody: rawResponse,\n        isRetryable: false\n      });\n    }\n    const outputTextElements = response.output.filter((output) => output.type === \"message\").flatMap((output) => output.content).filter((content) => content.type === \"output_text\");\n    const toolCalls = response.output.filter((output) => output.type === \"function_call\").map((output) => ({\n      toolCallType: \"function\",\n      toolCallId: output.call_id,\n      toolName: output.name,\n      args: output.arguments\n    }));\n    const reasoningSummary = (_b = (_a = response.output.find((item) => item.type === \"reasoning\")) == null ? void 0 : _a.summary) != null ? _b : null;\n    return {\n      text: outputTextElements.map((content) => content.text).join(\"\\n\"),\n      sources: outputTextElements.flatMap(\n        (content) => content.annotations.map((annotation) => {\n          var _a2, _b2, _c2;\n          return {\n            sourceType: \"url\",\n            id: (_c2 = (_b2 = (_a2 = this.config).generateId) == null ? void 0 : _b2.call(_a2)) != null ? _c2 : generateId2(),\n            url: annotation.url,\n            title: annotation.title\n          };\n        })\n      ),\n      finishReason: mapOpenAIResponseFinishReason({\n        finishReason: (_c = response.incomplete_details) == null ? void 0 : _c.reason,\n        hasToolCalls: toolCalls.length > 0\n      }),\n      toolCalls: toolCalls.length > 0 ? toolCalls : void 0,\n      reasoning: reasoningSummary ? reasoningSummary.map((summary) => ({\n        type: \"text\",\n        text: summary.text\n      })) : void 0,\n      usage: {\n        promptTokens: response.usage.input_tokens,\n        completionTokens: response.usage.output_tokens\n      },\n      rawCall: {\n        rawPrompt: void 0,\n        rawSettings: {}\n      },\n      rawResponse: {\n        headers: responseHeaders,\n        body: rawResponse\n      },\n      request: {\n        body: JSON.stringify(body)\n      },\n      response: {\n        id: response.id,\n        timestamp: new Date(response.created_at * 1e3),\n        modelId: response.model\n      },\n      providerMetadata: {\n        openai: {\n          responseId: response.id,\n          cachedPromptTokens: (_e = (_d = response.usage.input_tokens_details) == null ? void 0 : _d.cached_tokens) != null ? _e : null,\n          reasoningTokens: (_g = (_f = response.usage.output_tokens_details) == null ? void 0 : _f.reasoning_tokens) != null ? _g : null\n        }\n      },\n      warnings\n    };\n  }\n  async doStream(options) {\n    const { args: body, warnings } = this.getArgs(options);\n    const { responseHeaders, value: response } = await postJsonToApi5({\n      url: this.config.url({\n        path: \"/responses\",\n        modelId: this.modelId\n      }),\n      headers: combineHeaders6(this.config.headers(), options.headers),\n      body: {\n        ...body,\n        stream: true\n      },\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createEventSourceResponseHandler3(\n        openaiResponsesChunkSchema\n      ),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch\n    });\n    const self = this;\n    let finishReason = \"unknown\";\n    let promptTokens = NaN;\n    let completionTokens = NaN;\n    let cachedPromptTokens = null;\n    let reasoningTokens = null;\n    let responseId = null;\n    const ongoingToolCalls = {};\n    let hasToolCalls = false;\n    return {\n      stream: response.pipeThrough(\n        new TransformStream({\n          transform(chunk, controller) {\n            var _a, _b, _c, _d, _e, _f, _g, _h;\n            if (!chunk.success) {\n              finishReason = \"error\";\n              controller.enqueue({ type: \"error\", error: chunk.error });\n              return;\n            }\n            const value = chunk.value;\n            if (isResponseOutputItemAddedChunk(value)) {\n              if (value.item.type === \"function_call\") {\n                ongoingToolCalls[value.output_index] = {\n                  toolName: value.item.name,\n                  toolCallId: value.item.call_id\n                };\n                controller.enqueue({\n                  type: \"tool-call-delta\",\n                  toolCallType: \"function\",\n                  toolCallId: value.item.call_id,\n                  toolName: value.item.name,\n                  argsTextDelta: value.item.arguments\n                });\n              }\n            } else if (isResponseFunctionCallArgumentsDeltaChunk(value)) {\n              const toolCall = ongoingToolCalls[value.output_index];\n              if (toolCall != null) {\n                controller.enqueue({\n                  type: \"tool-call-delta\",\n                  toolCallType: \"function\",\n                  toolCallId: toolCall.toolCallId,\n                  toolName: toolCall.toolName,\n                  argsTextDelta: value.delta\n                });\n              }\n            } else if (isResponseCreatedChunk(value)) {\n              responseId = value.response.id;\n              controller.enqueue({\n                type: \"response-metadata\",\n                id: value.response.id,\n                timestamp: new Date(value.response.created_at * 1e3),\n                modelId: value.response.model\n              });\n            } else if (isTextDeltaChunk(value)) {\n              controller.enqueue({\n                type: \"text-delta\",\n                textDelta: value.delta\n              });\n            } else if (isResponseReasoningSummaryTextDeltaChunk(value)) {\n              controller.enqueue({\n                type: \"reasoning\",\n                textDelta: value.delta\n              });\n            } else if (isResponseOutputItemDoneChunk(value) && value.item.type === \"function_call\") {\n              ongoingToolCalls[value.output_index] = void 0;\n              hasToolCalls = true;\n              controller.enqueue({\n                type: \"tool-call\",\n                toolCallType: \"function\",\n                toolCallId: value.item.call_id,\n                toolName: value.item.name,\n                args: value.item.arguments\n              });\n            } else if (isResponseFinishedChunk(value)) {\n              finishReason = mapOpenAIResponseFinishReason({\n                finishReason: (_a = value.response.incomplete_details) == null ? void 0 : _a.reason,\n                hasToolCalls\n              });\n              promptTokens = value.response.usage.input_tokens;\n              completionTokens = value.response.usage.output_tokens;\n              cachedPromptTokens = (_c = (_b = value.response.usage.input_tokens_details) == null ? void 0 : _b.cached_tokens) != null ? _c : cachedPromptTokens;\n              reasoningTokens = (_e = (_d = value.response.usage.output_tokens_details) == null ? void 0 : _d.reasoning_tokens) != null ? _e : reasoningTokens;\n            } else if (isResponseAnnotationAddedChunk(value)) {\n              controller.enqueue({\n                type: \"source\",\n                source: {\n                  sourceType: \"url\",\n                  id: (_h = (_g = (_f = self.config).generateId) == null ? void 0 : _g.call(_f)) != null ? _h : generateId2(),\n                  url: value.annotation.url,\n                  title: value.annotation.title\n                }\n              });\n            } else if (isErrorChunk(value)) {\n              controller.enqueue({ type: \"error\", error: value });\n            }\n          },\n          flush(controller) {\n            controller.enqueue({\n              type: \"finish\",\n              finishReason,\n              usage: { promptTokens, completionTokens },\n              ...(cachedPromptTokens != null || reasoningTokens != null) && {\n                providerMetadata: {\n                  openai: {\n                    responseId,\n                    cachedPromptTokens,\n                    reasoningTokens\n                  }\n                }\n              }\n            });\n          }\n        })\n      ),\n      rawCall: {\n        rawPrompt: void 0,\n        rawSettings: {}\n      },\n      rawResponse: { headers: responseHeaders },\n      request: { body: JSON.stringify(body) },\n      warnings\n    };\n  }\n};\nvar usageSchema = z7.object({\n  input_tokens: z7.number(),\n  input_tokens_details: z7.object({ cached_tokens: z7.number().nullish() }).nullish(),\n  output_tokens: z7.number(),\n  output_tokens_details: z7.object({ reasoning_tokens: z7.number().nullish() }).nullish()\n});\nvar textDeltaChunkSchema = z7.object({\n  type: z7.literal(\"response.output_text.delta\"),\n  delta: z7.string()\n});\nvar responseFinishedChunkSchema = z7.object({\n  type: z7.enum([\"response.completed\", \"response.incomplete\"]),\n  response: z7.object({\n    incomplete_details: z7.object({ reason: z7.string() }).nullish(),\n    usage: usageSchema\n  })\n});\nvar responseCreatedChunkSchema = z7.object({\n  type: z7.literal(\"response.created\"),\n  response: z7.object({\n    id: z7.string(),\n    created_at: z7.number(),\n    model: z7.string()\n  })\n});\nvar responseOutputItemDoneSchema = z7.object({\n  type: z7.literal(\"response.output_item.done\"),\n  output_index: z7.number(),\n  item: z7.discriminatedUnion(\"type\", [\n    z7.object({\n      type: z7.literal(\"message\")\n    }),\n    z7.object({\n      type: z7.literal(\"function_call\"),\n      id: z7.string(),\n      call_id: z7.string(),\n      name: z7.string(),\n      arguments: z7.string(),\n      status: z7.literal(\"completed\")\n    })\n  ])\n});\nvar responseFunctionCallArgumentsDeltaSchema = z7.object({\n  type: z7.literal(\"response.function_call_arguments.delta\"),\n  item_id: z7.string(),\n  output_index: z7.number(),\n  delta: z7.string()\n});\nvar responseOutputItemAddedSchema = z7.object({\n  type: z7.literal(\"response.output_item.added\"),\n  output_index: z7.number(),\n  item: z7.discriminatedUnion(\"type\", [\n    z7.object({\n      type: z7.literal(\"message\")\n    }),\n    z7.object({\n      type: z7.literal(\"function_call\"),\n      id: z7.string(),\n      call_id: z7.string(),\n      name: z7.string(),\n      arguments: z7.string()\n    })\n  ])\n});\nvar responseAnnotationAddedSchema = z7.object({\n  type: z7.literal(\"response.output_text.annotation.added\"),\n  annotation: z7.object({\n    type: z7.literal(\"url_citation\"),\n    url: z7.string(),\n    title: z7.string()\n  })\n});\nvar responseReasoningSummaryTextDeltaSchema = z7.object({\n  type: z7.literal(\"response.reasoning_summary_text.delta\"),\n  item_id: z7.string(),\n  output_index: z7.number(),\n  summary_index: z7.number(),\n  delta: z7.string()\n});\nvar errorChunkSchema = z7.object({\n  type: z7.literal(\"error\"),\n  code: z7.string(),\n  message: z7.string(),\n  param: z7.string().nullish(),\n  sequence_number: z7.number()\n});\nvar openaiResponsesChunkSchema = z7.union([\n  textDeltaChunkSchema,\n  responseFinishedChunkSchema,\n  responseCreatedChunkSchema,\n  responseOutputItemDoneSchema,\n  responseFunctionCallArgumentsDeltaSchema,\n  responseOutputItemAddedSchema,\n  responseAnnotationAddedSchema,\n  responseReasoningSummaryTextDeltaSchema,\n  errorChunkSchema,\n  z7.object({ type: z7.string() }).passthrough()\n  // fallback for unknown chunks\n]);\nfunction isTextDeltaChunk(chunk) {\n  return chunk.type === \"response.output_text.delta\";\n}\nfunction isResponseOutputItemDoneChunk(chunk) {\n  return chunk.type === \"response.output_item.done\";\n}\nfunction isResponseFinishedChunk(chunk) {\n  return chunk.type === \"response.completed\" || chunk.type === \"response.incomplete\";\n}\nfunction isResponseCreatedChunk(chunk) {\n  return chunk.type === \"response.created\";\n}\nfunction isResponseFunctionCallArgumentsDeltaChunk(chunk) {\n  return chunk.type === \"response.function_call_arguments.delta\";\n}\nfunction isResponseOutputItemAddedChunk(chunk) {\n  return chunk.type === \"response.output_item.added\";\n}\nfunction isResponseAnnotationAddedChunk(chunk) {\n  return chunk.type === \"response.output_text.annotation.added\";\n}\nfunction isResponseReasoningSummaryTextDeltaChunk(chunk) {\n  return chunk.type === \"response.reasoning_summary_text.delta\";\n}\nfunction isErrorChunk(chunk) {\n  return chunk.type === \"error\";\n}\nfunction getResponsesModelConfig(modelId) {\n  if (modelId.startsWith(\"o\") || modelId.startsWith(\"gpt-5\")) {\n    if (modelId.startsWith(\"o1-mini\") || modelId.startsWith(\"o1-preview\")) {\n      return {\n        isReasoningModel: true,\n        systemMessageMode: \"remove\",\n        requiredAutoTruncation: false\n      };\n    }\n    return {\n      isReasoningModel: true,\n      systemMessageMode: \"developer\",\n      requiredAutoTruncation: false\n    };\n  }\n  return {\n    isReasoningModel: false,\n    systemMessageMode: \"system\",\n    requiredAutoTruncation: false\n  };\n}\nvar openaiResponsesProviderOptionsSchema = z7.object({\n  metadata: z7.any().nullish(),\n  parallelToolCalls: z7.boolean().nullish(),\n  previousResponseId: z7.string().nullish(),\n  store: z7.boolean().nullish(),\n  user: z7.string().nullish(),\n  reasoningEffort: z7.string().nullish(),\n  strictSchemas: z7.boolean().nullish(),\n  instructions: z7.string().nullish(),\n  reasoningSummary: z7.string().nullish()\n});\n\n// src/openai-tools.ts\nimport { z as z8 } from \"zod\";\nvar WebSearchPreviewParameters = z8.object({});\nfunction webSearchPreviewTool({\n  searchContextSize,\n  userLocation\n} = {}) {\n  return {\n    type: \"provider-defined\",\n    id: \"openai.web_search_preview\",\n    args: {\n      searchContextSize,\n      userLocation\n    },\n    parameters: WebSearchPreviewParameters\n  };\n}\nvar openaiTools = {\n  webSearchPreview: webSearchPreviewTool\n};\n\n// src/openai-speech-model.ts\nimport {\n  combineHeaders as combineHeaders7,\n  createBinaryResponseHandler,\n  parseProviderOptions as parseProviderOptions3,\n  postJsonToApi as postJsonToApi6\n} from \"@ai-sdk/provider-utils\";\nimport { z as z9 } from \"zod\";\nvar OpenAIProviderOptionsSchema = z9.object({\n  instructions: z9.string().nullish(),\n  speed: z9.number().min(0.25).max(4).default(1).nullish()\n});\nvar OpenAISpeechModel = class {\n  constructor(modelId, config) {\n    this.modelId = modelId;\n    this.config = config;\n    this.specificationVersion = \"v1\";\n  }\n  get provider() {\n    return this.config.provider;\n  }\n  getArgs({\n    text,\n    voice = \"alloy\",\n    outputFormat = \"mp3\",\n    speed,\n    instructions,\n    providerOptions\n  }) {\n    const warnings = [];\n    const openAIOptions = parseProviderOptions3({\n      provider: \"openai\",\n      providerOptions,\n      schema: OpenAIProviderOptionsSchema\n    });\n    const requestBody = {\n      model: this.modelId,\n      input: text,\n      voice,\n      response_format: \"mp3\",\n      speed,\n      instructions\n    };\n    if (outputFormat) {\n      if ([\"mp3\", \"opus\", \"aac\", \"flac\", \"wav\", \"pcm\"].includes(outputFormat)) {\n        requestBody.response_format = outputFormat;\n      } else {\n        warnings.push({\n          type: \"unsupported-setting\",\n          setting: \"outputFormat\",\n          details: `Unsupported output format: ${outputFormat}. Using mp3 instead.`\n        });\n      }\n    }\n    if (openAIOptions) {\n      const speechModelOptions = {};\n      for (const key in speechModelOptions) {\n        const value = speechModelOptions[key];\n        if (value !== void 0) {\n          requestBody[key] = value;\n        }\n      }\n    }\n    return {\n      requestBody,\n      warnings\n    };\n  }\n  async doGenerate(options) {\n    var _a, _b, _c;\n    const currentDate = (_c = (_b = (_a = this.config._internal) == null ? void 0 : _a.currentDate) == null ? void 0 : _b.call(_a)) != null ? _c : /* @__PURE__ */ new Date();\n    const { requestBody, warnings } = this.getArgs(options);\n    const {\n      value: audio,\n      responseHeaders,\n      rawValue: rawResponse\n    } = await postJsonToApi6({\n      url: this.config.url({\n        path: \"/audio/speech\",\n        modelId: this.modelId\n      }),\n      headers: combineHeaders7(this.config.headers(), options.headers),\n      body: requestBody,\n      failedResponseHandler: openaiFailedResponseHandler,\n      successfulResponseHandler: createBinaryResponseHandler(),\n      abortSignal: options.abortSignal,\n      fetch: this.config.fetch\n    });\n    return {\n      audio,\n      warnings,\n      request: {\n        body: JSON.stringify(requestBody)\n      },\n      response: {\n        timestamp: currentDate,\n        modelId: this.modelId,\n        headers: responseHeaders,\n        body: rawResponse\n      }\n    };\n  }\n};\n\n// src/openai-provider.ts\nfunction createOpenAI(options = {}) {\n  var _a, _b, _c;\n  const baseURL = (_a = withoutTrailingSlash(options.baseURL)) != null ? _a : \"https://api.openai.com/v1\";\n  const compatibility = (_b = options.compatibility) != null ? _b : \"compatible\";\n  const providerName = (_c = options.name) != null ? _c : \"openai\";\n  const getHeaders = () => ({\n    Authorization: `Bearer ${loadApiKey({\n      apiKey: options.apiKey,\n      environmentVariableName: \"OPENAI_API_KEY\",\n      description: \"OpenAI\"\n    })}`,\n    \"OpenAI-Organization\": options.organization,\n    \"OpenAI-Project\": options.project,\n    ...options.headers\n  });\n  const createChatModel = (modelId, settings = {}) => new OpenAIChatLanguageModel(modelId, settings, {\n    provider: `${providerName}.chat`,\n    url: ({ path }) => `${baseURL}${path}`,\n    headers: getHeaders,\n    compatibility,\n    fetch: options.fetch\n  });\n  const createCompletionModel = (modelId, settings = {}) => new OpenAICompletionLanguageModel(modelId, settings, {\n    provider: `${providerName}.completion`,\n    url: ({ path }) => `${baseURL}${path}`,\n    headers: getHeaders,\n    compatibility,\n    fetch: options.fetch\n  });\n  const createEmbeddingModel = (modelId, settings = {}) => new OpenAIEmbeddingModel(modelId, settings, {\n    provider: `${providerName}.embedding`,\n    url: ({ path }) => `${baseURL}${path}`,\n    headers: getHeaders,\n    fetch: options.fetch\n  });\n  const createImageModel = (modelId, settings = {}) => new OpenAIImageModel(modelId, settings, {\n    provider: `${providerName}.image`,\n    url: ({ path }) => `${baseURL}${path}`,\n    headers: getHeaders,\n    fetch: options.fetch\n  });\n  const createTranscriptionModel = (modelId) => new OpenAITranscriptionModel(modelId, {\n    provider: `${providerName}.transcription`,\n    url: ({ path }) => `${baseURL}${path}`,\n    headers: getHeaders,\n    fetch: options.fetch\n  });\n  const createSpeechModel = (modelId) => new OpenAISpeechModel(modelId, {\n    provider: `${providerName}.speech`,\n    url: ({ path }) => `${baseURL}${path}`,\n    headers: getHeaders,\n    fetch: options.fetch\n  });\n  const createLanguageModel = (modelId, settings) => {\n    if (new.target) {\n      throw new Error(\n        \"The OpenAI model function cannot be called with the new keyword.\"\n      );\n    }\n    if (modelId === \"gpt-3.5-turbo-instruct\") {\n      return createCompletionModel(\n        modelId,\n        settings\n      );\n    }\n    return createChatModel(modelId, settings);\n  };\n  const createResponsesModel = (modelId) => {\n    return new OpenAIResponsesLanguageModel(modelId, {\n      provider: `${providerName}.responses`,\n      url: ({ path }) => `${baseURL}${path}`,\n      headers: getHeaders,\n      fetch: options.fetch\n    });\n  };\n  const provider = function(modelId, settings) {\n    return createLanguageModel(modelId, settings);\n  };\n  provider.languageModel = createLanguageModel;\n  provider.chat = createChatModel;\n  provider.completion = createCompletionModel;\n  provider.responses = createResponsesModel;\n  provider.embedding = createEmbeddingModel;\n  provider.textEmbedding = createEmbeddingModel;\n  provider.textEmbeddingModel = createEmbeddingModel;\n  provider.image = createImageModel;\n  provider.imageModel = createImageModel;\n  provider.transcription = createTranscriptionModel;\n  provider.transcriptionModel = createTranscriptionModel;\n  provider.speech = createSpeechModel;\n  provider.speechModel = createSpeechModel;\n  provider.tools = openaiTools;\n  return provider;\n}\nvar openai = createOpenAI({\n  compatibility: \"strict\"\n  // strict for OpenAI API\n});\nexport {\n  createOpenAI,\n  openai\n};\n//# sourceMappingURL=index.mjs.map"],"names":["combineHeaders","headers","reduce","combinedHeaders","currentHeaders","createEventSourceParserStream","event","lastEventId","retry","buffer","data","parseLine","line","controller","dispatchEvent","startsWith","colonIndex","indexOf","handleField","valueStart","slice","length","enqueue","join","id","field","value","push","parsedRetry","parseInt","isNaN","TransformStream","transform","chunk","lines","incompleteLine","currentLine","i","char","splitLines","flush","extractResponseHeaders","response","forEach","key","generateId","prefix","size","defaultSize","alphabet","separator","generator","customAlphabet","includes","InvalidArgumentError","argument","message","createIdGenerator","isAbortError","error","Error","name","loadApiKey","apiKey","environmentVariableName","apiKeyParameterName","description","LoadAPIKeyError","process","define_process_env_default","validatorSymbol","Symbol","for","asValidator","isValidator","zodSchema","validate","result","safeParse","success","safeValidateTypes","schema","validator2","TypeValidationError","wrap","cause","parseJSON","text","SecureJSON","parse","inputSchema","validateTypes","JSONParseError","isInstance","TypeValidationError2","safeParseJSON","rawValue","validationResult","isParsableJson","input","e","parseProviderOptions","provider","providerOptions","parsedProviderOptions","InvalidArgumentError2","getOriginalFetch2","globalThis","fetch","postJsonToApi","async","url","body","failedResponseHandler","successfulResponseHandler","abortSignal","postToApi","content","JSON","stringify","values","method","record","Object","fromEntries","entries","filter","_key","signal","responseHeaders","ok","errorInformation","requestBodyValues","APICallError2","statusCode","status","TypeError","isRetryable","createEventSourceResponseHandler","chunkSchema","EmptyResponseBodyError","pipeThrough","TextDecoderStream","createJsonResponseHandler","responseSchema","responseBody","parsedResult","APICallError3","btoa","atob","convertBase64ToUint8Array","base64String","base64Url","replace","latin1string","Uint8Array","from","byte","codePointAt","convertUint8ArrayToBase64","array","String","fromCodePoint","mapOpenAIChatLogProbsOutput","logprobs","_a","_b","map","token","logprob","top_logprobs","topLogprobs","token2","logprob2","mapOpenAIFinishReason","finishReason","openaiErrorDataSchema","z.object","z.string","type","nullish","param","z.any","code","z.union","z.number","openaiFailedResponseHandler","errorSchema","errorToMessage","trim","statusText","parsedError","parseError","createJsonErrorResponseHandler","getResponseMetadata","model","created","modelId","timestamp","Date","OpenAIChatLanguageModel","constructor","settings","config","this","specificationVersion","supportsStructuredOutputs","structuredOutputs","isReasoningModel","defaultObjectGenerationMode","supportsImageUrls","downloadImages","getArgs","mode","prompt","maxTokens","temperature","topP","topK","frequencyPenalty","presencePenalty","stopSequences","responseFormat","seed","providerMetadata","_c","_d","_e","_f","_g","_h","warnings","setting","details","useLegacyFunctionCalling","parallelToolCalls","UnsupportedFunctionalityError3","functionality","messages","messageWarnings","systemMessageMode","role","part","index","image_url","image","URL","toString","mimeType","detail","openai","imageDetail","UnsupportedFunctionalityError","input_audio","format","file","filename","file_data","toolCalls","toolCallId","function","toolName","arguments","args","function_call","tool_calls","toolResponse","tool_call_id","convertToOpenAIChatMessages","getSystemMessageMode","baseArgs","logit_bias","logitBias","user","parallel_tool_calls","max_tokens","top_p","frequency_penalty","presence_penalty","response_format","json_schema","strict","stop","max_completion_tokens","maxCompletionTokens","store","metadata","prediction","reasoning_effort","reasoningEffort","tools","tool_choice","functions","toolWarnings","toolChoice","openaiFunctions","tool","parameters","UnsupportedFunctionalityError2","openaiTools2","prepareTools","doGenerate","options","rawResponse","path","openaiChatResponseSchema","rawPrompt","rawSettings","choice","choices","completionTokenDetails","usage","completion_tokens_details","promptTokenDetails","prompt_tokens_details","reasoning_tokens","reasoningTokens","accepted_prediction_tokens","acceptedPredictionTokens","rejected_prediction_tokens","rejectedPredictionTokens","cached_tokens","cachedPromptTokens","toolCallType","toolCall","_a2","finish_reason","promptTokens","prompt_tokens","NaN","completionTokens","completion_tokens","rawCall","request","doStream","simulateStreaming","stream","ReadableStream","start","textDelta","argsTextDelta","close","stream_options","compatibility","include_usage","openaiChatChunkSchema","isFirstChunk","_i","_j","_k","_l","delta","mappedLogprobs","mappedToolCalls","toolCallDelta","InvalidResponseDataError","hasFinished","toolCall2","openaiTokenUsageSchema","z2.object","z2.number","z2.string","z2.array","z2.literal","nullable","z2.union","z2.enum","optional","reasoningModels","o3","mapOpenAICompletionLogProbs","tokens","token_logprobs","OpenAICompletionLanguageModel","inputFormat","userStopSequences","completionPrompt","assistant","InvalidPromptError","UnsupportedFunctionalityError4","convertToOpenAICompletionPrompt","echo","suffix","UnsupportedFunctionalityError5","postJsonToApi2","combineHeaders2","createJsonResponseHandler2","openaiCompletionResponseSchema","createEventSourceResponseHandler2","openaiCompletionChunkSchema","Number","z3.object","z3.string","z3.number","z3.array","z3.record","z3.union","OpenAIEmbeddingModel","maxEmbeddingsPerCall","supportsParallelCalls","doEmbed","TooManyEmbeddingValuesForCallError","postJsonToApi3","combineHeaders3","encoding_format","dimensions","createJsonResponseHandler3","openaiTextEmbeddingResponseSchema","embeddings","item","embedding","z4.object","z4.array","z4.number","modelMaxImagesPerCall","hasDefaultResponseFormat","Set","OpenAIImageModel","maxImagesPerCall","n","aspectRatio","currentDate","_internal","call","postJsonToApi4","combineHeaders4","has","createJsonResponseHandler4","openaiImageResponseSchema","images","b64_json","z5.object","z5.array","z5.string","openAIProviderOptionsSchema","z6.object","include","z6.array","z6.string","language","z6.number","min","max","default","timestampGranularities","z6.enum","languageMap","afrikaans","arabic","armenian","azerbaijani","belarusian","bosnian","bulgarian","catalan","chinese","croatian","czech","danish","dutch","english","estonian","finnish","french","galician","german","greek","hebrew","hindi","hungarian","icelandic","indonesian","italian","japanese","kannada","kazakh","korean","latvian","lithuanian","macedonian","malay","marathi","maori","nepali","norwegian","persian","polish","portuguese","romanian","russian","serbian","slovak","slovenian","spanish","swahili","swedish","tagalog","tamil","thai","turkish","ukrainian","urdu","vietnamese","welsh","OpenAITranscriptionModel","audio","mediaType","openAIOptions","formData","FormData","blob","Blob","append","File","transcriptionModelOptions","timestamp_granularities","postFormDataToApi","combineHeaders5","createJsonResponseHandler5","openaiTranscriptionResponseSchema","segments","words","word","startSecond","endSecond","end","durationInSeconds","duration","mapOpenAIResponseFinishReason","hasToolCalls","OpenAIResponsesLanguageModel","modelConfig","requiredAutoTruncation","getResponsesModelConfig","convertUint8ArrayToBase642","UnsupportedFunctionalityError6","call_id","output","convertToOpenAIResponsesMessages","openaiOptions","parseProviderOptions2","openaiResponsesProviderOptionsSchema","isStrict","strictSchemas","max_output_tokens","previous_response_id","previousResponseId","instructions","reasoningSummary","reasoning","effort","summary","truncation","search_context_size","searchContextSize","user_location","userLocation","UnsupportedFunctionalityError7","prepareResponsesTools","postJsonToApi5","combineHeaders6","createJsonResponseHandler6","z7.object","z7.string","created_at","z7.number","z7.array","z7.discriminatedUnion","z7.literal","annotations","start_index","end_index","title","incomplete_details","reason","usageSchema","APICallError","outputTextElements","flatMap","find","sources","annotation","_b2","_c2","sourceType","generateId2","input_tokens","output_tokens","responseId","input_tokens_details","output_tokens_details","createEventSourceResponseHandler3","openaiResponsesChunkSchema","self","ongoingToolCalls","isResponseOutputItemAddedChunk","output_index","isResponseFunctionCallArgumentsDeltaChunk","isResponseCreatedChunk","isTextDeltaChunk","isResponseReasoningSummaryTextDeltaChunk","isResponseOutputItemDoneChunk","isResponseFinishedChunk","isResponseAnnotationAddedChunk","isErrorChunk","source","z7.union","z7.enum","item_id","summary_index","sequence_number","passthrough","z7.any","z7.boolean","WebSearchPreviewParameters","z8.object","openaiTools","webSearchPreview","OpenAIProviderOptionsSchema","z9.object","z9.string","speed","z9.number","OpenAISpeechModel","voice","outputFormat","parseProviderOptions3","requestBody","speechModelOptions","postJsonToApi6","combineHeaders7","arrayBuffer","createOpenAI","baseURL","providerName","getHeaders","Authorization","organization","project","createChatModel","createCompletionModel","createEmbeddingModel","createImageModel","createTranscriptionModel","createSpeechModel","createLanguageModel","languageModel","chat","completion","responses","textEmbedding","textEmbeddingModel","imageModel","transcription","transcriptionModel","speech","speechModel"],"mappings":"6NACA,SAASA,KAAkBC,GACzB,OAAOA,EAAQC,OACb,CAACC,EAAiBC,KAAA,IACbD,KACkB,MAAlBC,EAAyBA,EAAiB,CAAA,IAE/C,CAAA,EAEJ,CAqCA,SAASC,IACP,IACIC,EAEAC,EACAC,EAJAC,EAAS,GAETC,EAAO,GAGX,SAASC,EAAUC,EAAMC,GACvB,GAAa,KAATD,EAEF,YADAE,EAAcD,GAGhB,GAAID,EAAKG,WAAW,KAClB,OAEF,MAAMC,EAAaJ,EAAKK,QAAQ,KAChC,IAAmB,IAAfD,EAEF,YADAE,EAAYN,EAAM,IAGpB,MACMO,EAAaH,EAAa,EAEhCE,EAHcN,EAAKQ,MAAM,EAAGJ,GAEdG,EAAaP,EAAKS,QAA+B,MAArBT,EAAKO,GAAsBP,EAAKQ,MAAMD,EAAa,GAAKP,EAAKQ,MAAMD,GACrF,CAE1B,SAASL,EAAcD,GACjBH,EAAKW,OAAS,IAChBR,EAAWS,QAAQ,CACjBhB,QACAI,KAAMA,EAAKa,KAAK,MAChBC,GAAIjB,EACJC,UAEFE,EAAO,GACPJ,OAAQ,EACRE,OAAQ,EACV,CAEF,SAASU,EAAYO,EAAOC,GAC1B,OAAQD,GACN,IAAK,QACHnB,EAAQoB,EACR,MACF,IAAK,OACHhB,EAAKiB,KAAKD,GACV,MACF,IAAK,KACHnB,EAAcmB,EACd,MACF,IAAK,QACH,MAAME,EAAcC,SAASH,EAAO,IAC/BI,MAAMF,KACTpB,EAAQoB,GAGd,CAEF,OAAO,IAAIG,gBAAgB,CACzB,SAAAC,CAAUC,EAAOpB,GACf,MAAMqB,MAAEA,EAAAC,eAAOA,GAYrB,SAAoB1B,EAAQwB,GAC1B,MAAMC,EAAQ,GACd,IAAIE,EAAc3B,EAClB,IAAA,IAAS4B,EAAI,EAAGA,EAAIJ,EAAMZ,QAAU,CAClC,MAAMiB,EAAOL,EAAMI,KACN,OAATC,GACFJ,EAAMP,KAAKS,GACXA,EAAc,IACI,OAATE,GACTJ,EAAMP,KAAKS,GACXA,EAAc,GACG,OAAbH,EAAMI,IACRA,KAGFD,GAAeE,CACjB,CAEF,MAAO,CAAEJ,QAAOC,eAAgBC,EAClC,CA/BwCG,CAAW9B,EAAQwB,GACrDxB,EAAS0B,EACT,IAAA,IAASE,EAAI,EAAGA,EAAIH,EAAMb,OAAQgB,IAChC1B,EAAUuB,EAAMG,GAAIxB,EACtB,EAEF,KAAA2B,CAAM3B,GACJF,EAAUF,EAAQI,GAClBC,EAAcD,EAAU,GAG9B,CAuBA,SAAS4B,EAAuBC,GAC9B,MAAMzC,EAAU,CAAA,EAIhB,OAHAyC,EAASzC,QAAQ0C,QAAQ,CAACjB,EAAOkB,KAC/B3C,EAAQ2C,GAAOlB,IAEVzB,CACT,CAKA,IAkBI4C,EAlBoB,GACtBC,SACAC,KAAMC,EAAc,GACpBC,WAAW,iEACXC,YAAY,KACV,MACF,MAAMC,EAAYC,EAAeH,EAAUD,GAC3C,GAAc,MAAVF,EACF,OAAOK,EAET,GAAIF,EAASI,SAASH,GACpB,MAAM,IAAII,EAAqB,CAC7BC,SAAU,YACVC,QAAS,kBAAkBN,wCAAgDD,QAG/E,OAAQF,GAAS,GAAGD,IAASI,IAAYC,EAAUJ,MAEpCU,GA2BjB,SAASC,EAAaC,GACpB,OAAOA,aAAiBC,QAAyB,eAAfD,EAAME,MAAwC,iBAAfF,EAAME,KACzE,CAqFA,SAASC,GAAWC,OAClBA,EAAAC,wBACAA,EAAAC,oBACAA,EAAsB,SAAAC,YACtBA,IAEA,GAAsB,iBAAXH,EACT,OAAOA,EAET,GAAc,MAAVA,EACF,MAAM,IAAII,EAAgB,CACxBX,QAAS,GAAGU,gCAGhB,GAAuB,oBAAZE,QACT,MAAM,IAAID,EAAgB,CACxBX,QAAS,GAAGU,4CAAsDD,8EAItE,GAAc,OADdF,EAASM,EAAYL,IAEnB,MAAM,IAAIG,EAAgB,CACxBX,QAAS,GAAGU,4CAAsDD,uBAAyCD,4BAG/G,GAAsB,iBAAXD,EACT,MAAM,IAAII,EAAgB,CACxBX,QAAS,GAAGU,gDAA0DF,4CAG1E,OAAOD,CACT,CAkEA,IAAIO,EAAkBC,OAAOC,IAAI,uBAOjC,SAASC,EAAY/C,GACnB,OAJF,SAAqBA,GACnB,MAAwB,iBAAVA,GAAgC,OAAVA,GAAkB4C,KAAmB5C,IAAoC,IAA3BA,EAAM4C,IAA6B,aAAc5C,CACrI,CAESgD,CAAYhD,GAASA,GAERiD,EAF6BjD,EAPhCkD,EAUClD,IAChB,MAAMmD,EAASF,EAAUG,UAAUpD,GACnC,OAAOmD,EAAOE,QAAU,CAAEA,SAAS,EAAMrD,MAAOmD,EAAOnE,MAAS,CAAEqE,SAAS,EAAOpB,MAAOkB,EAAOlB,QAX3F,CAAEW,CAACA,IAAkB,EAAMM,aAQpC,IAAsBD,EATHC,CAQnB,CAmBA,SAASI,GAAkBtD,MACzBA,EAAAuD,OACAA,IAEA,MAAMC,EAAaT,EAAYQ,GAC/B,IACE,GAA2B,MAAvBC,EAAWN,SACb,MAAO,CAAEG,SAAS,EAAMrD,SAE1B,MAAMmD,EAASK,EAAWN,SAASlD,GACnC,OAAImD,EAAOE,QACFF,EAEF,CACLE,SAAS,EACTpB,MAAOwB,EAAoBC,KAAK,CAAE1D,QAAO2D,MAAOR,EAAOlB,QACzD,OACOA,GACP,MAAO,CACLoB,SAAS,EACTpB,MAAOwB,EAAoBC,KAAK,CAAE1D,QAAO2D,MAAO1B,IAClD,CAEJ,CAGA,SAAS2B,GAAUC,KACjBA,EAAAN,OACAA,IAEA,IACE,MAAMvD,EAAQ8D,EAAWC,MAAMF,GAC/B,OAAc,MAAVN,EACKvD,EA3Cb,UAAuBA,MACrBA,EACAuD,OAAQS,IAER,MAAMb,EAASG,EAAkB,CAAEtD,QAAOuD,OAAQS,IAClD,IAAKb,EAAOE,QACV,MAAMI,EAAoBC,KAAK,CAAE1D,QAAO2D,MAAOR,EAAOlB,QAExD,OAAOkB,EAAOnD,KAChB,CAoCWiE,CAAc,CAAEjE,QAAOuD,UAAQ,OAC/BtB,GACP,GAAIiC,EAAeC,WAAWlC,IAAUmC,EAAqBD,WAAWlC,GACtE,MAAMA,EAER,MAAM,IAAIiC,EAAe,CAAEL,OAAMF,MAAO1B,GAAO,CAEnD,CACA,SAASoC,GAAcR,KACrBA,EAAAN,OACAA,IAEA,IACE,MAAMvD,EAAQ8D,EAAWC,MAAMF,GAC/B,GAAc,MAAVN,EACF,MAAO,CAAEF,SAAS,EAAMrD,QAAOsE,SAAUtE,GAE3C,MAAMuE,EAAmBjB,EAAkB,CAAEtD,QAAOuD,WACpD,OAAOgB,EAAiBlB,QAAU,IAAKkB,EAAkBD,SAAUtE,GAAUuE,CAAA,OACtEtC,GACP,MAAO,CACLoB,SAAS,EACTpB,MAAOiC,EAAeC,WAAWlC,GAASA,EAAQ,IAAIiC,EAAe,CAAEL,OAAMF,MAAO1B,IACtF,CAEJ,CACA,SAASuC,EAAeC,GACtB,IAEE,OADAX,EAAWC,MAAMU,IACV,CAAA,OACAC,GACP,OAAO,CAAA,CAEX,CAIA,SAASC,GAAqBC,SAC5BA,EAAAC,gBACAA,EAAAtB,OACAA,IAEA,GAAsE,OAA9C,MAAnBsB,OAA0B,EAASA,EAAgBD,IACtD,OAEF,MAAME,EAAwBxB,EAAkB,CAC9CtD,MAAO6E,EAAgBD,GACvBrB,WAEF,IAAKuB,EAAsBzB,QACzB,MAAM,IAAI0B,EAAsB,CAC9BlD,SAAU,kBACVC,QAAS,WAAW8C,qBACpBjB,MAAOmB,EAAsB7C,QAGjC,OAAO6C,EAAsB9E,KAC/B,CAIA,IAAIgF,EAAoB,IAAMC,WAAWC,MACrCC,EAAgBC,OAClBC,MACA9G,UACA+G,OACAC,wBACAC,4BACAC,cACAP,WACIQ,EAAU,CACdL,MACA9G,QAAS,CACP,eAAgB,sBACbA,GAEL+G,KAAM,CACJK,QAASC,KAAKC,UAAUP,GACxBQ,OAAQR,GAEVC,wBACAC,4BACAC,cACAP,UAsBEQ,EAAYN,OACdC,MACA9G,UAAU,CAAA,EACV+G,OACAE,4BACAD,wBACAE,cACAP,QAAQF,QAER,IACE,MAAMhE,QAAiBkE,EAAMG,EAAK,CAChCU,OAAQ,OACRxH,SAnX0ByH,EAmXMzH,EAlX7B0H,OAAOC,YACZD,OAAOE,QAAQH,GAAQI,OAAO,EAAEC,EAAMrG,KAAoB,MAATA,KAkX/CsF,KAAMA,EAAKK,QACXW,OAAQb,IAEJc,EAAkBxF,EAAuBC,GAC/C,IAAKA,EAASwF,GAAI,CAChB,IAAIC,EACJ,IACEA,QAAyBlB,EAAsB,CAC7CvE,WACAqE,MACAqB,kBAAmBpB,EAAKQ,QACzB,OACM7D,GACP,GAAID,EAAaC,IAAU0E,EAAcxC,WAAWlC,GAClD,MAAMA,EAER,MAAM,IAAI0E,EAAc,CACtB7E,QAAS,mCACT6B,MAAO1B,EACP2E,WAAY5F,EAAS6F,OACrBxB,MACAkB,kBACAG,kBAAmBpB,EAAKQ,QACzB,CAEH,MAAMW,EAAiBzG,KAAA,CAEzB,IACE,aAAawF,EAA0B,CACrCxE,WACAqE,MACAqB,kBAAmBpB,EAAKQ,QACzB,OACM7D,GACP,GAAIA,aAAiBC,QACfF,EAAaC,IAAU0E,EAAcxC,WAAWlC,IAClD,MAAMA,EAGV,MAAM,IAAI0E,EAAc,CACtB7E,QAAS,wCACT6B,MAAO1B,EACP2E,WAAY5F,EAAS6F,OACrBxB,MACAkB,kBACAG,kBAAmBpB,EAAKQ,QACzB,CACH,OACO7D,GACP,GAAID,EAAaC,GACf,MAAMA,EAER,GAAIA,aAAiB6E,WAA+B,iBAAlB7E,EAAMH,QAA4B,CAClE,MAAM6B,EAAQ1B,EAAM0B,MACpB,GAAa,MAATA,EACF,MAAM,IAAIgD,EAAc,CACtB7E,QAAS,0BAA0B6B,EAAM7B,UACzC6B,QACA0B,MACAqB,kBAAmBpB,EAAKQ,OACxBiB,aAAa,GAGjB,CAEF,MAAM9E,CAAA,CArbV,IAAgC+D,GAyf5BgB,EAAoCC,GAAgB7B,OAASpE,eAC/D,MAAMuF,EAAkBxF,EAAuBC,GAC/C,GAAqB,MAAjBA,EAASsE,KACX,MAAM,IAAI4B,EAAuB,IAEnC,MAAO,CACLX,kBACAvG,MAAOgB,EAASsE,KAAK6B,YAAY,IAAIC,mBAAqBD,YAAYxI,KAAiCwI,YACrG,IAAI9G,gBAAgB,CAClB,SAAAC,EAAUtB,KAAEA,GAAQG,GACL,WAATH,GAGJG,EAAWS,QACTyE,EAAc,CACZR,KAAM7E,EACNuE,OAAQ0D,IAEZ,OAiCNI,EAA6BC,GAAmBlC,OAASpE,WAAUqE,MAAKqB,wBAC1E,MAAMa,QAAqBvG,EAAS6C,OAC9B2D,EAAenD,EAAc,CACjCR,KAAM0D,EACNhE,OAAQ+D,IAEJf,EAAkBxF,EAAuBC,GAC/C,IAAKwG,EAAanE,QAChB,MAAM,IAAIoE,EAAc,CACtB3F,QAAS,wBACT6B,MAAO6D,EAAavF,MACpB2E,WAAY5F,EAAS6F,OACrBN,kBACAgB,eACAlC,MACAqB,sBAGJ,MAAO,CACLH,kBACAvG,MAAOwH,EAAaxH,MACpBsE,SAAUkD,EAAalD,YAkDvBoD,KAAEA,EAAAC,KAAMA,GAAS1C,WACrB,SAAS2C,EAA0BC,GACjC,MAAMC,EAAYD,EAAaE,QAAQ,KAAM,KAAKA,QAAQ,KAAM,KAC1DC,EAAeL,EAAKG,GAC1B,OAAOG,WAAWC,KAAKF,EAAeG,GAASA,EAAKC,YAAY,GAClE,CACA,SAASC,EAA0BC,GACjC,IAAIN,EAAe,GACnB,IAAA,IAASrH,EAAI,EAAGA,EAAI2H,EAAM3I,OAAQgB,IAChCqH,GAAgBO,OAAOC,cAAcF,EAAM3H,IAE7C,OAAO+G,EAAKM,EACd,CCvnBA,SAASS,EAA4BC,GACnC,IAAIC,EAAIC,EACR,OAOQ,OAPAA,EAA4D,OAAtDD,EAAiB,MAAZD,OAAmB,EAASA,EAAS/C,cAAmB,EAASgD,EAAGE,IAAI,EAAGC,QAAOC,UAASC,oBAC5GF,QACAC,UACAE,YAAaD,EAAeA,EAAaH,IAAI,EAAGC,MAAOI,EAAQH,QAASI,OACtEL,MAAOI,EACPH,QAASI,KACL,OACOP,OAAK,CACtB,CAGA,SAASQ,EAAsBC,GAC7B,OAAQA,GACN,IAAK,OACH,MAAO,OACT,IAAK,SACH,MAAO,SACT,IAAK,iBACH,MAAO,iBACT,IAAK,gBACL,IAAK,aACH,MAAO,aACT,QACE,MAAO,UAEb,CAKA,IAAIC,EAAwBC,EAAS,CACnCtH,MAAOsH,EAAS,CACdzH,QAAS0H,IAITC,KAAMD,IAAWE,UACjBC,MAAOC,IAAQF,UACfG,KAAMC,EAAQ,CAACN,IAAYO,MAAaL,cAGxCM,EDgZiC,GACnCC,cACAC,iBACAnD,iBACI3B,OAASpE,WAAUqE,MAAKqB,wBAC5B,MAAMa,QAAqBvG,EAAS6C,OAC9B0C,EAAkBxF,EAAuBC,GAC/C,GAA4B,KAAxBuG,EAAa4C,OACf,MAAO,CACL5D,kBACAvG,MAAO,IAAIyH,EAAc,CACvB3F,QAASd,EAASoJ,WAClB/E,MACAqB,oBACAE,WAAY5F,EAAS6F,OACrBN,kBACAgB,eACAR,YAA4B,MAAfA,OAAsB,EAASA,EAAY/F,MAI9D,IACE,MAAMqJ,EAAczG,EAAU,CAC5BC,KAAM0D,EACNhE,OAAQ0G,IAEV,MAAO,CACL1D,kBACAvG,MAAO,IAAIyH,EAAc,CACvB3F,QAASoI,EAAeG,GACxBhF,MACAqB,oBACAE,WAAY5F,EAAS6F,OACrBN,kBACAgB,eACAvI,KAAMqL,EACNtD,YAA4B,MAAfA,OAAsB,EAASA,EAAY/F,EAAUqJ,KAEtE,OACOC,GACP,MAAO,CACL/D,kBACAvG,MAAO,IAAIyH,EAAc,CACvB3F,QAASd,EAASoJ,WAClB/E,MACAqB,oBACAE,WAAY5F,EAAS6F,OACrBN,kBACAgB,eACAR,YAA4B,MAAfA,OAAsB,EAASA,EAAY/F,KAE5D,GCnc8BuJ,CAA+B,CAC/DN,YAAaX,EACbY,eAAiBlL,GAASA,EAAKiD,MAAMH,UAIvC,SAAS0I,GAAoB1K,GAC3BA,EAAA2K,MACAA,EAAAC,QACAA,IAEA,MAAO,CACL5K,GAAU,MAANA,EAAaA,OAAK,EACtB6K,QAAkB,MAATF,EAAgBA,OAAQ,EACjCG,UAAsB,MAAXF,EAAkB,IAAIG,KAAe,IAAVH,QAAiB,EAE3D,CA0GA,IAAII,EAA0B,MAC5B,WAAAC,CAAYJ,EAASK,EAAUC,GAC7BC,KAAKC,qBAAuB,KAC5BD,KAAKP,QAAUA,EACfO,KAAKF,SAAWA,EAChBE,KAAKD,OAASA,CAClB,CACE,6BAAIG,GACF,IAAIzC,EACJ,OAAiD,OAAzCA,EAAKuC,KAAKF,SAASK,mBAA6B1C,EAAK2C,GAAiBJ,KAAKP,QACvF,CACE,+BAAIY,GACF,OAAiBL,KAAKP,QAoqBTtL,WAAW,wBAnqBf,OAEF6L,KAAKE,0BAA4B,OAAS,MACrD,CACE,YAAIxG,GACF,OAAOsG,KAAKD,OAAOrG,QACvB,CACE,qBAAI4G,GACF,OAAQN,KAAKF,SAASS,cAC1B,CACE,OAAAC,EAAQC,KACNA,EAAAC,OACAA,EAAAC,UACAA,EAAAC,YACAA,EAAAC,KACAA,EAAAC,KACAA,EAAAC,iBACAA,EAAAC,gBACAA,EAAAC,cACAA,EAAAC,eACAA,EAAAC,KACAA,EAAAC,iBACAA,IAEA,IAAI3D,EAAIC,EAAI2D,EAAIC,EAAIC,EAAIC,EAAIC,EAAIC,EAChC,MAAMnD,EAAOkC,EAAKlC,KACZoD,EAAW,GACL,MAARb,GACFa,EAAS5M,KAAK,CACZwJ,KAAM,sBACNqD,QAAS,SAGmD,UAAzC,MAAlBV,OAAyB,EAASA,EAAe3C,OAA6C,MAAzB2C,EAAe7I,QAAmB2H,KAAKE,2BAC/GyB,EAAS5M,KAAK,CACZwJ,KAAM,sBACNqD,QAAS,iBACTC,QAAS,yEAGb,MAAMC,EAA2B9B,KAAKF,SAASgC,yBAC/C,GAAIA,IAAgE,IAApC9B,KAAKF,SAASiC,kBAC5C,MAAM,IAAIC,EAA+B,CACvCC,cAAe,oDAGnB,GAAIH,GAA4B9B,KAAKE,0BACnC,MAAM,IAAI8B,EAA+B,CACvCC,cAAe,oDAGnB,MAAMC,SAAEA,EAAUP,SAAUQ,GA9YhC,UAAqCzB,OACnCA,EAAAoB,yBACAA,GAA2B,EAAAM,kBAC3BA,EAAoB,WAEpB,MAAMF,EAAW,GACXP,EAAW,GACjB,IAAA,MAAWU,KAAEA,EAAA5H,QAAMA,KAAaiG,EAC9B,OAAQ2B,GACN,IAAK,SACH,OAAQD,GACN,IAAK,SACHF,EAASnN,KAAK,CAAEsN,KAAM,SAAU5H,YAChC,MAEF,IAAK,YACHyH,EAASnN,KAAK,CAAEsN,KAAM,YAAa5H,YACnC,MAEF,IAAK,SACHkH,EAAS5M,KAAK,CACZwJ,KAAM,QACN3H,QAAS,+CAEX,MAEF,QAEE,MAAM,IAAII,MACR,oCAFuBoL,KAM7B,MAEF,IAAK,OACH,GAAuB,IAAnB3H,EAAQhG,QAAoC,SAApBgG,EAAQ,GAAG8D,KAAiB,CACtD2D,EAASnN,KAAK,CAAEsN,KAAM,OAAQ5H,QAASA,EAAQ,GAAG9B,OAClD,KACV,CACQuJ,EAASnN,KAAK,CACZsN,KAAM,OACN5H,QAASA,EAAQkD,IAAI,CAAC2E,EAAMC,KAC1B,IAAI9E,EAAIC,EAAI2D,EAAIC,EAChB,OAAQgB,EAAK/D,MACX,IAAK,OACH,MAAO,CAAEA,KAAM,OAAQ5F,KAAM2J,EAAK3J,MAEpC,IAAK,QACH,MAAO,CACL4F,KAAM,YACNiE,UAAW,CACTrI,IAAKmI,EAAKG,iBAAiBC,IAAMJ,EAAKG,MAAME,WAAa,QAAgC,OAAvBlF,EAAK6E,EAAKM,UAAoBnF,EAAK,uBAAuBN,EAA0BmF,EAAKG,SAE3JI,OAA4E,OAAnExB,EAAqC,OAA/B3D,EAAK4E,EAAKlB,uBAA4B,EAAS1D,EAAGoF,aAAkB,EAASzB,EAAG0B,cAIrG,IAAK,OACH,GAAIT,EAAKxO,gBAAgB4O,IACvB,MAAM,IAAIM,EAA8B,CACtCf,cAAe,oEAGnB,OAAQK,EAAKM,UACX,IAAK,YACH,MAAO,CACLrE,KAAM,cACN0E,YAAa,CAAEnP,KAAMwO,EAAKxO,KAAMoP,OAAQ,QAG5C,IAAK,YACL,IAAK,aACH,MAAO,CACL3E,KAAM,cACN0E,YAAa,CAAEnP,KAAMwO,EAAKxO,KAAMoP,OAAQ,QAG5C,IAAK,kBACH,MAAO,CACL3E,KAAM,OACN4E,KAAM,CACJC,SAAkC,OAAvB9B,EAAKgB,EAAKc,UAAoB9B,EAAK,QAAQiB,QACtDc,UAAW,+BAA+Bf,EAAKxO,SAIrD,QACE,MAAM,IAAIkP,EAA8B,CACtCf,cAAe,0BAA0BK,EAAKM,oCAQ5D,MAEF,IAAK,YAAa,CAChB,IAAIjK,EAAO,GACX,MAAM2K,EAAY,GAClB,IAAA,MAAWhB,KAAQ7H,EACjB,OAAQ6H,EAAK/D,MACX,IAAK,OACH5F,GAAQ2J,EAAK3J,KACb,MAEF,IAAK,YACH2K,EAAUvO,KAAK,CACbH,GAAI0N,EAAKiB,WACThF,KAAM,WACNiF,SAAU,CACRvM,KAAMqL,EAAKmB,SACXC,UAAWhJ,KAAKC,UAAU2H,EAAKqB,SAOzC,GAAI7B,EAA0B,CAC5B,GAAIwB,EAAU7O,OAAS,EACrB,MAAM,IAAIuO,EAA8B,CACtCf,cAAe,qEAGnBC,EAASnN,KAAK,CACZsN,KAAM,YACN5H,QAAS9B,EACTiL,cAAeN,EAAU7O,OAAS,EAAI6O,EAAU,GAAGE,cAAW,GAE1E,MACUtB,EAASnN,KAAK,CACZsN,KAAM,YACN5H,QAAS9B,EACTkL,WAAYP,EAAU7O,OAAS,EAAI6O,OAAY,IAGnD,KACR,CACM,IAAK,OACH,IAAA,MAAWQ,KAAgBrJ,EACrBqH,EACFI,EAASnN,KAAK,CACZsN,KAAM,WACNpL,KAAM6M,EAAaL,SACnBhJ,QAASC,KAAKC,UAAUmJ,EAAa7L,UAGvCiK,EAASnN,KAAK,CACZsN,KAAM,OACN0B,aAAcD,EAAaP,WAC3B9I,QAASC,KAAKC,UAAUmJ,EAAa7L,UAI3C,MAEF,QAEE,MAAM,IAAIjB,MAAM,qBADSqL,KAK/B,MAAO,CAAEH,WAAUP,WACrB,CAwOoDqC,CAC9C,CACEtD,SACAoB,2BACAM,kBAAmB6B,GAAqBjE,KAAKP,WAGjDkC,EAAS5M,QAAQoN,GACjB,MAAM+B,EAAW,CAEf3E,MAAOS,KAAKP,QAEZ0E,WAAYnE,KAAKF,SAASsE,UAC1B5G,UAAqC,IAA3BwC,KAAKF,SAAStC,UAAuD,iBAA3BwC,KAAKF,SAAStC,eAA+B,EACjGM,aAAgD,iBAA3BkC,KAAKF,SAAStC,SAAwBwC,KAAKF,SAAStC,SAA6C,kBAA3BwC,KAAKF,SAAStC,UAAyBwC,KAAKF,SAAStC,SAAW,OAAa,EACxK6G,KAAMrE,KAAKF,SAASuE,KACpBC,oBAAqBtE,KAAKF,SAASiC,kBAEnCwC,WAAY5D,EACZC,cACA4D,MAAO3D,EACP4D,kBAAmB1D,EACnB2D,iBAAkB1D,EAClB2D,gBAA6E,UAAzC,MAAlBzD,OAAyB,EAASA,EAAe3C,MAAmByB,KAAKE,2BAAsD,MAAzBgB,EAAe7I,OAAiB,CACtJkG,KAAM,cACNqG,YAAa,CACXvM,OAAQ6I,EAAe7I,OACvBwM,QAAQ,EACR5N,KAAoC,OAA7BwG,EAAKyD,EAAejK,MAAgBwG,EAAK,WAChDnG,YAAa4J,EAAe5J,cAE5B,CAAEiH,KAAM,oBAAkB,EAC9BuG,KAAM7D,EACNE,OAGA4D,sBAA6F,OAArErH,EAAyB,MAApB0D,OAA2B,EAASA,EAAiB0B,aAAkB,EAASpF,EAAGsH,oBAChHC,MAA6E,OAArE5D,EAAyB,MAApBD,OAA2B,EAASA,EAAiB0B,aAAkB,EAASzB,EAAG4D,MAChGC,SAAgF,OAArE5D,EAAyB,MAApBF,OAA2B,EAASA,EAAiB0B,aAAkB,EAASxB,EAAG4D,SACnGC,WAAkF,OAArE5D,EAAyB,MAApBH,OAA2B,EAASA,EAAiB0B,aAAkB,EAASvB,EAAG4D,WACrGC,iBAAqI,OAAlH3D,EAA2E,OAArED,EAAyB,MAApBJ,OAA2B,EAASA,EAAiB0B,aAAkB,EAAStB,EAAG6D,iBAA2B5D,EAAKzB,KAAKF,SAASuF,gBAE/JnD,YAwEF,OAtEI9B,GAAiBJ,KAAKP,UACI,MAAxByE,EAAStD,cACXsD,EAAStD,iBAAc,EACvBe,EAAS5M,KAAK,CACZwJ,KAAM,sBACNqD,QAAS,cACTC,QAAS,uDAGS,MAAlBqC,EAASM,QACXN,EAASM,WAAQ,EACjB7C,EAAS5M,KAAK,CACZwJ,KAAM,sBACNqD,QAAS,OACTC,QAAS,gDAGqB,MAA9BqC,EAASO,oBACXP,EAASO,uBAAoB,EAC7B9C,EAAS5M,KAAK,CACZwJ,KAAM,sBACNqD,QAAS,mBACTC,QAAS,4DAGoB,MAA7BqC,EAASQ,mBACXR,EAASQ,sBAAmB,EAC5B/C,EAAS5M,KAAK,CACZwJ,KAAM,sBACNqD,QAAS,kBACTC,QAAS,2DAGc,MAAvBqC,EAASC,aACXD,EAASC,gBAAa,EACtBxC,EAAS5M,KAAK,CACZwJ,KAAM,QACN3H,QAAS,qDAGY,MAArBsN,EAAS1G,WACX0G,EAAS1G,cAAW,EACpBmE,EAAS5M,KAAK,CACZwJ,KAAM,QACN3H,QAAS,oDAGgB,MAAzBsN,EAASpG,eACXoG,EAASpG,kBAAe,EACxB6D,EAAS5M,KAAK,CACZwJ,KAAM,QACN3H,QAAS,uDAGc,MAAvBsN,EAASK,aAC2B,MAAlCL,EAASa,wBACXb,EAASa,sBAAwBb,EAASK,YAE5CL,EAASK,gBAAa,KAEfvE,KAAKP,QAAQtL,WAAW,0BAA4B6L,KAAKP,QAAQtL,WAAW,gCACzD,MAAxB+P,EAAStD,cACXsD,EAAStD,iBAAc,EACvBe,EAAS5M,KAAK,CACZwJ,KAAM,sBACNqD,QAAS,cACTC,QAAS,sFAIPtD,GACN,IAAK,UAAW,CACd,MAAM+G,MAAEA,EAAAC,YAAOA,EAAAC,UAAaA,gBAAW5B,EAAA6B,aAAeA,GAxR9D,UAAsBhF,KACpBA,EAAAqB,yBACAA,GAA2B,EAAA3B,kBAC3BA,IAEA,IAAI1C,EACJ,MAAM6H,GAA8B,OAApB7H,EAAKgD,EAAK6E,YAAiB,EAAS7H,EAAGhJ,QAAUgM,EAAK6E,WAAQ,EACxEG,EAAe,GACrB,GAAa,MAATH,EACF,MAAO,CAAEA,WAAO,EAAQC,iBAAa,EAAQE,gBAE/C,MAAMC,EAAajF,EAAKiF,WACxB,GAAI5D,EAA0B,CAC5B,MAAM6D,EAAkB,GACxB,IAAA,MAAWC,KAAQN,EACC,qBAAdM,EAAKrH,KACPkH,EAAa1Q,KAAK,CAAEwJ,KAAM,mBAAoBqH,SAE9CD,EAAgB5Q,KAAK,CACnBkC,KAAM2O,EAAK3O,KACXK,YAAasO,EAAKtO,YAClBuO,WAAYD,EAAKC,aAIvB,GAAkB,MAAdH,EACF,MAAO,CACLF,UAAWG,EACX/B,mBAAe,EACf6B,gBAIJ,OADcC,EAAWnH,MAEvB,IAAK,OACL,IAAK,OACL,UAAK,EACH,MAAO,CACLiH,UAAWG,EACX/B,mBAAe,EACf6B,gBAEJ,IAAK,WACH,MAAM,IAAIK,EAA+B,CACvC7D,cAAe,sDAEnB,QACE,MAAO,CACLuD,UAAWG,EACX/B,cAAe,CAAE3M,KAAMyO,EAAWjC,UAClCgC,gBAGV,CACE,MAAMM,EAAe,GACrB,IAAA,MAAWH,KAAQN,EACC,qBAAdM,EAAKrH,KACPkH,EAAa1Q,KAAK,CAAEwJ,KAAM,mBAAoBqH,SAE9CG,EAAahR,KAAK,CAChBwJ,KAAM,WACNiF,SAAU,CACRvM,KAAM2O,EAAK3O,KACXK,YAAasO,EAAKtO,YAClBuO,WAAYD,EAAKC,WACjBhB,SAAQ1E,QAA2B,KAK3C,GAAkB,MAAduF,EACF,MAAO,CAAEJ,MAAOS,EAAcR,iBAAa,EAAQE,gBAErD,MAAMlH,EAAOmH,EAAWnH,KACxB,OAAQA,GACN,IAAK,OACL,IAAK,OACL,IAAK,WACH,MAAO,CAAE+G,MAAOS,EAAcR,YAAahH,EAAMkH,gBACnD,IAAK,OACH,MAAO,CACLH,MAAOS,EACPR,YAAa,CACXhH,KAAM,WACNiF,SAAU,CACRvM,KAAMyO,EAAWjC,WAGrBgC,gBAEJ,QAEE,MAAM,IAAIK,EAA+B,CACvC7D,cAAe,iCAFQ1D,MAM/B,CAuL+EyH,CAAa,CAClFvF,OACAqB,2BACA3B,kBAAmBH,KAAKE,4BAE1B,MAAO,CACLyD,KAAM,IACDO,EACHoB,QACAC,cACAC,YACA5B,iBAEFjC,SAAU,IAAIA,KAAa8D,GAErC,CACM,IAAK,cACH,MAAO,CACL9B,KAAM,IACDO,EACHS,gBAAiB3E,KAAKE,2BAA4C,MAAfO,EAAKpI,OAAiB,CACvEkG,KAAM,cACNqG,YAAa,CACXvM,OAAQoI,EAAKpI,OACbwM,QAAQ,EACR5N,KAA0B,OAAnByK,EAAKjB,EAAKxJ,MAAgByK,EAAK,WACtCpK,YAAamJ,EAAKnJ,cAElB,CAAEiH,KAAM,gBAEdoD,YAGJ,IAAK,cACH,MAAO,CACLgC,KAAM7B,EAA2B,IAC5BoC,EACHN,cAAe,CACb3M,KAAMwJ,EAAKmF,KAAK3O,MAElBuO,UAAW,CACT,CACEvO,KAAMwJ,EAAKmF,KAAK3O,KAChBK,YAAamJ,EAAKmF,KAAKtO,YACvBuO,WAAYpF,EAAKmF,KAAKC,cAGxB,IACC3B,EACHqB,YAAa,CACXhH,KAAM,WACNiF,SAAU,CAAEvM,KAAMwJ,EAAKmF,KAAK3O,OAE9BqO,MAAO,CACL,CACE/G,KAAM,WACNiF,SAAU,CACRvM,KAAMwJ,EAAKmF,KAAK3O,KAChBK,YAAamJ,EAAKmF,KAAKtO,YACvBuO,WAAYpF,EAAKmF,KAAKC,WACtBhB,SAAQ7E,KAAKE,gCAAmC,MAKxDyB,YAGJ,QAEE,MAAM,IAAI3K,MAAM,qBADSuH,KAIjC,CACE,gBAAM0H,CAAWC,GACf,IAAIzI,EAAIC,EAAI2D,EAAIC,EAAIC,EAAIC,EAAIC,EAAIC,EAChC,MAAQiC,KAAMvJ,EAAAuH,SAAMA,GAAa3B,KAAKQ,QAAQ0F,IACxC7K,gBACJA,EACAvG,MAAOgB,EACPsD,SAAU+M,SACFlM,EAAc,CACtBE,IAAK6F,KAAKD,OAAO5F,IAAI,CACnBiM,KAAM,oBACN3G,QAASO,KAAKP,UAEhBpM,QAASD,EAAe4M,KAAKD,OAAO1M,UAAW6S,EAAQ7S,SACvD+G,OACAC,sBAAuByE,EACvBxE,0BAA2B6B,EACzBkK,GAEF9L,YAAa2L,EAAQ3L,YACrBP,MAAOgG,KAAKD,OAAO/F,SAEbkI,SAAUoE,KAAcC,GAAgBnM,EAC1CoM,EAAS1Q,EAAS2Q,QAAQ,GAC1BC,EAAkD,OAAxBjJ,EAAK3H,EAAS6Q,YAAiB,EAASlJ,EAAGmJ,0BACrEC,EAA8C,OAAxBnJ,EAAK5H,EAAS6Q,YAAiB,EAASjJ,EAAGoJ,sBACjE1F,EAAmB,CAAE0B,OAAQ,IAanC,OAZ2F,OAA5D,MAA1B4D,OAAiC,EAASA,EAAuBK,oBACpE3F,EAAiB0B,OAAOkE,gBAA4C,MAA1BN,OAAiC,EAASA,EAAuBK,kBAER,OAAtE,MAA1BL,OAAiC,EAASA,EAAuBO,8BACpE7F,EAAiB0B,OAAOoE,yBAAqD,MAA1BR,OAAiC,EAASA,EAAuBO,4BAEjB,OAAtE,MAA1BP,OAAiC,EAASA,EAAuBS,8BACpE/F,EAAiB0B,OAAOsE,yBAAqD,MAA1BV,OAAiC,EAASA,EAAuBS,4BAEtC,OAArD,MAAtBN,OAA6B,EAASA,EAAmBQ,iBAC5DjG,EAAiB0B,OAAOwE,mBAA2C,MAAtBT,OAA6B,EAASA,EAAmBQ,eAEjG,CACL1O,KAAuC,OAAhC0I,EAAKmF,EAAO5P,QAAQ6D,SAAmB4G,OAAK,EACnDiC,UAAWtD,KAAKF,SAASgC,0BAA4B0E,EAAO5P,QAAQgN,cAAgB,CAClF,CACE2D,aAAc,WACdhE,WAAYtN,IACZwN,SAAU+C,EAAO5P,QAAQgN,cAAc3M,KACvC0M,KAAM6C,EAAO5P,QAAQgN,cAAcF,YAEC,OAAnCpC,EAAKkF,EAAO5P,QAAQiN,iBAAsB,EAASvC,EAAG3D,IAAK6J,IAC9D,IAAIC,EACJ,MAAO,CACLF,aAAc,WACdhE,WAAmC,OAAtBkE,EAAMD,EAAS5S,IAAc6S,EAAMxR,IAChDwN,SAAU+D,EAAShE,SAASvM,KAC5B0M,KAAM6D,EAAShE,SAASE,aAG5BvF,aAAcD,EAAsBsI,EAAOkB,eAC3Cf,MAAO,CACLgB,aAAkF,OAAnEnG,EAA8B,OAAxBD,EAAKzL,EAAS6Q,YAAiB,EAASpF,EAAGqG,eAAyBpG,EAAKqG,IAC9FC,iBAA0F,OAAvEpG,EAA8B,OAAxBD,EAAK3L,EAAS6Q,YAAiB,EAASlF,EAAGsG,mBAA6BrG,EAAKmG,KAExGG,QAAS,CAAE1B,YAAWC,eACtBJ,YAAa,CAAE9S,QAASgI,EAAiBjB,KAAM+L,GAC/C8B,QAAS,CAAE7N,KAAMM,KAAKC,UAAUP,IAChCtE,SAAUwJ,EAAoBxJ,GAC9B6L,WACAnE,SAAUD,EAA4BiJ,EAAOhJ,UAC7C4D,mBAEN,CACE,cAAM8G,CAAShC,GACb,GAAIlG,KAAKF,SAASqI,kBAAmB,CACnC,MAAMlQ,QAAe+H,KAAKiG,WAAWC,GAmCrC,MAAO,CACLkC,OAnCsB,IAAIC,eAAe,CACzC,KAAAC,CAAMrU,GAQJ,GAPAA,EAAWS,QAAQ,CAAE6J,KAAM,uBAAwBtG,EAAOnC,WACtDmC,EAAOU,MACT1E,EAAWS,QAAQ,CACjB6J,KAAM,aACNgK,UAAWtQ,EAAOU,OAGlBV,EAAOqL,UACT,IAAA,MAAWkE,KAAYvP,EAAOqL,UAC5BrP,EAAWS,QAAQ,CACjB6J,KAAM,kBACNgJ,aAAc,WACdhE,WAAYiE,EAASjE,WACrBE,SAAU+D,EAAS/D,SACnB+E,cAAehB,EAAS7D,OAE1B1P,EAAWS,QAAQ,CACjB6J,KAAM,eACHiJ,IAITvT,EAAWS,QAAQ,CACjB6J,KAAM,SACNJ,aAAclG,EAAOkG,aACrBwI,MAAO1O,EAAO0O,MACdnJ,SAAUvF,EAAOuF,SACjB4D,iBAAkBnJ,EAAOmJ,mBAE3BnN,EAAWwU,OACrB,IAIQT,QAAS/P,EAAO+P,QAChB7B,YAAalO,EAAOkO,YACpBxE,SAAU1J,EAAO0J,SAEzB,CACI,MAAMgC,KAAEA,EAAAhC,SAAMA,GAAa3B,KAAKQ,QAAQ0F,GAClC9L,EAAO,IACRuJ,EACHyE,QAAQ,EAERM,eAA8C,WAA9B1I,KAAKD,OAAO4I,cAA6B,CAAEC,eAAe,QAAS,IAE/EvN,gBAAEA,EAAiBvG,MAAOgB,SAAmBmE,EAAc,CAC/DE,IAAK6F,KAAKD,OAAO5F,IAAI,CACnBiM,KAAM,oBACN3G,QAASO,KAAKP,UAEhBpM,QAASD,EAAe4M,KAAKD,OAAO1M,UAAW6S,EAAQ7S,SACvD+G,OACAC,sBAAuByE,EACvBxE,0BAA2BwB,EACzB+M,IAEFtO,YAAa2L,EAAQ3L,YACrBP,MAAOgG,KAAKD,OAAO/F,SAEbkI,SAAUoE,KAAcC,GAAgB5C,EAC1CL,EAAY,GAClB,IAKI9F,EALAW,EAAe,UACfwI,EAAQ,CACVgB,kBAAc,EACdG,sBAAkB,GAGhBgB,GAAe,EACnB,MAAMhH,yBAAEA,GAA6B9B,KAAKF,SACpCsB,EAAmB,CAAE0B,OAAQ,IACnC,MAAO,CACLsF,OAAQtS,EAASmG,YACf,IAAI9G,gBAAgB,CAClB,SAAAC,CAAUC,EAAOpB,GACf,IAAIwJ,EAAIC,EAAI2D,EAAIC,EAAIC,EAAIC,EAAIC,EAAIC,EAAIqH,EAAIC,EAAIC,EAAIC,EAChD,IAAK7T,EAAM8C,QAGT,OAFAgG,EAAe,aACflK,EAAWS,QAAQ,CAAE6J,KAAM,QAASxH,MAAO1B,EAAM0B,QAGnD,MAAMjC,EAAQO,EAAMP,MACpB,GAAI,UAAWA,EAGb,OAFAqJ,EAAe,aACflK,EAAWS,QAAQ,CAAE6J,KAAM,QAASxH,MAAOjC,EAAMiC,QAUnD,GAPI+R,IACFA,GAAe,EACf7U,EAAWS,QAAQ,CACjB6J,KAAM,uBACHe,EAAoBxK,MAGR,MAAfA,EAAM6R,MAAe,CACvB,MAAMiB,cACJA,EAAAG,kBACAA,EAAAjB,sBACAA,EAAAF,0BACAA,GACE9R,EAAM6R,MACVA,EAAQ,CACNgB,aAA+B,MAAjBC,EAAwBA,OAAgB,EACtDE,iBAAuC,MAArBC,EAA4BA,OAAoB,GAE6B,OAA/D,MAA7BnB,OAAoC,EAASA,EAA0BG,oBAC1E3F,EAAiB0B,OAAOkE,gBAA+C,MAA7BJ,OAAoC,EAASA,EAA0BG,kBAER,OAAzE,MAA7BH,OAAoC,EAASA,EAA0BK,8BAC1E7F,EAAiB0B,OAAOoE,yBAAwD,MAA7BN,OAAoC,EAASA,EAA0BK,4BAEjB,OAAzE,MAA7BL,OAAoC,EAASA,EAA0BO,8BAC1E/F,EAAiB0B,OAAOsE,yBAAwD,MAA7BR,OAAoC,EAASA,EAA0BO,4BAEtC,OAAxD,MAAzBL,OAAgC,EAASA,EAAsBO,iBAClEjG,EAAiB0B,OAAOwE,mBAA8C,MAAzBR,OAAgC,EAASA,EAAsBO,cAE5H,CACY,MAAMb,EAAS1R,EAAM2R,QAAQ,GAI7B,GAHwD,OAAzC,MAAVD,OAAiB,EAASA,EAAOkB,iBACpCvJ,EAAeD,EAAsBsI,EAAOkB,gBAEE,OAAjC,MAAVlB,OAAiB,EAASA,EAAO2C,OACpC,OAEF,MAAMA,EAAQ3C,EAAO2C,MACA,MAAjBA,EAAM1O,SACRxG,EAAWS,QAAQ,CACjB6J,KAAM,aACNgK,UAAWY,EAAM1O,UAGrB,MAAM2O,EAAiB7L,EACX,MAAViJ,OAAiB,EAASA,EAAOhJ,WAEb,MAAlB4L,OAAyB,EAASA,EAAe3U,eAClC,IAAb+I,IAAqBA,EAAW,IACpCA,EAASzI,QAAQqU,IAEnB,MAAMC,EAAkBvH,GAAmD,MAAvBqH,EAAMvF,cAAwB,CAChF,CACErF,KAAM,WACN3J,GAAIqB,IACJuN,SAAU2F,EAAMvF,cAChBrB,MAAO,IAEP4G,EAAMtF,WACV,GAAuB,MAAnBwF,EACF,IAAA,MAAWC,KAAiBD,EAAiB,CAC3C,MAAM9G,EAAQ+G,EAAc/G,MAC5B,GAAwB,MAApBe,EAAUf,GAAgB,CAC5B,GAA2B,aAAvB+G,EAAc/K,KAChB,MAAM,IAAIgL,EAAyB,CACjCzV,KAAMwV,EACN1S,QAAS,8BAGb,GAAwB,MAApB0S,EAAc1U,GAChB,MAAM,IAAI2U,EAAyB,CACjCzV,KAAMwV,EACN1S,QAAS,kCAGb,GAAkE,OAA5B,OAAhC6G,EAAK6L,EAAc9F,eAAoB,EAAS/F,EAAGxG,MACvD,MAAM,IAAIsS,EAAyB,CACjCzV,KAAMwV,EACN1S,QAAS,6CAGb0M,EAAUf,GAAS,CACjB3N,GAAI0U,EAAc1U,GAClB2J,KAAM,WACNiF,SAAU,CACRvM,KAAMqS,EAAc9F,SAASvM,KAC7ByM,UAAsD,OAA1ChG,EAAK4L,EAAc9F,SAASE,WAAqBhG,EAAK,IAEpE8L,aAAa,GAEf,MAAMC,EAAYnG,EAAUf,GACkC,OAA5B,OAA5BlB,EAAKoI,EAAUjG,eAAoB,EAASnC,EAAGpK,OAAgF,OAAjC,OAA5BqK,EAAKmI,EAAUjG,eAAoB,EAASlC,EAAGoC,aACjH+F,EAAUjG,SAASE,UAAUjP,OAAS,GACxCR,EAAWS,QAAQ,CACjB6J,KAAM,kBACNgJ,aAAc,WACdhE,WAAYkG,EAAU7U,GACtB6O,SAAUgG,EAAUjG,SAASvM,KAC7BuR,cAAeiB,EAAUjG,SAASE,YAGlCpK,EAAemQ,EAAUjG,SAASE,aACpCzP,EAAWS,QAAQ,CACjB6J,KAAM,YACNgJ,aAAc,WACdhE,WAAmC,OAAtBhC,EAAKkI,EAAU7U,IAAc2M,EAAKtL,IAC/CwN,SAAUgG,EAAUjG,SAASvM,KAC7B0M,KAAM8F,EAAUjG,SAASE,YAE3B+F,EAAUD,aAAc,IAG5B,QAClB,CACgB,MAAMhC,EAAWlE,EAAUf,GACvBiF,EAASgC,cAG0D,OAAjC,OAAhChI,EAAK8H,EAAc9F,eAAoB,EAAShC,EAAGkC,aACvD8D,EAAShE,SAASE,WAAqF,OAAvEhC,EAAsC,OAAhCD,EAAK6H,EAAc9F,eAAoB,EAAS/B,EAAGiC,WAAqBhC,EAAK,IAErHzN,EAAWS,QAAQ,CACjB6J,KAAM,kBACNgJ,aAAc,WACdhE,WAAYiE,EAAS5S,GACrB6O,SAAU+D,EAAShE,SAASvM,KAC5BuR,cAA0D,OAA1CO,EAAKO,EAAc9F,SAASE,WAAqBqF,EAAK,KAEX,OAA5B,OAA3BC,EAAKxB,EAAShE,eAAoB,EAASwF,EAAG/R,OAA+E,OAAjC,OAA3BgS,EAAKzB,EAAShE,eAAoB,EAASyF,EAAGvF,YAAsBpK,EAAekO,EAAShE,SAASE,aAC1KzP,EAAWS,QAAQ,CACjB6J,KAAM,YACNgJ,aAAc,WACdhE,WAAkC,OAArB2F,EAAK1B,EAAS5S,IAAcsU,EAAKjT,IAC9CwN,SAAU+D,EAAShE,SAASvM,KAC5B0M,KAAM6D,EAAShE,SAASE,YAE1B8D,EAASgC,aAAc,GAEzC,CAEA,EACU,KAAA5T,CAAM3B,GACJ,IAAIwJ,EAAIC,EACRzJ,EAAWS,QAAQ,CACjB6J,KAAM,SACNJ,eACAX,WACAmJ,MAAO,CACLgB,aAA2C,OAA5BlK,EAAKkJ,EAAMgB,cAAwBlK,EAAKoK,IACvDC,iBAAmD,OAAhCpK,EAAKiJ,EAAMmB,kBAA4BpK,EAAKmK,QAE1C,MAApBzG,EAA2B,CAAEA,oBAAqB,CAAA,GAEnE,KAGM4G,QAAS,CAAE1B,YAAWC,eACtBJ,YAAa,CAAE9S,QAASgI,GACxB4M,QAAS,CAAE7N,KAAMM,KAAKC,UAAUP,IAChCuH,WAEN,GAEI+H,EAAyBC,EAAU,CACrC/B,cAAegC,IAAYpL,UAC3BuJ,kBAAmB6B,IAAYpL,UAC/BsI,sBAAuB6C,EAAU,CAC/BtC,cAAeuC,IAAYpL,YAC1BA,UACHoI,0BAA2B+C,EAAU,CACnC5C,iBAAkB6C,IAAYpL,UAC9ByI,2BAA4B2C,IAAYpL,UACxC2I,2BAA4ByC,IAAYpL,YACvCA,YACFA,UACC6H,EAA2BsD,EAAU,CACvC/U,GAAIiV,IAAYrL,UAChBgB,QAASoK,IAAYpL,UACrBe,MAAOsK,IAAYrL,UACnBiI,QAASqD,EACPH,EAAU,CACR/S,QAAS+S,EAAU,CACjBtH,KAAM0H,EAAW,aAAavL,UAC9B/D,QAASoP,IAAYrL,UACrBoF,cAAe+F,EAAU,CACvBjG,UAAWmG,IACX5S,KAAM4S,MACLrL,UACHqF,WAAYiG,EACVH,EAAU,CACR/U,GAAIiV,IAAYrL,UAChBD,KAAMwL,EAAW,YACjBvG,SAAUmG,EAAU,CAClB1S,KAAM4S,IACNnG,UAAWmG,SAGfrL,YAEJ+D,MAAOqH,IACPpM,SAAUmM,EAAU,CAClBlP,QAASqP,EACPH,EAAU,CACR/L,MAAOiM,IACPhM,QAAS+L,IACT9L,aAAcgM,EACZH,EAAU,CACR/L,MAAOiM,IACPhM,QAAS+L,UAIfI,aACDxL,UACHkJ,cAAemC,IAAYrL,aAG/BmI,MAAO+C,IAELb,GAAwBoB,EAAS,CACnCN,EAAU,CACR/U,GAAIiV,IAAYrL,UAChBgB,QAASoK,IAAYpL,UACrBe,MAAOsK,IAAYrL,UACnBiI,QAASqD,EACPH,EAAU,CACRR,MAAOQ,EAAU,CACftH,KAAM6H,EAAQ,CAAC,cAAc1L,UAC7B/D,QAASoP,IAAYrL,UACrBoF,cAAe+F,EAAU,CACvB1S,KAAM4S,IAAYM,WAClBzG,UAAWmG,IAAYM,aACtB3L,UACHqF,WAAYiG,EACVH,EAAU,CACRpH,MAAOqH,IACPhV,GAAIiV,IAAYrL,UAChBD,KAAMwL,EAAW,YAAYvL,UAC7BgF,SAAUmG,EAAU,CAClB1S,KAAM4S,IAAYrL,UAClBkF,UAAWmG,IAAYrL,eAG3BA,YACDA,UACHhB,SAAUmM,EAAU,CAClBlP,QAASqP,EACPH,EAAU,CACR/L,MAAOiM,IACPhM,QAAS+L,IACT9L,aAAcgM,EACZH,EAAU,CACR/L,MAAOiM,IACPhM,QAAS+L,UAIfI,aACDxL,UACHkJ,cAAemC,IAAYrL,UAC3B+D,MAAOqH,OAGXjD,MAAO+C,IAETtL,IAEF,SAASgC,GAAiBX,GACxB,OAAOA,EAAQtL,WAAW,MAAQsL,EAAQtL,WAAW,QACvD,CAIA,SAAS8P,GAAqBxE,GAC5B,IAAIhC,EAAIC,EACR,OAAK0C,GAAiBX,GAGmE,OAAjF/B,EAAwC,OAAlCD,EAAK2M,GAAgB3K,SAAoB,EAAShC,EAAG2E,mBAA6B1E,EAAK,YAF5F,QAGX,CACA,IAAI0M,GAAkB,CACpB,UAAW,CACThI,kBAAmB,UAErB,qBAAsB,CACpBA,kBAAmB,UAErB,aAAc,CACZA,kBAAmB,UAErB,wBAAyB,CACvBA,kBAAmB,UAErBiI,GAAI,CACFjI,kBAAmB,aAErB,gBAAiB,CACfA,kBAAmB,aAErB,UAAW,CACTA,kBAAmB,aAErB,qBAAsB,CACpBA,kBAAmB,aAErB,UAAW,CACTA,kBAAmB,aAErB,qBAAsB,CACpBA,kBAAmB,cAwGvB,SAASkI,GAA4B9M,GACnC,OAAmB,MAAZA,OAAmB,EAASA,EAAS+M,OAAO5M,IAAI,CAACC,EAAO2E,KAAA,CAC7D3E,QACAC,QAASL,EAASgN,eAAejI,GACjCxE,YAAaP,EAASM,aAAe/C,OAAOE,QAAQuC,EAASM,aAAayE,IAAQ5E,IAChF,EAAEK,EAAQH,MAAO,CACfD,MAAOI,EACPH,aAEA,KAER,CAGA,IAAI4M,GAAgC,MAClC,WAAA5K,CAAYJ,EAASK,EAAUC,GAC7BC,KAAKC,qBAAuB,KAC5BD,KAAKK,iCAA8B,EACnCL,KAAKP,QAAUA,EACfO,KAAKF,SAAWA,EAChBE,KAAKD,OAASA,CAClB,CACE,YAAIrG,GACF,OAAOsG,KAAKD,OAAOrG,QACvB,CACE,OAAA8G,EAAQC,KACNA,EAAAiK,YACAA,EAAAhK,OACAA,EAAAC,UACAA,EAAAC,YACAA,EAAAC,KACAA,EAAAC,KACAA,EAAAC,iBACAA,EAAAC,gBACAA,EACAC,cAAe0J,EAAAzJ,eACfA,EAAAC,KACAA,IAEA,IAAI1D,EACJ,MAAMc,EAAOkC,EAAKlC,KACZoD,EAAW,GACL,MAARb,GACFa,EAAS5M,KAAK,CACZwJ,KAAM,sBACNqD,QAAS,SAGS,MAAlBV,GAAkD,SAAxBA,EAAe3C,MAC3CoD,EAAS5M,KAAK,CACZwJ,KAAM,sBACNqD,QAAS,iBACTC,QAAS,2CAGb,MAAQnB,OAAQkK,EAAA3J,cAAkBA,GA1ItC,UAAyCP,OACvCA,EAAAgK,YACAA,EAAArG,KACAA,EAAO,OAAAwG,UACPA,EAAY,cAEZ,GAAoB,WAAhBH,GAA8C,IAAlBhK,EAAOjM,QAAmC,SAAnBiM,EAAO,GAAG2B,MAAgD,IAA7B3B,EAAO,GAAGjG,QAAQhG,QAA8C,SAA9BiM,EAAO,GAAGjG,QAAQ,GAAG8D,KACzI,MAAO,CAAEmC,OAAQA,EAAO,GAAGjG,QAAQ,GAAG9B,MAExC,IAAIA,EAAO,GACY,WAAnB+H,EAAO,GAAG2B,OACZ1J,GAAQ,GAAG+H,EAAO,GAAGjG,cAGrBiG,EAASA,EAAOlM,MAAM,IAExB,IAAA,MAAW6N,KAAEA,EAAA5H,QAAMA,KAAaiG,EAC9B,OAAQ2B,GACN,IAAK,SACH,MAAM,IAAIyI,EAAmB,CAC3BlU,QAAS,kDACT8J,WAGJ,IAAK,OAaH/H,GAAQ,GAAG0L,OAZS5J,EAAQkD,IAAK2E,IAC/B,OAAQA,EAAK/D,MACX,IAAK,OACH,OAAO+D,EAAK3J,KAEd,IAAK,QACH,MAAM,IAAIoS,EAA+B,CACvC9I,cAAe,cAIpBtN,KAAK,UAKR,MAEF,IAAK,YAaHgE,GAAQ,GAAGkS,OAZcpQ,EAAQkD,IAAK2E,IACpC,OAAQA,EAAK/D,MACX,IAAK,OACH,OAAO+D,EAAK3J,KAEd,IAAK,YACH,MAAM,IAAIoS,EAA+B,CACvC9I,cAAe,0BAIpBtN,KAAK,UAKR,MAEF,IAAK,OACH,MAAM,IAAIoW,EAA+B,CACvC9I,cAAe,kBAGnB,QAEE,MAAM,IAAIjL,MAAM,qBADSqL,KAO/B,OAFA1J,GAAQ,GAAGkS,OAEJ,CACLnK,OAAQ/H,EACRsI,cAAe,CAAC,KAClBoD,MAEF,CA0DwD2G,CAAgC,CAAEtK,SAAQgK,gBACxF5F,EAAO,IAAqB,MAAjB7D,EAAwBA,EAAgB,MAA4B,MAArB0J,EAA4BA,EAAoB,IAC1GzG,EAAW,CAEf3E,MAAOS,KAAKP,QAEZwL,KAAMjL,KAAKF,SAASmL,KACpB9G,WAAYnE,KAAKF,SAASsE,UAC1B5G,SAA4C,iBAA3BwC,KAAKF,SAAStC,SAAwBwC,KAAKF,SAAStC,SAA6C,kBAA3BwC,KAAKF,SAAStC,UAAyBwC,KAAKF,SAAStC,SAAW,OAAa,EACpK0N,OAAQlL,KAAKF,SAASoL,OACtB7G,KAAMrE,KAAKF,SAASuE,KAEpBE,WAAY5D,EACZC,cACA4D,MAAO3D,EACP4D,kBAAmB1D,EACnB2D,iBAAkB1D,EAClBG,OAEAT,OAAQkK,EAER9F,KAAMA,EAAKrQ,OAAS,EAAIqQ,OAAO,GAEjC,OAAQvG,GACN,IAAK,UACH,GAAyB,OAApBd,EAAKgD,EAAK6E,YAAiB,EAAS7H,EAAGhJ,OAC1C,MAAM,IAAI0W,EAA+B,CACvClJ,cAAe,UAGnB,GAAIxB,EAAKiF,WACP,MAAM,IAAIyF,EAA+B,CACvClJ,cAAe,eAGnB,MAAO,CAAE0B,KAAMO,EAAUvC,YAE3B,IAAK,cACH,MAAM,IAAIwJ,EAA+B,CACvClJ,cAAe,qBAGnB,IAAK,cACH,MAAM,IAAIkJ,EAA+B,CACvClJ,cAAe,qBAGnB,QAEE,MAAM,IAAIjL,MAAM,qBADSuH,KAIjC,CACE,gBAAM0H,CAAWC,GACf,MAAMvC,KAAEA,EAAAhC,SAAMA,GAAa3B,KAAKQ,QAAQ0F,IAClC7K,gBACJA,EACAvG,MAAOgB,EACPsD,SAAU+M,SACFiF,EAAe,CACvBjR,IAAK6F,KAAKD,OAAO5F,IAAI,CACnBiM,KAAM,eACN3G,QAASO,KAAKP,UAEhBpM,QAASgY,EAAgBrL,KAAKD,OAAO1M,UAAW6S,EAAQ7S,SACxD+G,KAAMuJ,EACNtJ,sBAAuByE,EACvBxE,0BAA2BgR,EACzBC,IAEFhR,YAAa2L,EAAQ3L,YACrBP,MAAOgG,KAAKD,OAAO/F,SAEb0G,OAAQ4F,KAAcC,GAAgB5C,EACxC6C,EAAS1Q,EAAS2Q,QAAQ,GAChC,MAAO,CACL9N,KAAM6N,EAAO7N,KACbgO,MAAO,CACLgB,aAAc7R,EAAS6Q,MAAMiB,cAC7BE,iBAAkBhS,EAAS6Q,MAAMoB,mBAEnC5J,aAAcD,EAAsBsI,EAAOkB,eAC3ClK,SAAU8M,GAA4B9D,EAAOhJ,UAC7CwK,QAAS,CAAE1B,YAAWC,eACtBJ,YAAa,CAAE9S,QAASgI,EAAiBjB,KAAM+L,GAC/CrQ,SAAUwJ,EAAoBxJ,GAC9B6L,WACAsG,QAAS,CAAE7N,KAAMM,KAAKC,UAAUgJ,IAEtC,CACE,cAAMuE,CAAShC,GACb,MAAMvC,KAAEA,EAAAhC,SAAMA,GAAa3B,KAAKQ,QAAQ0F,GAClC9L,EAAO,IACRuJ,EACHyE,QAAQ,EAERM,eAA8C,WAA9B1I,KAAKD,OAAO4I,cAA6B,CAAEC,eAAe,QAAS,IAE/EvN,gBAAEA,EAAiBvG,MAAOgB,SAAmBsV,EAAe,CAChEjR,IAAK6F,KAAKD,OAAO5F,IAAI,CACnBiM,KAAM,eACN3G,QAASO,KAAKP,UAEhBpM,QAASgY,EAAgBrL,KAAKD,OAAO1M,UAAW6S,EAAQ7S,SACxD+G,OACAC,sBAAuByE,EACvBxE,0BAA2BkR,EACzBC,IAEFlR,YAAa2L,EAAQ3L,YACrBP,MAAOgG,KAAKD,OAAO/F,SAEb0G,OAAQ4F,KAAcC,GAAgB5C,EAC9C,IAKInG,EALAW,EAAe,UACfwI,EAAQ,CACVgB,aAAc+D,OAAO7D,IACrBC,iBAAkB4D,OAAO7D,KAGvBiB,GAAe,EACnB,MAAO,CACLV,OAAQtS,EAASmG,YACf,IAAI9G,gBAAgB,CAClB,SAAAC,CAAUC,EAAOpB,GACf,IAAKoB,EAAM8C,QAGT,OAFAgG,EAAe,aACflK,EAAWS,QAAQ,CAAE6J,KAAM,QAASxH,MAAO1B,EAAM0B,QAGnD,MAAMjC,EAAQO,EAAMP,MACpB,GAAI,UAAWA,EAGb,OAFAqJ,EAAe,aACflK,EAAWS,QAAQ,CAAE6J,KAAM,QAASxH,MAAOjC,EAAMiC,QAG/C+R,IACFA,GAAe,EACf7U,EAAWS,QAAQ,CACjB6J,KAAM,uBACHe,EAAoBxK,MAGR,MAAfA,EAAM6R,QACRA,EAAQ,CACNgB,aAAc7S,EAAM6R,MAAMiB,cAC1BE,iBAAkBhT,EAAM6R,MAAMoB,oBAGlC,MAAMvB,EAAS1R,EAAM2R,QAAQ,GAC2B,OAAzC,MAAVD,OAAiB,EAASA,EAAOkB,iBACpCvJ,EAAeD,EAAsBsI,EAAOkB,gBAEC,OAAhC,MAAVlB,OAAiB,EAASA,EAAO7N,OACpC1E,EAAWS,QAAQ,CACjB6J,KAAM,aACNgK,UAAW/B,EAAO7N,OAGtB,MAAMyQ,EAAiBkB,GACX,MAAV9D,OAAiB,EAASA,EAAOhJ,WAEb,MAAlB4L,OAAyB,EAASA,EAAe3U,eAClC,IAAb+I,IAAqBA,EAAW,IACpCA,EAASzI,QAAQqU,GAE/B,EACU,KAAAxT,CAAM3B,GACJA,EAAWS,QAAQ,CACjB6J,KAAM,SACNJ,eACAX,WACAmJ,SAEd,KAGMqB,QAAS,CAAE1B,YAAWC,eACtBJ,YAAa,CAAE9S,QAASgI,GACxBsG,WACAsG,QAAS,CAAE7N,KAAMM,KAAKC,UAAUP,IAEtC,GAEImR,GAAiCI,EAAU,CAC7C/W,GAAIgX,IAAYpN,UAChBgB,QAASqM,IAAYrN,UACrBe,MAAOqM,IAAYpN,UACnBiI,QAASqF,EACPH,EAAU,CACRhT,KAAMiT,IACNlE,cAAekE,IACfpO,SAAUmO,EAAU,CAClBpB,OAAQuB,EAASF,KACjBpB,eAAgBsB,EAASD,KACzB/N,aAAcgO,EAASC,EAAUH,IAAaC,MAAc7B,aAC3DxL,aAGPmI,MAAOgF,EAAU,CACf/D,cAAeiE,IACf9D,kBAAmB8D,QAGnBJ,GAA8BO,EAAS,CACzCL,EAAU,CACR/W,GAAIgX,IAAYpN,UAChBgB,QAASqM,IAAYrN,UACrBe,MAAOqM,IAAYpN,UACnBiI,QAASqF,EACPH,EAAU,CACRhT,KAAMiT,IACNlE,cAAekE,IAAYpN,UAC3B+D,MAAOsJ,IACPrO,SAAUmO,EAAU,CAClBpB,OAAQuB,EAASF,KACjBpB,eAAgBsB,EAASD,KACzB/N,aAAcgO,EAASC,EAAUH,IAAaC,MAAc7B,aAC3DxL,aAGPmI,MAAOgF,EAAU,CACf/D,cAAeiE,IACf9D,kBAAmB8D,MAClBrN,YAELJ,IAaE6N,GAAuB,MACzB,WAAApM,CAAYJ,EAASK,EAAUC,GAC7BC,KAAKC,qBAAuB,KAC5BD,KAAKP,QAAUA,EACfO,KAAKF,SAAWA,EAChBE,KAAKD,OAASA,CAClB,CACE,YAAIrG,GACF,OAAOsG,KAAKD,OAAOrG,QACvB,CACE,wBAAIwS,GACF,IAAIzO,EACJ,OAAoD,OAA5CA,EAAKuC,KAAKF,SAASoM,sBAAgCzO,EAAK,IACpE,CACE,yBAAI0O,GACF,IAAI1O,EACJ,OAAqD,OAA7CA,EAAKuC,KAAKF,SAASqM,wBAAiC1O,CAChE,CACE,aAAM2O,EAAQxR,OACZA,EAAAvH,QACAA,EAAAkH,YACAA,IAEA,GAAIK,EAAOnG,OAASuL,KAAKkM,qBACvB,MAAM,IAAIG,EAAmC,CAC3C3S,SAAUsG,KAAKtG,SACf+F,QAASO,KAAKP,QACdyM,qBAAsBlM,KAAKkM,qBAC3BtR,WAGJ,MAAMS,gBAAEA,EAAiBvG,MAAOgB,SAAmBwW,EAAe,CAChEnS,IAAK6F,KAAKD,OAAO5F,IAAI,CACnBiM,KAAM,cACN3G,QAASO,KAAKP,UAEhBpM,QAASkZ,EAAgBvM,KAAKD,OAAO1M,UAAWA,GAChD+G,KAAM,CACJmF,MAAOS,KAAKP,QACZlG,MAAOqB,EACP4R,gBAAiB,QACjBC,WAAYzM,KAAKF,SAAS2M,WAC1BpI,KAAMrE,KAAKF,SAASuE,MAEtBhK,sBAAuByE,EACvBxE,0BAA2BoS,EACzBC,IAEFpS,cACAP,MAAOgG,KAAKD,OAAO/F,QAErB,MAAO,CACL4S,WAAY9W,EAAShC,KAAK6J,IAAKkP,GAASA,EAAKC,WAC7CnG,MAAO7Q,EAAS6Q,MAAQ,CAAE4D,OAAQzU,EAAS6Q,MAAMiB,oBAAkB,EACnEzB,YAAa,CAAE9S,QAASgI,GAE9B,GAEIsR,GAAoCI,EAAU,CAChDjZ,KAAMkZ,EAASD,EAAU,CAAED,UAAWE,EAASC,QAC/CtG,MAAOoG,EAAU,CAAEnF,cAAeqF,MAAezO,YAY/C0O,GAAwB,CAC1B,WAAY,EACZ,WAAY,GACZ,cAAe,IAEbC,GAA2C,IAAIC,IAAI,CAAC,gBAGpDC,GAAmB,MACrB,WAAAxN,CAAYJ,EAASK,EAAUC,GAC7BC,KAAKP,QAAUA,EACfO,KAAKF,SAAWA,EAChBE,KAAKD,OAASA,EACdC,KAAKC,qBAAuB,IAChC,CACE,oBAAIqN,GACF,IAAI7P,EAAIC,EACR,OAA0G,OAAlGA,EAA8C,OAAxCD,EAAKuC,KAAKF,SAASwN,kBAA4B7P,EAAKyP,GAAsBlN,KAAKP,UAAoB/B,EAAK,CAC1H,CACE,YAAIhE,GACF,OAAOsG,KAAKD,OAAOrG,QACvB,CACE,gBAAMuM,EAAWvF,OACfA,EAAA6M,EACAA,EAAApX,KACAA,EAAAqX,YACAA,EAAArM,KACAA,EAAAxH,gBACAA,EAAAtG,QACAA,EAAAkH,YACAA,IAEA,IAAIkD,EAAIC,EAAI2D,EAAIC,EAChB,MAAMK,EAAW,GACE,MAAf6L,GACF7L,EAAS5M,KAAK,CACZwJ,KAAM,sBACNqD,QAAS,cACTC,QAAS,kEAGD,MAARV,GACFQ,EAAS5M,KAAK,CAAEwJ,KAAM,sBAAuBqD,QAAS,SAExD,MAAM6L,EAA6H,OAA9GpM,EAA8E,OAAxE3D,EAAqC,OAA/BD,EAAKuC,KAAKD,OAAO2N,gBAAqB,EAASjQ,EAAGgQ,kBAAuB,EAAS/P,EAAGiQ,KAAKlQ,IAAe4D,MAAyB1B,MAC3J7K,MAAOgB,EAAAuF,gBAAUA,SAA0BuS,EAAe,CAChEzT,IAAK6F,KAAKD,OAAO5F,IAAI,CACnBiM,KAAM,sBACN3G,QAASO,KAAKP,UAEhBpM,QAASwa,EAAgB7N,KAAKD,OAAO1M,UAAWA,GAChD+G,KAAM,CACJmF,MAAOS,KAAKP,QACZiB,SACA6M,IACApX,UACoC,OAAhCmL,EAAK3H,EAAgBmJ,QAAkBxB,EAAK,CAAA,KAC5C6L,GAAyBW,IAAI9N,KAAKP,SAA6C,CAAA,EAAlC,CAAEkF,gBAAiB,aAEtEtK,sBAAuByE,EACvBxE,0BAA2ByT,EACzBC,IAEFzT,cACAP,MAAOgG,KAAKD,OAAO/F,QAErB,MAAO,CACLiU,OAAQnY,EAAShC,KAAK6J,IAAKkP,GAASA,EAAKqB,UACzCvM,WACA7L,SAAU,CACR4J,UAAW+N,EACXhO,QAASO,KAAKP,QACdpM,QAASgI,GAGjB,GAEI2S,GAA4BG,EAAU,CACxCra,KAAMsa,EAASD,EAAU,CAAED,SAAUG,SAYnCC,GAA8BC,EAAU,CAC1CC,QAASC,EAASC,KAAalQ,UAC/BmQ,SAAUD,IAAYlQ,UACtBkC,OAAQgO,IAAYlQ,UACpBoC,YAAagO,IAAYC,IAAI,GAAGC,IAAI,GAAGtQ,UAAUuQ,QAAQ,GACzDC,uBAAwBP,EAASQ,EAAQ,CAAC,OAAQ,aAAazQ,UAAUuQ,QAAQ,CAAC,cAEhFG,GAAc,CAChBC,UAAW,KACXC,OAAQ,KACRC,SAAU,KACVC,YAAa,KACbC,WAAY,KACZC,QAAS,KACTC,UAAW,KACXC,QAAS,KACTC,QAAS,KACTC,SAAU,KACVC,MAAO,KACPC,OAAQ,KACRC,MAAO,KACPC,QAAS,KACTC,SAAU,KACVC,QAAS,KACTC,OAAQ,KACRC,SAAU,KACVC,OAAQ,KACRC,MAAO,KACPC,OAAQ,KACRC,MAAO,KACPC,UAAW,KACXC,UAAW,KACXC,WAAY,KACZC,QAAS,KACTC,SAAU,KACVC,QAAS,KACTC,OAAQ,KACRC,OAAQ,KACRC,QAAS,KACTC,WAAY,KACZC,WAAY,KACZC,MAAO,KACPC,QAAS,KACTC,MAAO,KACPC,OAAQ,KACRC,UAAW,KACXC,QAAS,KACTC,OAAQ,KACRC,WAAY,KACZC,SAAU,KACVC,QAAS,KACTC,QAAS,KACTC,OAAQ,KACRC,UAAW,KACXC,QAAS,KACTC,QAAS,KACTC,QAAS,KACTC,QAAS,KACTC,MAAO,KACPC,KAAM,KACNC,QAAS,KACTC,UAAW,KACXC,KAAM,KACNC,WAAY,KACZC,MAAO,MAELC,GAA2B,MAC7B,WAAA/S,CAAYJ,EAASM,GACnBC,KAAKP,QAAUA,EACfO,KAAKD,OAASA,EACdC,KAAKC,qBAAuB,IAChC,CACE,YAAIvG,GACF,OAAOsG,KAAKD,OAAOrG,QACvB,CACE,OAAA8G,EAAQqS,MACNA,EAAAC,UACAA,EAAAnZ,gBACAA,IAEA,IAAI8D,EAAIC,EAAI2D,EAAIC,EAAIC,EACpB,MACMwR,EAAgBtZ,EAAqB,CACzCC,SAAU,SACVC,kBACAtB,OAAQiW,KAEJ0E,EAAW,IAAIC,SACfC,EAAOL,aAAiB9V,WAAa,IAAIoW,KAAK,CAACN,IAAU,IAAIM,KAAK,CAACzW,EAA0BmW,KAGnG,GAFAG,EAASI,OAAO,QAASpT,KAAKP,SAC9BuT,EAASI,OAAO,OAAQ,IAAIC,KAAK,CAACH,GAAO,QAAS,CAAE3U,KAAMuU,KACtDC,EAAe,CACjB,MAAMO,EAA4B,CAChC9E,QAAyC,OAA/B/Q,EAAKsV,EAAcvE,SAAmB/Q,OAAK,EACrDkR,SAA2C,OAAhCjR,EAAKqV,EAAcpE,UAAoBjR,OAAK,EACvDgD,OAAuC,OAA9BW,EAAK0R,EAAcrS,QAAkBW,OAAK,EACnDT,YAAiD,OAAnCU,EAAKyR,EAAcnS,aAAuBU,OAAK,EAC7DiS,wBAAwE,OAA9ChS,EAAKwR,EAAc/D,wBAAkCzN,OAAK,GAEtF,IAAA,MAAWvL,KAAOsd,EAA2B,CAC3C,MAAMxe,EAAQwe,EAA0Btd,QAC1B,IAAVlB,GACFke,EAASI,OAAOpd,EAAKqH,OAAOvI,GAEtC,CACA,CACI,MAAO,CACLke,WACArR,SA3Be,GA6BrB,CACE,gBAAMsE,CAAWC,GACf,IAAIzI,EAAIC,EAAI2D,EAAIC,EAAIC,EAAIC,EACxB,MAAMiM,EAA6H,OAA9GpM,EAA8E,OAAxE3D,EAAqC,OAA/BD,EAAKuC,KAAKD,OAAO2N,gBAAqB,EAASjQ,EAAGgQ,kBAAuB,EAAS/P,EAAGiQ,KAAKlQ,IAAe4D,MAAyB1B,MAC7JqT,SAAEA,EAAArR,SAAUA,GAAa3B,KAAKQ,QAAQ0F,IAE1CpR,MAAOgB,EAAAuF,gBACPA,EACAjC,SAAU+M,QDrtCQjM,QACtBC,MACA9G,UACA2f,WACA3Y,wBACAC,4BACAC,cACAP,WACIQ,EAAU,CACdL,MACA9G,UACA+G,KAAM,CACJK,QAASuY,EACTpY,OAAQG,OAAOC,YAAYgY,EAAS/X,YAEtCZ,wBACAC,4BACAC,cACAP,UCosCYwZ,CAAkB,CAC1BrZ,IAAK6F,KAAKD,OAAO5F,IAAI,CACnBiM,KAAM,wBACN3G,QAASO,KAAKP,UAEhBpM,QAASogB,EAAgBzT,KAAKD,OAAO1M,UAAW6S,EAAQ7S,SACxD2f,WACA3Y,sBAAuByE,EACvBxE,0BAA2BoZ,EACzBC,IAEFpZ,YAAa2L,EAAQ3L,YACrBP,MAAOgG,KAAKD,OAAO/F,QAEf2U,EAAgC,MAArB7Y,EAAS6Y,UAAoB7Y,EAAS6Y,YAAYO,GAAcA,GAAYpZ,EAAS6Y,eAAY,EAClH,MAAO,CACLhW,KAAM7C,EAAS6C,KACfib,SAIQ,OAJGrS,EAA8B,OAAxBD,EAAKxL,EAAS+d,YAAiB,EAASvS,EAAG3D,IAAKmW,IAAA,CAC/Dnb,KAAMmb,EAAKA,KACXC,YAAaD,EAAKxL,MAClB0L,UAAWF,EAAKG,QACH1S,EAAK,GACpBoN,WACAuF,kBAA+C,OAA3B1S,EAAK1L,EAASqe,UAAoB3S,OAAK,EAC3DG,WACA7L,SAAU,CACR4J,UAAW+N,EACXhO,QAASO,KAAKP,QACdpM,QAASgI,EACTjB,KAAM+L,GAGd,GAEIwN,GAAoCpF,EAAU,CAChD5V,KAAM+V,IACNC,SAAUD,IAAYlQ,UACtB2V,SAAUvF,IAAYpQ,UACtBqV,MAAOpF,EACLF,EAAU,CACRuF,KAAMpF,IACNpG,MAAOsG,IACPqF,IAAKrF,OAEPpQ,YA8IJ,SAAS4V,IAA8BjW,aACrCA,EAAAkW,aACAA,IAEA,OAAQlW,GACN,UAAK,EACL,KAAK,KACH,OAAOkW,EAAe,aAAe,OACvC,IAAK,oBACH,MAAO,SACT,IAAK,iBACH,MAAO,iBACT,QACE,OAAOA,EAAe,aAAe,UAE3C,CAsFA,IAAIC,GAA+B,MACjC,WAAAzU,CAAYJ,EAASM,GACnBC,KAAKC,qBAAuB,KAC5BD,KAAKK,4BAA8B,OACnCL,KAAKE,2BAA4B,EACjCF,KAAKP,QAAUA,EACfO,KAAKD,OAASA,CAClB,CACE,YAAIrG,GACF,OAAOsG,KAAKD,OAAOrG,QACvB,CACE,OAAA8G,EAAQC,KACNA,EAAAE,UACAA,EAAAC,YACAA,EAAAK,cACAA,EAAAJ,KACAA,EAAAC,KACAA,EAAAE,gBACAA,EAAAD,iBACAA,EAAAI,KACAA,EAAAT,OACAA,EAAAU,iBACAA,EAAAF,eACAA,IAEA,IAAIzD,EAAIC,EAAI2D,EACZ,MAAMM,EAAW,GACX4S,EA6jBV,SAAiC9U,GAC/B,GAAIA,EAAQtL,WAAW,MAAQsL,EAAQtL,WAAW,SAChD,OAAIsL,EAAQtL,WAAW,YAAcsL,EAAQtL,WAAW,cAC/C,CACLiM,kBAAkB,EAClBgC,kBAAmB,SACnBoS,wBAAwB,GAGrB,CACLpU,kBAAkB,EAClBgC,kBAAmB,YACnBoS,wBAAwB,GAG5B,MAAO,CACLpU,kBAAkB,EAClBgC,kBAAmB,SACnBoS,wBAAwB,EAE5B,CAjlBwBC,CAAwBzU,KAAKP,SAC3ClB,EAAOkC,EAAKlC,KACN,MAARuC,GACFa,EAAS5M,KAAK,CACZwJ,KAAM,sBACNqD,QAAS,SAGD,MAART,GACFQ,EAAS5M,KAAK,CACZwJ,KAAM,sBACNqD,QAAS,SAGU,MAAnBZ,GACFW,EAAS5M,KAAK,CACZwJ,KAAM,sBACNqD,QAAS,oBAGW,MAApBb,GACFY,EAAS5M,KAAK,CACZwJ,KAAM,sBACNqD,QAAS,qBAGQ,MAAjBX,GACFU,EAAS5M,KAAK,CACZwJ,KAAM,sBACNqD,QAAS,kBAGb,MAAMM,SAAEA,EAAUP,SAAUQ,GAxRhC,UAA0CzB,OACxCA,EAAA0B,kBACAA,IAEA,MAAMF,EAAW,GACXP,EAAW,GACjB,IAAA,MAAWU,KAAEA,EAAA5H,QAAMA,KAAaiG,EAC9B,OAAQ2B,GACN,IAAK,SACH,OAAQD,GACN,IAAK,SACHF,EAASnN,KAAK,CAAEsN,KAAM,SAAU5H,YAChC,MAEF,IAAK,YACHyH,EAASnN,KAAK,CAAEsN,KAAM,YAAa5H,YACnC,MAEF,IAAK,SACHkH,EAAS5M,KAAK,CACZwJ,KAAM,QACN3H,QAAS,+CAEX,MAEF,QAEE,MAAM,IAAII,MACR,oCAFuBoL,KAM7B,MAEF,IAAK,OACHF,EAASnN,KAAK,CACZsN,KAAM,OACN5H,QAASA,EAAQkD,IAAI,CAAC2E,EAAMC,KAC1B,IAAI9E,EAAIC,EAAI2D,EAAIC,EAChB,OAAQgB,EAAK/D,MACX,IAAK,OACH,MAAO,CAAEA,KAAM,aAAc5F,KAAM2J,EAAK3J,MAE1C,IAAK,QACH,MAAO,CACL4F,KAAM,cACNiE,UAAWF,EAAKG,iBAAiBC,IAAMJ,EAAKG,MAAME,WAAa,QAAgC,OAAvBlF,EAAK6E,EAAKM,UAAoBnF,EAAK,uBAAuBiX,EAA2BpS,EAAKG,SAElKI,OAA4E,OAAnExB,EAAqC,OAA/B3D,EAAK4E,EAAKlB,uBAA4B,EAAS1D,EAAGoF,aAAkB,EAASzB,EAAG0B,aAGnG,IAAK,OACH,GAAIT,EAAKxO,gBAAgB4O,IACvB,MAAM,IAAIiS,EAA+B,CACvC1S,cAAe,+BAGnB,GACO,oBADCK,EAAKM,SAET,MAAO,CACLrE,KAAM,aACN6E,SAAkC,OAAvB9B,EAAKgB,EAAKc,UAAoB9B,EAAK,QAAQiB,QACtDc,UAAW,+BAA+Bf,EAAKxO,QAIjD,MAAM,IAAI6gB,EAA+B,CACvC1S,cAAe,uDAQ7B,MAEF,IAAK,YACH,IAAA,MAAWK,KAAQ7H,EACjB,OAAQ6H,EAAK/D,MACX,IAAK,OACH2D,EAASnN,KAAK,CACZsN,KAAM,YACN5H,QAAS,CAAC,CAAE8D,KAAM,cAAe5F,KAAM2J,EAAK3J,SAE9C,MAEF,IAAK,YACHuJ,EAASnN,KAAK,CACZwJ,KAAM,gBACNqW,QAAStS,EAAKiB,WACdtM,KAAMqL,EAAKmB,SACXC,UAAWhJ,KAAKC,UAAU2H,EAAKqB,QAMvC,MAEF,IAAK,OACH,IAAA,MAAWrB,KAAQ7H,EACjByH,EAASnN,KAAK,CACZwJ,KAAM,uBACNqW,QAAStS,EAAKiB,WACdsR,OAAQna,KAAKC,UAAU2H,EAAKrK,UAGhC,MAEF,QAEE,MAAM,IAAIjB,MAAM,qBADSqL,KAK/B,MAAO,CAAEH,WAAUP,WACrB,CAmKoDmT,CAAiC,CAC/EpU,SACA0B,kBAAmBmS,EAAYnS,oBAEjCT,EAAS5M,QAAQoN,GACjB,MAAM4S,EAAgBC,EAAsB,CAC1Ctb,SAAU,SACVC,gBAAiByH,EACjB/I,OAAQ4c,KAEJC,EAAkF,OAAtEzX,EAAsB,MAAjBsX,OAAwB,EAASA,EAAcI,gBAAyB1X,EACzFyG,EAAW,CACf3E,MAAOS,KAAKP,QACZlG,MAAO2I,EACPtB,cACA4D,MAAO3D,EACPuU,kBAAmBzU,KAC4C,UAAzC,MAAlBO,OAAyB,EAASA,EAAe3C,OAAoB,CACvE5F,KAAM,CACJuK,OAAiC,MAAzBhC,EAAe7I,OAAiB,CACtCkG,KAAM,cACNsG,OAAQqQ,EACRje,KAAoC,OAA7ByG,EAAKwD,EAAejK,MAAgByG,EAAK,WAChDpG,YAAa4J,EAAe5J,YAC5Be,OAAQ6I,EAAe7I,QACrB,CAAEkG,KAAM,iBAIhB2G,SAA2B,MAAjB6P,OAAwB,EAASA,EAAc7P,SACzDZ,oBAAsC,MAAjByQ,OAAwB,EAASA,EAAchT,kBACpEsT,qBAAuC,MAAjBN,OAAwB,EAASA,EAAcO,mBACrErQ,MAAwB,MAAjB8P,OAAwB,EAASA,EAAc9P,MACtDZ,KAAuB,MAAjB0Q,OAAwB,EAASA,EAAc1Q,KACrDkR,aAA+B,MAAjBR,OAAwB,EAASA,EAAcQ,gBAE1DhB,EAAYnU,mBAAyF,OAAlD,MAAjB2U,OAAwB,EAASA,EAAc1P,kBAAiG,OAAnD,MAAjB0P,OAAwB,EAASA,EAAcS,oBAA8B,CAC5LC,UAAW,IAC8D,OAAlD,MAAjBV,OAAwB,EAASA,EAAc1P,kBAA4B,CAC7EqQ,OAAQX,EAAc1P,oBAEgD,OAAnD,MAAjB0P,OAAwB,EAASA,EAAcS,mBAA6B,CAC9EG,QAASZ,EAAcS,uBAI1BjB,EAAYC,wBAA0B,CACvCoB,WAAY,SAqBhB,OAlBIrB,EAAYnU,mBACc,MAAxB8D,EAAStD,cACXsD,EAAStD,iBAAc,EACvBe,EAAS5M,KAAK,CACZwJ,KAAM,sBACNqD,QAAS,cACTC,QAAS,uDAGS,MAAlBqC,EAASM,QACXN,EAASM,WAAQ,EACjB7C,EAAS5M,KAAK,CACZwJ,KAAM,sBACNqD,QAAS,OACTC,QAAS,iDAIPtD,GACN,IAAK,UAAW,CACd,MAAM+G,MAAEA,EAAAC,YAAOA,EAAAE,aAAaA,GAjNpC,UAA+BhF,KAC7BA,EAAAoE,OACAA,IAEA,IAAIpH,EACJ,MAAM6H,GAA8B,OAApB7H,EAAKgD,EAAK6E,YAAiB,EAAS7H,EAAGhJ,QAAUgM,EAAK6E,WAAQ,EACxEG,EAAe,GACrB,GAAa,MAATH,EACF,MAAO,CAAEA,WAAO,EAAQC,iBAAa,EAAQE,gBAE/C,MAAMC,EAAajF,EAAKiF,WAClBK,EAAe,GACrB,IAAA,MAAWH,KAAQN,EACjB,OAAQM,EAAKrH,MACX,IAAK,WACHwH,EAAahR,KAAK,CAChBwJ,KAAM,WACNtH,KAAM2O,EAAK3O,KACXK,YAAasO,EAAKtO,YAClBuO,WAAYD,EAAKC,WACjBhB,SAAQA,QAAgB,IAE1B,MACF,IAAK,mBAEI,8BADCe,EAAKhR,GAETmR,EAAahR,KAAK,CAChBwJ,KAAM,qBACNsX,oBAAqBjQ,EAAKjC,KAAKmS,kBAC/BC,cAAenQ,EAAKjC,KAAKqS,eAI3BvQ,EAAa1Q,KAAK,CAAEwJ,KAAM,mBAAoBqH,SAGlD,MACF,QACEH,EAAa1Q,KAAK,CAAEwJ,KAAM,mBAAoBqH,SAIpD,GAAkB,MAAdF,EACF,MAAO,CAAEJ,MAAOS,EAAcR,iBAAa,EAAQE,gBAErD,MAAMlH,EAAOmH,EAAWnH,KACxB,OAAQA,GACN,IAAK,OACL,IAAK,OACL,IAAK,WACH,MAAO,CAAE+G,MAAOS,EAAcR,YAAahH,EAAMkH,gBACnD,IAAK,OACH,MAA4B,uBAAxBC,EAAWjC,SACN,CACL6B,MAAOS,EACPR,YAAa,CACXhH,KAAM,sBAERkH,gBAGG,CACLH,MAAOS,EACPR,YAAa,CACXhH,KAAM,WACNtH,KAAMyO,EAAWjC,UAEnBgC,gBAGJ,QAEE,MAAM,IAAIwQ,EAA+B,CACvChU,cAAe,iCAFQ1D,MAM/B,CAoIqD2X,CAAsB,CACjEzV,OACAoE,OAAQqQ,IAGV,MAAO,CACLvR,KAAM,IACDO,EACHoB,QACAC,eAEF5D,SAAU,IAAIA,KAAa8D,GAErC,CACM,IAAK,cACH,MAAO,CACL9B,KAAM,IACDO,EACHvL,KAAM,CACJuK,OAAuB,MAAfzC,EAAKpI,OAAiB,CAC5BkG,KAAM,cACNsG,OAAQqQ,EACRje,KAA0B,OAAnBoK,EAAKZ,EAAKxJ,MAAgBoK,EAAK,WACtC/J,YAAamJ,EAAKnJ,YAClBe,OAAQoI,EAAKpI,QACX,CAAEkG,KAAM,iBAGhBoD,YAGJ,IAAK,cACH,MAAO,CACLgC,KAAM,IACDO,EACHqB,YAAa,CAAEhH,KAAM,WAAYtH,KAAMwJ,EAAKmF,KAAK3O,MACjDqO,MAAO,CACL,CACE/G,KAAM,WACNtH,KAAMwJ,EAAKmF,KAAK3O,KAChBK,YAAamJ,EAAKmF,KAAKtO,YACvBuO,WAAYpF,EAAKmF,KAAKC,WACtBhB,OAAQqQ,KAIdvT,YAGJ,QAEE,MAAM,IAAI3K,MAAM,qBADSuH,KAIjC,CACE,gBAAM0H,CAAWC,GACf,IAAIzI,EAAIC,EAAI2D,EAAIC,EAAIC,EAAIC,EAAIC,EAC5B,MAAQkC,KAAMvJ,EAAAuH,SAAMA,GAAa3B,KAAKQ,QAAQ0F,GACxC/L,EAAM6F,KAAKD,OAAO5F,IAAI,CAC1BiM,KAAM,aACN3G,QAASO,KAAKP,WAEVpE,gBACJA,EACAvG,MAAOgB,EACPsD,SAAU+M,SACFgQ,EAAe,CACvBhc,MACA9G,QAAS+iB,EAAgBpW,KAAKD,OAAO1M,UAAW6S,EAAQ7S,SACxD+G,OACAC,sBAAuByE,EACvBxE,0BAA2B+b,EACzBC,EAAU,CACR1hB,GAAI2hB,IACJC,WAAYC,IACZ1f,MAAOuf,EAAU,CACf1f,QAAS2f,IACT5X,KAAM4X,MACL/X,UACHe,MAAOgX,IACP1B,OAAQ6B,EACNC,EAAsB,OAAQ,CAC5BL,EAAU,CACR/X,KAAMqY,EAAW,WACjBvU,KAAMuU,EAAW,aACjBnc,QAASic,EACPJ,EAAU,CACR/X,KAAMqY,EAAW,eACjBje,KAAM4d,IACNM,YAAaH,EACXJ,EAAU,CACR/X,KAAMqY,EAAW,gBACjBE,YAAaL,IACbM,UAAWN,IACXtc,IAAKoc,IACLS,MAAOT,YAMjBD,EAAU,CACR/X,KAAMqY,EAAW,iBACjBhC,QAAS2B,IACTtf,KAAMsf,IACN7S,UAAW6S,MAEbD,EAAU,CACR/X,KAAMqY,EAAW,qBAEnBN,EAAU,CACR/X,KAAMqY,EAAW,mBAEnBN,EAAU,CACR/X,KAAMqY,EAAW,aACjBjB,QAASe,EACPJ,EAAU,CACR/X,KAAMqY,EAAW,gBACjBje,KAAM4d,YAMhBU,mBAAoBX,EAAU,CAAEY,OAAQX,MAAevM,WACvDrD,MAAOwQ,MAGX5c,YAAa2L,EAAQ3L,YACrBP,MAAOgG,KAAKD,OAAO/F,QAErB,GAAIlE,EAASiB,MACX,MAAM,IAAIqgB,EAAa,CACrBxgB,QAASd,EAASiB,MAAMH,QACxBuD,MACAqB,kBAAmBpB,EACnBsB,WAAY,IACZL,kBACAgB,aAAc8J,EACdtK,aAAa,IAGjB,MAAMwb,EAAqBvhB,EAAS+e,OAAO3Z,OAAQ2Z,GAA2B,YAAhBA,EAAOtW,MAAoB+Y,QAASzC,GAAWA,EAAOpa,SAASS,OAAQT,GAA6B,gBAAjBA,EAAQ8D,MACnJ+E,EAAYxN,EAAS+e,OAAO3Z,OAAQ2Z,GAA2B,kBAAhBA,EAAOtW,MAA0BZ,IAAKkX,IAAA,CACzFtN,aAAc,WACdhE,WAAYsR,EAAOD,QACnBnR,SAAUoR,EAAO5d,KACjB0M,KAAMkR,EAAOnR,aAET8R,EAA4H,OAAxG9X,EAAyE,OAAnED,EAAK3H,EAAS+e,OAAO0C,KAAM1K,GAAuB,cAAdA,EAAKtO,YAAiC,EAASd,EAAGkY,SAAmBjY,EAAK,KAC9I,MAAO,CACL/E,KAAM0e,EAAmB1Z,IAAKlD,GAAYA,EAAQ9B,MAAMhE,KAAK,MAC7D6iB,QAASH,EAAmBC,QACzB7c,GAAYA,EAAQoc,YAAYlZ,IAAK8Z,IACpC,IAAIhQ,EAAKiQ,EAAKC,EACd,MAAO,CACLC,WAAY,MACZhjB,GAAuF,OAAlF+iB,EAAgD,OAAzCD,GAAOjQ,EAAMzH,KAAKD,QAAQ9J,iBAAsB,EAASyhB,EAAI/J,KAAKlG,IAAgBkQ,EAAME,IACpG1d,IAAKsd,EAAWtd,IAChB6c,MAAOS,EAAWT,UAIxB7Y,aAAciW,GAA8B,CAC1CjW,aAAoD,OAArCkD,EAAKvL,EAASmhB,yBAA8B,EAAS5V,EAAG6V,OACvE7C,aAAc/Q,EAAU7O,OAAS,IAEnC6O,UAAWA,EAAU7O,OAAS,EAAI6O,OAAY,EAC9CmS,UAAWD,EAAmBA,EAAiB7X,IAAKgY,IAAA,CAClDpX,KAAM,OACN5F,KAAMgd,EAAQhd,aACV,EACNgO,MAAO,CACLgB,aAAc7R,EAAS6Q,MAAMmR,aAC7BhQ,iBAAkBhS,EAAS6Q,MAAMoR,eAEnC/P,QAAS,CACP1B,eAAW,EACXC,YAAa,CAAA,GAEfJ,YAAa,CACX9S,QAASgI,EACTjB,KAAM+L,GAER8B,QAAS,CACP7N,KAAMM,KAAKC,UAAUP,IAEvBtE,SAAU,CACRlB,GAAIkB,EAASlB,GACb8K,UAAW,IAAIC,KAA2B,IAAtB7J,EAAS0gB,YAC7B/W,QAAS3J,EAASyJ,OAEpB6B,iBAAkB,CAChB0B,OAAQ,CACNkV,WAAYliB,EAASlB,GACrB0S,mBAA6G,OAAxF/F,EAAmD,OAA7CD,EAAKxL,EAAS6Q,MAAMsR,2BAAgC,EAAS3W,EAAG+F,eAAyB9F,EAAK,KACzHyF,gBAA8G,OAA5FvF,EAAoD,OAA9CD,EAAK1L,EAAS6Q,MAAMuR,4BAAiC,EAAS1W,EAAGuF,kBAA4BtF,EAAK,OAG9HE,WAEN,CACE,cAAMuG,CAAShC,GACb,MAAQvC,KAAMvJ,EAAAuH,SAAMA,GAAa3B,KAAKQ,QAAQ0F,IACxC7K,gBAAEA,EAAiBvG,MAAOgB,SAAmBqgB,EAAe,CAChEhc,IAAK6F,KAAKD,OAAO5F,IAAI,CACnBiM,KAAM,aACN3G,QAASO,KAAKP,UAEhBpM,QAAS+iB,EAAgBpW,KAAKD,OAAO1M,UAAW6S,EAAQ7S,SACxD+G,KAAM,IACDA,EACHgO,QAAQ,GAEV/N,sBAAuByE,EACvBxE,0BAA2B6d,EACzBC,IAEF7d,YAAa2L,EAAQ3L,YACrBP,MAAOgG,KAAKD,OAAO/F,QAEfqe,EAAOrY,KACb,IAAI7B,EAAe,UACfwJ,EAAeE,IACfC,EAAmBD,IACnBP,EAAqB,KACrBN,EAAkB,KAClBgR,EAAa,KACjB,MAAMM,EAAmB,CAAA,EACzB,IAAIjE,GAAe,EACnB,MAAO,CACLjM,OAAQtS,EAASmG,YACf,IAAI9G,gBAAgB,CAClB,SAAAC,CAAUC,EAAOpB,GACf,IAAIwJ,EAAIC,EAAI2D,EAAIC,EAAIC,EAAIC,EAAIC,EAAIC,EAChC,IAAKrM,EAAM8C,QAGT,OAFAgG,EAAe,aACflK,EAAWS,QAAQ,CAAE6J,KAAM,QAASxH,MAAO1B,EAAM0B,QAGnD,MAAMjC,EAAQO,EAAMP,MACpB,GA0NZ,SAAwCO,GACtC,MAAsB,+BAAfA,EAAMkJ,IACf,CA5NgBga,CAA+BzjB,GACT,kBAApBA,EAAM+X,KAAKtO,OACb+Z,EAAiBxjB,EAAM0jB,cAAgB,CACrC/U,SAAU3O,EAAM+X,KAAK5V,KACrBsM,WAAYzO,EAAM+X,KAAK+H,SAEzB3gB,EAAWS,QAAQ,CACjB6J,KAAM,kBACNgJ,aAAc,WACdhE,WAAYzO,EAAM+X,KAAK+H,QACvBnR,SAAU3O,EAAM+X,KAAK5V,KACrBuR,cAAe1T,EAAM+X,KAAKnJ,kBAG5C,GAyMA,SAAmDrO,GACjD,MAAsB,2CAAfA,EAAMkJ,IACf,CA3MuBka,CAA0C3jB,GAAQ,CAC3D,MAAM0S,EAAW8Q,EAAiBxjB,EAAM0jB,cACxB,MAAZhR,GACFvT,EAAWS,QAAQ,CACjB6J,KAAM,kBACNgJ,aAAc,WACdhE,WAAYiE,EAASjE,WACrBE,SAAU+D,EAAS/D,SACnB+E,cAAe1T,EAAMqU,OAGvC,MA2LA,SAAgC9T,GAC9B,MAAsB,qBAAfA,EAAMkJ,IACf,CA7LuBma,CAAuB5jB,IAkL9C,SAA0BO,GACxB,MAAsB,+BAAfA,EAAMkJ,IACf,CA5KuBoa,CAAiB7jB,IA+LxC,SAAkDO,GAChD,MAAsB,0CAAfA,EAAMkJ,IACf,CA5LuBqa,CAAyC9jB,IAwKhE,SAAuCO,GACrC,MAAsB,8BAAfA,EAAMkJ,IACf,CArKuBsa,CAA8B/jB,IAA8B,kBAApBA,EAAM+X,KAAKtO,MAsK1E,SAAiClJ,GAC/B,MAAsB,uBAAfA,EAAMkJ,MAAgD,wBAAflJ,EAAMkJ,IACtD,CA9JuBua,CAAwBhkB,IAwK/C,SAAwCO,GACtC,MAAsB,0CAAfA,EAAMkJ,IACf,CAjKuBwa,CAA+BjkB,GAqKtD,SAAsBO,GACpB,MAAsB,UAAfA,EAAMkJ,IACf,CA7JuBya,CAAalkB,IACtBb,EAAWS,QAAQ,CAAE6J,KAAM,QAASxH,MAAOjC,IAV3Cb,EAAWS,QAAQ,CACjB6J,KAAM,SACN0a,OAAQ,CACNrB,WAAY,MACZhjB,GAAkF,OAA7E8M,EAA6C,OAAvCD,GAAMD,EAAK6W,EAAKtY,QAAQ9J,iBAAsB,EAASwL,EAAGkM,KAAKnM,IAAeE,EAAKmW,IAC9F1d,IAAKrF,EAAM2iB,WAAWtd,IACtB6c,MAAOliB,EAAM2iB,WAAWT,UAf5B7Y,EAAeiW,GAA8B,CAC3CjW,aAA0D,OAA3CV,EAAK3I,EAAMgB,SAASmhB,yBAA8B,EAASxZ,EAAGyZ,OAC7E7C,iBAEF1M,EAAe7S,EAAMgB,SAAS6Q,MAAMmR,aACpChQ,EAAmBhT,EAAMgB,SAAS6Q,MAAMoR,cACxCzQ,EAAoH,OAA9FjG,EAAyD,OAAnD3D,EAAK5I,EAAMgB,SAAS6Q,MAAMsR,2BAAgC,EAASva,EAAG2J,eAAyBhG,EAAKiG,EAChIN,EAAqH,OAAlGzF,EAA0D,OAApDD,EAAKxM,EAAMgB,SAAS6Q,MAAMuR,4BAAiC,EAAS5W,EAAGyF,kBAA4BxF,EAAKyF,IAjBjIsR,EAAiBxjB,EAAM0jB,mBAAgB,EACvCnE,GAAe,EACfpgB,EAAWS,QAAQ,CACjB6J,KAAM,YACNgJ,aAAc,WACdhE,WAAYzO,EAAM+X,KAAK+H,QACvBnR,SAAU3O,EAAM+X,KAAK5V,KACrB0M,KAAM7O,EAAM+X,KAAKnJ,aAZnBzP,EAAWS,QAAQ,CACjB6J,KAAM,YACNgK,UAAWzT,EAAMqU,QAPnBlV,EAAWS,QAAQ,CACjB6J,KAAM,aACNgK,UAAWzT,EAAMqU,SAVnB6O,EAAaljB,EAAMgB,SAASlB,GAC5BX,EAAWS,QAAQ,CACjB6J,KAAM,oBACN3J,GAAIE,EAAMgB,SAASlB,GACnB8K,UAAW,IAAIC,KAAiC,IAA5B7K,EAAMgB,SAAS0gB,YACnC/W,QAAS3K,EAAMgB,SAASyJ,QA4CxC,EACU,KAAA3J,CAAM3B,GACJA,EAAWS,QAAQ,CACjB6J,KAAM,SACNJ,eACAwI,MAAO,CAAEgB,eAAcG,wBACG,MAAtBR,GAAiD,MAAnBN,IAA4B,CAC5D5F,iBAAkB,CAChB0B,OAAQ,CACNkV,aACA1Q,qBACAN,sBAKpB,KAGMgB,QAAS,CACP1B,eAAW,EACXC,YAAa,CAAA,GAEfJ,YAAa,CAAE9S,QAASgI,GACxB4M,QAAS,CAAE7N,KAAMM,KAAKC,UAAUP,IAChCuH,WAEN,GAEIwV,GAAcb,EAAU,CAC1BwB,aAAcrB,IACdwB,qBAAsB3B,EAAU,CAAEjP,cAAeoP,IAAYjY,YAAaA,UAC1EuZ,cAAetB,IACfyB,sBAAuB5B,EAAU,CAAEvP,iBAAkB0P,IAAYjY,YAAaA,YAkF5E4Z,GAA6Bc,EAAS,CAhFf5C,EAAU,CACnC/X,KAAMqY,EAAW,8BACjBzN,MAAOoN,MAEyBD,EAAU,CAC1C/X,KAAM4a,EAAQ,CAAC,qBAAsB,wBACrCrjB,SAAUwgB,EAAU,CAClBW,mBAAoBX,EAAU,CAAEY,OAAQX,MAAe/X,UACvDmI,MAAOwQ,OAGsBb,EAAU,CACzC/X,KAAMqY,EAAW,oBACjB9gB,SAAUwgB,EAAU,CAClB1hB,GAAI2hB,IACJC,WAAYC,IACZlX,MAAOgX,QAGwBD,EAAU,CAC3C/X,KAAMqY,EAAW,6BACjB4B,aAAc/B,IACd5J,KAAM8J,EAAsB,OAAQ,CAClCL,EAAU,CACR/X,KAAMqY,EAAW,aAEnBN,EAAU,CACR/X,KAAMqY,EAAW,iBACjBhiB,GAAI2hB,IACJ3B,QAAS2B,IACTtf,KAAMsf,IACN7S,UAAW6S,IACX5a,OAAQib,EAAW,mBAIsBN,EAAU,CACvD/X,KAAMqY,EAAW,0CACjBwC,QAAS7C,IACTiC,aAAc/B,IACdtN,MAAOoN,MAE2BD,EAAU,CAC5C/X,KAAMqY,EAAW,8BACjB4B,aAAc/B,IACd5J,KAAM8J,EAAsB,OAAQ,CAClCL,EAAU,CACR/X,KAAMqY,EAAW,aAEnBN,EAAU,CACR/X,KAAMqY,EAAW,iBACjBhiB,GAAI2hB,IACJ3B,QAAS2B,IACTtf,KAAMsf,IACN7S,UAAW6S,UAImBD,EAAU,CAC5C/X,KAAMqY,EAAW,yCACjBa,WAAYnB,EAAU,CACpB/X,KAAMqY,EAAW,gBACjBzc,IAAKoc,IACLS,MAAOT,QAGmCD,EAAU,CACtD/X,KAAMqY,EAAW,yCACjBwC,QAAS7C,IACTiC,aAAc/B,IACd4C,cAAe5C,IACftN,MAAOoN,MAEcD,EAAU,CAC/B/X,KAAMqY,EAAW,SACjBjY,KAAM4X,IACN3f,QAAS2f,IACT9X,MAAO8X,IAAY/X,UACnB8a,gBAAiB7C,MAYjBH,EAAU,CAAE/X,KAAMgY,MAAegD,gBAmDnC,IAAItE,GAAuCqB,EAAU,CACnDpR,SAAUsU,IAAShb,UACnBuD,kBAAmB0X,IAAajb,UAChC8W,mBAAoBiB,IAAY/X,UAChCyG,MAAOwU,IAAajb,UACpB6F,KAAMkS,IAAY/X,UAClB6G,gBAAiBkR,IAAY/X,UAC7B2W,cAAesE,IAAajb,UAC5B+W,aAAcgB,IAAY/X,UAC1BgX,iBAAkBe,IAAY/X,YAK5Bkb,GAA6BC,EAAU,IAe3C,IAAIC,GAAc,CAChBC,iBAfF,UAA8B/D,kBAC5BA,EAAAE,aACAA,GACE,IACF,MAAO,CACLzX,KAAM,mBACN3J,GAAI,4BACJ+O,KAAM,CACJmS,oBACAE,gBAEFnQ,WAAY6T,GAEhB,GAaII,GAA8BC,EAAU,CAC1CxE,aAAcyE,IAAYxb,UAC1Byb,MAAOC,IAAYrL,IAAI,KAAMC,IAAI,GAAGC,QAAQ,GAAGvQ,YAE7C2b,GAAoB,MACtB,WAAAta,CAAYJ,EAASM,GACnBC,KAAKP,QAAUA,EACfO,KAAKD,OAASA,EACdC,KAAKC,qBAAuB,IAChC,CACE,YAAIvG,GACF,OAAOsG,KAAKD,OAAOrG,QACvB,CACE,OAAA8G,EAAQ7H,KACNA,EAAAyhB,MACAA,EAAQ,QAAAC,aACRA,EAAe,MAAAJ,MACfA,EAAA1E,aACAA,EAAA5b,gBACAA,IAEA,MAAMgI,EAAW,GACXoR,EAAgBuH,EAAsB,CAC1C5gB,SAAU,SACVC,kBACAtB,OAAQyhB,KAEJS,EAAc,CAClBhb,MAAOS,KAAKP,QACZlG,MAAOZ,EACPyhB,QACAzV,gBAAiB,MACjBsV,QACA1E,gBAaF,GAXI8E,IACE,CAAC,MAAO,OAAQ,MAAO,OAAQ,MAAO,OAAO5jB,SAAS4jB,GACxDE,EAAY5V,gBAAkB0V,EAE9B1Y,EAAS5M,KAAK,CACZwJ,KAAM,sBACNqD,QAAS,eACTC,QAAS,8BAA8BwY,2BAIzCtH,EAAe,CACjB,MAAMyH,EAAqB,CAAA,EAC3B,IAAA,MAAWxkB,KAAOwkB,EAAoB,CACpC,MAAM1lB,EAAQ0lB,EAAmBxkB,QACnB,IAAVlB,IACFylB,EAAYvkB,GAAOlB,EAE7B,CACA,CACI,MAAO,CACLylB,cACA5Y,WAEN,CACE,gBAAMsE,CAAWC,GACf,IAAIzI,EAAIC,EAAI2D,EACZ,MAAMoM,EAA6H,OAA9GpM,EAA8E,OAAxE3D,EAAqC,OAA/BD,EAAKuC,KAAKD,OAAO2N,gBAAqB,EAASjQ,EAAGgQ,kBAAuB,EAAS/P,EAAGiQ,KAAKlQ,IAAe4D,MAAyB1B,MAC7J4a,YAAEA,EAAA5Y,SAAaA,GAAa3B,KAAKQ,QAAQ0F,IAE7CpR,MAAO+d,EAAAxX,gBACPA,EACAjC,SAAU+M,SACFsU,EAAe,CACvBtgB,IAAK6F,KAAKD,OAAO5F,IAAI,CACnBiM,KAAM,gBACN3G,QAASO,KAAKP,UAEhBpM,QAASqnB,EAAgB1a,KAAKD,OAAO1M,UAAW6S,EAAQ7S,SACxD+G,KAAMmgB,EACNlgB,sBAAuByE,EACvBxE,0BDt+DkCJ,OAASpE,WAAUqE,MAAKqB,wBAC9D,MAAMH,EAAkBxF,EAAuBC,GAC/C,IAAKA,EAASsE,KACZ,MAAM,IAAImC,EAAc,CACtB3F,QAAS,yBACTuD,MACAqB,oBACAE,WAAY5F,EAAS6F,OACrBN,kBACAgB,kBAAc,IAGlB,IACE,MAAMxI,QAAeiC,EAAS6kB,cAC9B,MAAO,CACLtf,kBACAvG,MAAO,IAAIiI,WAAWlJ,GACxB,OACOkD,GACP,MAAM,IAAIwF,EAAc,CACtB3F,QAAS,0CACTuD,MACAqB,oBACAE,WAAY5F,EAAS6F,OACrBN,kBACAgB,kBAAc,EACd5D,MAAO1B,GACR,GC48DCwD,YAAa2L,EAAQ3L,YACrBP,MAAOgG,KAAKD,OAAO/F,QAErB,MAAO,CACL6Y,QACAlR,WACAsG,QAAS,CACP7N,KAAMM,KAAKC,UAAU4f,IAEvBzkB,SAAU,CACR4J,UAAW+N,EACXhO,QAASO,KAAKP,QACdpM,QAASgI,EACTjB,KAAM+L,GAGd,GAIA,SAASyU,GAAa1U,EAAU,IAC9B,IAAIzI,EAAIC,EAAI2D,EACZ,MAAMwZ,EAA0D,OAA/Cpd,ED97DH,OADctD,EC+7De+L,EAAQ2U,cD97D9B,EAAS1gB,EAAI0C,QAAQ,MAAO,KC87DsBY,EAAK,4BD/7D9E,IAA8BtD,ECg8D5B,MAAMwO,EAAgD,OAA/BjL,EAAKwI,EAAQyC,eAAyBjL,EAAK,aAC5Dod,EAAsC,OAAtBzZ,EAAK6E,EAAQjP,MAAgBoK,EAAK,SAClD0Z,EAAa,KAAA,CACjBC,cAAe,UAAU9jB,EAAW,CAClCC,OAAQ+O,EAAQ/O,OAChBC,wBAAyB,iBACzBE,YAAa,aAEf,sBAAuB4O,EAAQ+U,aAC/B,iBAAkB/U,EAAQgV,WACvBhV,EAAQ7S,UAEP8nB,EAAkB,CAAC1b,EAASK,EAAW,CAAA,IAAO,IAAIF,EAAwBH,EAASK,EAAU,CACjGpG,SAAU,GAAGohB,SACb3gB,IAAK,EAAGiM,UAAW,GAAGyU,IAAUzU,IAChC/S,QAAS0nB,EACTpS,gBACA3O,MAAOkM,EAAQlM,QAEXohB,EAAwB,CAAC3b,EAASK,EAAW,CAAA,IAAO,IAAI2K,GAA8BhL,EAASK,EAAU,CAC7GpG,SAAU,GAAGohB,eACb3gB,IAAK,EAAGiM,UAAW,GAAGyU,IAAUzU,IAChC/S,QAAS0nB,EACTpS,gBACA3O,MAAOkM,EAAQlM,QAEXqhB,EAAuB,CAAC5b,EAASK,EAAW,CAAA,IAAO,IAAImM,GAAqBxM,EAASK,EAAU,CACnGpG,SAAU,GAAGohB,cACb3gB,IAAK,EAAGiM,UAAW,GAAGyU,IAAUzU,IAChC/S,QAAS0nB,EACT/gB,MAAOkM,EAAQlM,QAEXshB,EAAmB,CAAC7b,EAASK,EAAW,CAAA,IAAO,IAAIuN,GAAiB5N,EAASK,EAAU,CAC3FpG,SAAU,GAAGohB,UACb3gB,IAAK,EAAGiM,UAAW,GAAGyU,IAAUzU,IAChC/S,QAAS0nB,EACT/gB,MAAOkM,EAAQlM,QAEXuhB,EAA4B9b,GAAY,IAAImT,GAAyBnT,EAAS,CAClF/F,SAAU,GAAGohB,kBACb3gB,IAAK,EAAGiM,UAAW,GAAGyU,IAAUzU,IAChC/S,QAAS0nB,EACT/gB,MAAOkM,EAAQlM,QAEXwhB,EAAqB/b,GAAY,IAAI0a,GAAkB1a,EAAS,CACpE/F,SAAU,GAAGohB,WACb3gB,IAAK,EAAGiM,UAAW,GAAGyU,IAAUzU,IAChC/S,QAAS0nB,EACT/gB,MAAOkM,EAAQlM,QAEXyhB,EAAsB,CAAChc,EAASK,KACpC,cACE,MAAM,IAAI9I,MACR,oEAGJ,MAAgB,2BAAZyI,EACK2b,EACL3b,EACAK,GAGGqb,EAAgB1b,EAASK,IAU5BpG,EAAW,SAAS+F,EAASK,GACjC,OAAO2b,EAAoBhc,EAASK,EACxC,EAeE,OAdApG,EAASgiB,cAAgBD,EACzB/hB,EAASiiB,KAAOR,EAChBzhB,EAASkiB,WAAaR,EACtB1hB,EAASmiB,UAdqBpc,GACrB,IAAI6U,GAA6B7U,EAAS,CAC/C/F,SAAU,GAAGohB,cACb3gB,IAAK,EAAGiM,UAAW,GAAGyU,IAAUzU,IAChC/S,QAAS0nB,EACT/gB,MAAOkM,EAAQlM,QAUnBN,EAASoT,UAAYuO,EACrB3hB,EAASoiB,cAAgBT,EACzB3hB,EAASqiB,mBAAqBV,EAC9B3hB,EAAS+I,MAAQ6Y,EACjB5hB,EAASsiB,WAAaV,EACtB5hB,EAASuiB,cAAgBV,EACzB7hB,EAASwiB,mBAAqBX,EAC9B7hB,EAASyiB,OAASX,EAClB9hB,EAAS0iB,YAAcZ,EACvB9hB,EAAS4L,MAAQsU,GACVlgB,CACT,CACakhB,GAAa,CACxBjS,cAAe","x_google_ignoreList":[0,1]}